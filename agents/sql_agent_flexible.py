#!/usr/bin/env python3
"""
üß† SQL Agent Completamente Inteligente v4.2 - Reconstrucci√≥n Definitiva
======================================================================
"""
import logging
import sqlite3
import json
import re
import os
import asyncio
import time
import traceback
from typing import Dict, List, Any, Union, Optional, Tuple
from pathlib import Path
from langchain.schema import SystemMessage, HumanMessage
from datetime import datetime
import math

# Import del m√≥dulo sql_agent_tools
try:
    from .sql_agent_tools import SQLAgentTools
except ImportError:
    from sql_agent_tools import SQLAgentTools

# Import de los nuevos m√≥dulos de utilidades
try:
    from ..utils.sql_cleaner import SQLCleaner
    from ..utils.sql_executor import SQLExecutor
except ImportError:
    # Fallback para imports relativos
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils.sql_cleaner import SQLCleaner
    from utils.sql_executor import SQLExecutor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SQLAgentIntelligent_v4.2")

class MockResponse:
    def __init__(self, content: str):
        self.content = content

def _call_openai_native(client, messages, temperature=0.1, max_tokens=4000, task_description="Consultando modelo de IA") -> MockResponse:
    """
    Funci√≥n de compatibilidad para llamar a OpenAI nativo con streaming y logging.
    """
    try:
        # Logging m√°s conciso
        from openai import OpenAI
        native_client = OpenAI()

        if isinstance(messages, list):
            openai_messages = []
            for msg in messages:
                role = "user"
                content = ""
                if hasattr(msg, 'content'):
                    content = str(msg.content)
                    if isinstance(msg, SystemMessage):
                        role = "system"
                    elif isinstance(msg, HumanMessage):
                        role = "user"
                elif isinstance(msg, dict) and "role" in msg and "content" in msg:
                    role = str(msg["role"])
                    content = str(msg["content"])
                else:
                    content = str(msg)
                openai_messages.append({"role": role, "content": content})
        else:
            content = messages.content if hasattr(messages, 'content') else str(messages)
            openai_messages = [{"role": "user", "content": str(content)}]

        # Siempre usar streaming para que se muestre el progreso en tiempo real
        stream_buffer: List[str] = []
        print(f"   üí° {task_description}...", end="", flush=True)
        
        resp_stream = native_client.chat.completions.create(
            model="gpt-4o",
            messages=openai_messages,  # type: ignore
            temperature=temperature,
            max_tokens=max_tokens,
            stream=True,
        )
        
        for chunk in resp_stream:
            delta = chunk.choices[0].delta
            if hasattr(delta, "content") and delta.content:
                token = delta.content
                stream_buffer.append(token)
                # Mostrar progreso visual
                if len(stream_buffer) % 10 == 0:  # Cada 10 tokens
                    print(".", end="", flush=True)
                    
        print(" ‚úì")  # Finalizar l√≠nea de progreso
        content = "".join(stream_buffer)

        if not content.strip():
            content = '{"success": false, "message": "Error: Respuesta vac√≠a del LLM"}'

        return MockResponse(content)

    except Exception as e:
        error_msg = f"Error en llamada OpenAI del SQLAgent: {str(e)}"
        print(f"   ‚ùå ERROR EN LLM: {error_msg}")
        logger.error(f"Error en _call_openai_native (SQLAgent): {e}", exc_info=True)
        return MockResponse('{"success": false, "message": "Error cr√≠tico en la llamada al LLM."}')

class SQLAgentIntelligent:
    def __init__(self, db_path: str, llm=None):
        """Inicializa el agente SQL inteligente con capacidades avanzadas"""
        self.db_path = db_path
        self.llm = llm
        self.column_metadata = {}
        self.table_relationships = {}
        self.query_cache = {}
        
        # NUEVO: Sistema de aprendizaje
        self.query_patterns = {}  # Patrones de consulta exitosos
        self.performance_metrics = {}  # M√©tricas de rendimiento
        self.medical_knowledge_base = {}  # Base de conocimiento m√©dico
        self.adaptive_weights = {  # Pesos adaptativos para scoring
            'temporal_relevance': 1.0,
            'severity_weight': 2.0,
            'recency_weight': 1.5,
            'complexity_bonus': 1.2
        }
        
        # NUEVO: Atributos para datos de muestra y estad√≠sticas
        self.table_row_counts = {}
        self.sample_data = {}
        self.knowledge_gaps = {}
        self.learned_patterns = {}
        self.semantic_cache = {}
        
        # NUEVO: Herramientas de LLM para validaci√≥n inteligente
        try:
            from .sql_agent_tools import SQLAgentTools
            self.schema_tools = SQLAgentTools(db_path, llm=llm)
        except ImportError:
            from sql_agent_tools import SQLAgentTools
            self.schema_tools = SQLAgentTools(db_path, llm=llm)
        
        # Inicializar componentes
        self._initialize_schema_analysis()  # Cargar esquema primero
        self._initialize_adaptive_learning()
        
        # Configuraci√≥n de logging mejorada con visualizaci√≥n streaming
        self.logger = logging.getLogger("SQLAgent")
        self.logger.setLevel(logging.INFO)
        
        # Formato de logging personalizado con emojis y colores
        formatter = logging.Formatter(
            '%(message)s',  # Solo el mensaje, sin timestamp
            datefmt='%H:%M:%S'
        )
        
        # Handler para consola con colores
        ch = logging.StreamHandler()
        ch.setFormatter(formatter)
        self.logger.addHandler(ch)
        
        # NUEVO: Sistema de visualizaci√≥n streaming
        self.stream_visualization = True
        self.current_step = 0
        self.total_steps = 0

    def _find_ambiguous_columns(self, sql: str, tables: list) -> list:
        """Detecta columnas ambiguas en el SQL generado (sin prefijo de tabla) que existen en m√°s de una tabla."""
        pattern = re.compile(r'(?<!\.)\b([A-Z0-9_]+)\b', re.IGNORECASE)
        used_columns = set(pattern.findall(sql))
        ambiguous = []
        col_table_map = {}
        for t in tables:
            if t in self.column_metadata:
                for c in self.column_metadata[t]['columns']:
                    col_table_map.setdefault(c['name'].upper(), []).append(t)
        for col in used_columns:
            if col.upper() in col_table_map and len(col_table_map[col.upper()]) > 1:
                ambiguous.append(col)
        return ambiguous

    def _auto_prefix_sql(self, sql: str, tables: list) -> str:
        ambiguous_columns = self._find_ambiguous_columns(sql, tables)
        if not ambiguous_columns:
            return sql

        for col in ambiguous_columns:
            candidate_tables = [t for t in tables if col.upper() in [c['name'].upper() for c in self.column_metadata[t]['columns']]]
            if len(candidate_tables) == 1:
                table = candidate_tables[0]
                pattern = re.compile(rf'(?<![\w.]){col}(?![\w.])', re.IGNORECASE)
                sql = pattern.sub(f'{table}.{col}', sql)
            else:
                raise ValueError(f"Ambig√ºedad persistente en columna '{col}', presente en tablas: {', '.join(candidate_tables)}")

        remaining_ambiguous = self._find_ambiguous_columns(sql, tables)
        if remaining_ambiguous:
            raise ValueError(f"Ambig√ºedad persistente despu√©s de correcci√≥n autom√°tica: {remaining_ambiguous}")

        return sql

    async def _explore_schema_for_concepts(self, conceptos: list) -> dict:
        """Busca en el esquema columnas candidatas para cada concepto cl√≠nico detectado."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        all_tables = [row[0] for row in cursor.fetchall()]
        # Buscar columnas candidatas para cada concepto
        concept_candidates = {}
        for concept in conceptos:
            concept_lower = concept.lower().replace(' ', '')
            candidates = []
            for table in all_tables:
                if table.startswith('sqlite_'):
                    continue
                cursor.execute(f"PRAGMA table_info('{table}');")
                for col in cursor.fetchall():
                    col_name = col[1]
                    if concept_lower in col_name.lower().replace('_',''):
                        candidates.append((table, col_name))
            concept_candidates[concept] = candidates
        conn.close()
        return {
            'all_tables': all_tables,
            'concept_candidates': concept_candidates
        }

    async def interactive_schema_exploration(self, conceptos: list) -> dict:
        """Explora el esquema y pregunta al usuario qu√© columnas usar para cada concepto cl√≠nico detectado."""
        exploration = await self._explore_schema_for_concepts(conceptos)
        print("\nüî¨ Exploraci√≥n autom√°tica del esquema:")
        print("\nTablas encontradas:")
        for t in exploration['all_tables']:
            print(f"  - {t}")

        user_choices = {}
        for concept in conceptos:
            print(f"\nColumnas candidatas para '{concept}':")
            candidates = exploration['concept_candidates'].get(concept, [])
            if candidates:
                for tbl, col in candidates:
                    print(f"  - {tbl}.{col}")
            else:
                print("  (No se encontraron columnas para este concepto)")
            print(f"¬øQu√© columna quieres usar para '{concept}'? (ejemplo: TABLA.COLUMNA, o deja vac√≠o para omitir):")
            user_choice = input().strip()
            user_choices[concept] = user_choice

        return {
            'concept_column_map': user_choices,
            'exploration': exploration
        }
    async def _active_schema_exploration(self, keywords: list) -> dict:
        """Explora activamente el esquema buscando tablas y columnas que contengan los keywords dados."""
        results = {}
        for table, meta in self.column_metadata.items():
            for col in meta['columns']:
                for kw in keywords:
                    if kw.lower() in col['name'].lower():
                        if table not in results:
                            results[table] = []
                        results[table].append(col['name'])
        return results


    def _initialize_adaptive_learning(self):
        """Inicializa el sistema de aprendizaje adaptativo."""
        try:
            # Cargar conocimiento previo si existe
            learning_cache = Path(f"learning_cache_{Path(self.db_path).stem}.json")
            if learning_cache.exists():
                with learning_cache.open('r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.knowledge_gaps = data.get('knowledge_gaps', {})
                    self.learned_patterns = data.get('learned_patterns', {})
                    self.semantic_cache = data.get('semantic_cache', {})
                logger.info("üß† Conocimiento previo cargado desde cache.")
        except Exception as e:
            logger.warning(f"No se pudo cargar el cache de aprendizaje: {e}")

    def _save_learning_cache(self):
        """Guarda el conocimiento adquirido para futuras sesiones."""
        try:
            learning_cache = Path(f"learning_cache_{Path(self.db_path).stem}.json")
            with learning_cache.open('w', encoding='utf-8') as f:
                json.dump({
                    'knowledge_gaps': self.knowledge_gaps,
                    'learned_patterns': self.learned_patterns,
                    'semantic_cache': self.semantic_cache
                }, f, indent=2, ensure_ascii=False)
            logger.info("üß† Conocimiento guardado en cache de aprendizaje.")
        except Exception as e:
            logger.warning(f"No se pudo guardar el cache de aprendizaje: {e}")

    def _initialize_schema_analysis(self):
        cache_file = Path(f"schema_cache_{Path(self.db_path).stem}.json")
        if cache_file.exists():
            try:
                with cache_file.open('r', encoding='utf-8') as f:
                    cached_data = json.load(f)
                    self.column_metadata = cached_data.get('column_metadata', {})
                    self.table_row_counts = cached_data.get('table_row_counts', {})
                    self.sample_data = cached_data.get('sample_data', {}) # NUEVO: Cargar muestra de cache
                logger.info("üóÑÔ∏è Esquema cargado desde cache.")
                return
            except (json.JSONDecodeError, IOError) as e:
                logger.warning(f"No se pudo cargar la cache del esquema ({e}), se regenerar√°.")

        logger.info("üîç Generando nuevo an√°lisis de esquema...")
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]
            
            self.table_row_counts = {}  # NUEVO: Almacenar conteo de filas
            
            for table in tables:
                if not table.startswith('sqlite_'):
                    logger.debug(f"üîç Analizando estructura de tabla: {table}")
                    cursor.execute(f"PRAGMA table_info('{table}');")
                    columns_info = cursor.fetchall()
                    self.column_metadata[table] = {'columns': [{'name': r[1], 'type': r[2]} for r in columns_info]}
                    
                    try:
                        logger.debug(f"   ‚ñ∂Ô∏è Conteo de registros en {table}")
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        self.table_row_counts[table] = count
                        
                        # NUEVO: Capturar datos de muestra si la tabla no est√° vac√≠a
                        if count > 0:
                            try:
                                logger.debug(f"   ‚ñ∂Ô∏è Extrayendo muestra de {table}")
                                cursor.execute(f"SELECT * FROM {table} LIMIT 3")
                                sample_rows = cursor.fetchall()
                                column_names = [desc[0] for desc in cursor.description]
                                self.sample_data[table] = {
                                    'columns': column_names,
                                    'rows': [dict(zip(column_names, row)) for row in sample_rows]
                                }
                            except sqlite3.Error as sample_err:
                                # Manejar errores comunes de funciones no soportadas (ej. GETDATE)
                                if "GETDATE" in str(sample_err).upper() or "NO SUCH FUNCTION" in str(sample_err).upper():
                                    logger.warning(f"‚ö†Ô∏è Saltando muestra para {table} (funci√≥n no soportada): {sample_err}")
                                else:
                                    logger.warning(f"‚ö†Ô∏è No se pudo obtener muestra de {table}: {sample_err}")
                    except Exception as e:
                        self.table_row_counts[table] = 0
                        if "GETDATE" in str(e).upper() or "NO SUCH FUNCTION" in str(e).upper():
                            logger.warning(f"‚ö†Ô∏è Saltando estad√≠stica para {table} (funci√≥n no soportada): {e}")
                            logger.debug(f"   ‚ùå Query fallida: SELECT COUNT(*) FROM {table}")
                        else:
                            logger.warning(f"No se pudo obtener estad√≠sticas/muestras de {table}: {e}")
                        
            conn.close()
            self._save_schema_cache()
        except Exception as e:
            logger.error(f"Error inicializando an√°lisis de esquema: {e}")

    def _save_schema_cache(self):
        try:
            cache_file = Path(f"schema_cache_{Path(self.db_path).stem}.json")
            with cache_file.open('w', encoding='utf-8') as f:
                json.dump({
                    'column_metadata': self.column_metadata,
                    'table_row_counts': self.table_row_counts,
                    'sample_data': self.sample_data, # NUEVO: Guardar muestra en cache
                    'table_relationships': self.table_relationships  # NUEVO: Guardar relaciones
                }, f, indent=2)
            logger.info("üíæ Cache del esquema guardado.")
        except Exception as e:
            logger.warning(f"No se pudo guardar la cache del esquema: {e}")

    def _analyze_table_relationships(self):
        """
        üîç MEJORA: Analiza las relaciones entre tablas bas√°ndose en:
        1. Foreign keys expl√≠citas (si existen)
        2. Nombres de columnas coincidentes
        3. Patrones de nomenclatura
        """
        try:
            logger.info("üîç Analizando relaciones entre tablas...")
            
            # Cargar desde cache si existe
            cache_file = Path(f"schema_cache_{Path(self.db_path).stem}.json")
            if cache_file.exists():
                try:
                    with cache_file.open('r', encoding='utf-8') as f:
                        cached_data = json.load(f)
                        if 'table_relationships' in cached_data:
                            self.table_relationships = cached_data['table_relationships']
                            logger.info("‚úÖ Relaciones cargadas desde cache")
                            return
                except Exception:
                    pass
            
            self.table_relationships = {}
            
            # Analizar cada tabla
            for table1, metadata1 in self.column_metadata.items():
                self.table_relationships[table1] = {
                    'foreign_keys': [],
                    'referenced_by': [],
                    'potential_joins': []
                }
                
                columns1 = {col['name'].lower(): col for col in metadata1['columns']}
                
                # Buscar relaciones con otras tablas
                for table2, metadata2 in self.column_metadata.items():
                    if table1 == table2:
                        continue
                    
                    columns2 = {col['name'].lower(): col for col in metadata2['columns']}
                    
                    # Detectar foreign keys por patrones de nomenclatura
                    # Ej: PATI_ID en otra tabla probablemente referencia a PATI_PATIENTS
                    for col_name, col_info in columns1.items():
                        # Patr√≥n 1: TABLA_ID en otra tabla
                        if col_name.endswith('_id'):
                            prefix = col_name[:-3]  # Quitar '_id'
                            # Buscar tabla que coincida con el prefijo
                            if any(table2.lower().startswith(prefix) for table2 in self.column_metadata):
                                self.table_relationships[table1]['foreign_keys'].append({
                                    'column': col_info['name'],
                                    'references_table': table2,
                                    'references_column': col_name,
                                    'confidence': 'high' if table2.lower().startswith(prefix) else 'medium'
                                })
                        
                        # Patr√≥n 2: Columnas con mismo nombre en ambas tablas
                        if col_name in columns2:
                            self.table_relationships[table1]['potential_joins'].append({
                                'local_column': col_info['name'],
                                'foreign_table': table2,
                                'foreign_column': columns2[col_name]['name'],
                                'type': 'same_name'
                            })
            
            # Analizar relaciones inversas
            for table1, rels in self.table_relationships.items():
                for fk in rels['foreign_keys']:
                    ref_table = fk['references_table']
                    if ref_table in self.table_relationships:
                        self.table_relationships[ref_table]['referenced_by'].append({
                            'table': table1,
                            'column': fk['column']
                        })
            
            # Log de resumen
            total_fks = sum(len(rels['foreign_keys']) for rels in self.table_relationships.values())
            total_joins = sum(len(rels['potential_joins']) for rels in self.table_relationships.values())
            logger.info(f"‚úÖ An√°lisis de relaciones completado: {total_fks} FKs detectadas, {total_joins} joins potenciales")
            
            # Guardar en cache
            self._save_schema_cache()
            
        except Exception as e:
            logger.error(f"Error analizando relaciones entre tablas: {e}")
            self.table_relationships = {}

    def _create_error_response(self, error: str, sql: str = "") -> Dict[str, Any]:
        return {'success': False, 'message': f"Error: {error}", 'data': [], 'sql_query': sql}
    
    def _check_table_has_data(self, table_name: str) -> bool:
        """Verifica si una tabla tiene datos (no est√° vac√≠a)."""
        # Siempre verificar directamente la base de datos para mayor confiabilidad
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = cursor.fetchone()[0]
            conn.close()
            
            # Actualizar el cache si est√° disponible
            if hasattr(self, 'table_row_counts'):
                self.table_row_counts[table_name] = count
            
            logger.debug(f"üìä Tabla {table_name}: {count} registros")
            return count > 0
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error verificando datos en {table_name}: {e}")
            return False
    
    def _find_alternative_tables_with_data(self, empty_tables: List[str], concept: str) -> List[str]:
        """Busca tablas alternativas con datos para un concepto dado usando el LLM."""
        try:
            # Recopilar informaci√≥n sobre tablas con datos
            tables_with_data = []
            table_info = []
            
            for table_name, metadata in self.column_metadata.items():
                if table_name in empty_tables:
                    continue
                    
                if self._check_table_has_data(table_name):
                    row_count = self.table_row_counts.get(table_name, 0)
                    if row_count > 0:
                        tables_with_data.append(table_name)
                        columns = [col['name'] for col in metadata['columns']][:10]  # Primeras 10 columnas
                        table_info.append(f"{table_name} ({row_count} registros): {', '.join(columns)}")
            
            if not tables_with_data:
                return []
            
            # Usar el LLM para seleccionar las mejores alternativas
            prompt = f"""Eres un arquitecto de datos m√©dicos especializado en encontrar informaci√≥n en esquemas complejos.

SITUACI√ìN: Las tablas principales para "{concept}" est√°n vac√≠as. Necesito encontrar tablas alternativas con datos.

CONCEPTO BUSCADO: "{concept}"

TABLAS DISPONIBLES CON DATOS (nombre_tabla (registros): columnas principales):
{chr(10).join(table_info[:30])}

ESTRATEGIA DE B√öSQUEDA:

1. AN√ÅLISIS DEL CONCEPTO:
   - ¬øQu√© tipo de informaci√≥n representa "{concept}"?
   - ¬øEn qu√© contexto m√©dico se usa?
   - ¬øQu√© sin√≥nimos o t√©rminos relacionados existen?

2. PATRONES DE B√öSQUEDA POR TIPO:
   
   DIAGN√ìSTICOS/ENFERMEDADES:
   - Tablas con: DIAG, EPIS, HIST, CONDITION, PATHOLOGY
   - Columnas con: diagnosis, disease, condition, observation
   
   PACIENTES:
   - Tablas con: PATI, PATIENT, PERSON
   - Columnas con: name, birth, gender, id
   
   MEDICAMENTOS:
   - Tablas con: MEDI, DRUG, PHARMA, TREATMENT
   - Columnas con: medication, drug, dose, prescription
   
   ALERGIAS:
   - Tablas con: ALLER, INTOL, REACTION
   - Columnas con: allergy, allergen, reaction
   
   PROCEDIMIENTOS:
   - Tablas con: PROC, SURG, INTERVENTION
   - Columnas con: procedure, surgery, operation

3. CRITERIOS DE SELECCI√ìN:
   - Prioriza tablas con m√°s registros (mejor cobertura)
   - Busca columnas de texto libre donde pueda estar la informaci√≥n
   - Considera tablas de historial que pueden contener datos legacy

RESPUESTA REQUERIDA (JSON):
{{
    "tablas_alternativas": ["TABLA1", "TABLA2", "TABLA3"],
    "justificacion": "Por qu√© estas tablas pueden contener informaci√≥n sobre {concept}"
}}"""

            response = _call_openai_native(self.llm, [SystemMessage(content=prompt)])
            content = self._extract_response_text(response)
            
            try:
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    result = json.loads(json_match.group(0))
                    alternatives = result.get('tablas_alternativas', [])
                    # Filtrar solo tablas que existen y tienen datos
                    valid_alternatives = [t for t in alternatives if t in tables_with_data]
                    return valid_alternatives[:3]
            except:
                pass
                
            # Fallback: buscar por palabras clave simples
            alternatives = []
            concept_lower = concept.lower()
            for table in tables_with_data[:10]:
                if concept_lower[:4] in table.lower():
                    alternatives.append(table)
                    if len(alternatives) >= 3:
                        break
                        
            return alternatives
            
        except Exception as e:
            logger.error(f"Error buscando alternativas: {e}")
            return []

    async def process_query(self, query: str, stream_callback=None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        üß† ARQUITECTURA README v3: Flujo de 4 Etapas
        
        Implementa el flujo de razonamiento descrito en la documentaci√≥n para m√°xima robustez.
        """
        start_time = time.time()
        
        try:
            # -----------------------------------------------------------------
            # ETAPA 1: An√°lisis Sem√°ntico con LLM
            # -----------------------------------------------------------------
            if stream_callback:
                stream_callback("üß† Etapa 1: Analizando intenci√≥n de la consulta...")

            medical_analysis = await self._analyze_medical_intent_with_llm(query, stream_callback)
            medical_analysis['original_query'] = query # Guardar query original
            
            # DEBUG: Loggear el resultado del an√°lisis sem√°ntico
            logger.info(f"DEBUG: Resultado Etapa 1 (An√°lisis Sem√°ntico) -> {json.dumps(medical_analysis, indent=2)}")
            
            if stream_callback:
                intent = medical_analysis.get('clinical_intent', 'N/A')[:50]
                stream_callback(f"   - Intenci√≥n detectada: {intent}...")

            # -----------------------------------------------------------------
            # ETAPA 1.5: Enriquecimiento de Conceptos (¬°NUEVO!)
            # -----------------------------------------------------------------
            if stream_callback:
                stream_callback("üß† Etapa 1.5: Expandiendo conceptos m√©dicos abstractos...")

            original_concepts = medical_analysis.get('medical_concepts', [])
            qualifiers = medical_analysis.get('qualifiers', [])
            enriched_concepts = await self._enrich_medical_concepts(original_concepts, qualifiers, stream_callback)
            
            # NO SOBRESCRIBIR: guardar conceptos enriquecidos por separado
            medical_analysis['enriched_keywords'] = [c for c in enriched_concepts if c not in original_concepts]

            if stream_callback:
                # Mostrar si hubo cambios
                if medical_analysis.get('enriched_keywords'):
                    stream_callback(f"   - Conceptos expandidos: {medical_analysis['enriched_keywords']}")
                else:
                    stream_callback("   - Conceptos m√©dicos confirmados sin necesidad de expansi√≥n")

            logger.info(f"DEBUG: An√°lisis m√©dico para Etapa 2 -> {json.dumps(medical_analysis, indent=2)}")

            # -----------------------------------------------------------------
            # ETAPA 2: Mapeo Inteligente de Tablas
            # -----------------------------------------------------------------
            if stream_callback:
                stream_callback("üó∫Ô∏è Etapa 2: Mapeando conceptos a tablas del esquema...")
                
            table_candidates = await self._intelligent_table_mapping(medical_analysis, medical_analysis, stream_callback)
            
            # NUEVO: An√°lisis din√°mico con LLM para detectar tablas obligatorias
            if self.llm:
                mandatory_analysis = await self._analyze_mandatory_tables_with_llm(query, table_candidates)
                if mandatory_analysis:
                    logger.info(f"üß† An√°lisis din√°mico de tablas obligatorias: {mandatory_analysis}")
                    # El an√°lisis din√°mico ya incluye las instrucciones en el prompt
            
            if not table_candidates:
                return self._create_error_response("No se pudieron identificar tablas relevantes para la consulta.")
            
            if stream_callback:
                stream_callback(f"   - Tablas candidatas: {', '.join(table_candidates[:4])}...")

            # -----------------------------------------------------------------
            # ETAPA 3: An√°lisis de Conectividad (JOINs)
            # -----------------------------------------------------------------
            if stream_callback:
                stream_callback("üîó Etapa 3: Buscando la mejor ruta de conexi√≥n (JOINs)...")

            join_analysis = await self._llm_find_join_path_optimized(query, table_candidates, stream_callback)
            final_tables = join_analysis.get("final_tables", table_candidates[:1])
            join_conditions = join_analysis.get("join_conditions", [])

            if stream_callback:
                stream_callback(f"   - Ruta de JOIN encontrada para: {', '.join(final_tables)}")

            # -----------------------------------------------------------------
            # ETAPA 4: Generaci√≥n de Plan y SQL
            # -----------------------------------------------------------------
            if stream_callback:
                stream_callback("üìù Etapa 4: Creando plan de ejecuci√≥n y generando SQL...")

            # Extraer par√°metros de la consulta ANTES de generar el plan
            extracted_params = []
            
            # Usar LLM para determinar si necesitamos par√°metros espec√≠ficos
            needs_specific_params = await self._llm_analyze_parameter_needs(query, medical_analysis, stream_callback)
            
            if needs_specific_params:
                entities = medical_analysis.get('entities', {})
                patient_ids = entities.get('patient_ids', [])
                patient_names = entities.get('patient_names', [])
                
                if patient_ids or patient_names:
                    if patient_ids:
                        extracted_params.append(patient_ids[0])
                    if patient_names:
                        patient_name = patient_names[0]
                        # Normalizar el nombre en Python para b√∫squeda exacta
                        normalized_name = self._normalize_accents_python(patient_name)
                        extracted_params.append(normalized_name)
                
                # Si no se detectaron entidades, intentar extraer manualmente nombres espec√≠ficos
                if not extracted_params:
                    import re
                    # Patrones para detectar nombres de personas en consultas en espa√±ol
                    specific_name_patterns = [
                        r'paciente\s+(?:llamad[ao]|que\s+se\s+llam[ae])\s+([A-Za-z√Å√°√â√©√ç√≠√ì√≥√ö√∫√ë√±\s]+)',
                        r'(?:de|del|para|sobre)\s+(?!de|del|para|sobre)([A-Z][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z][a-z√°√©√≠√≥√∫√±]+)+)',
                        r'(?:de|del|para|sobre)\s+(?!de|del|para|sobre)([A-Za-z√Å√°√â√©√ç√≠√ì√≥√ö√∫√ë√±]+)',
                        r'constantes\s+(?:de|para|vitales\s+de)\s+([A-Za-z√Å√°√â√©√ç√≠√ì√≥√ö√∫√ë√±\s]+)',
                        r'(?:paciente|persona)\s+([A-Za-z√Å√°√â√©√ç√≠√ì√≥√ö√∫√ë√±\s]+?)\s+(?:tiene|ha|con|ha sido|hab√≠a)',
                        r'(?:paciente|persona)\s+([A-Za-z√Å√°√â√©√ç√≠√ì√≥√ö√∫√ë√±\s]+)',
                        r'\b([A-Z][a-z√°√©√≠√≥√∫√±]+\s+[A-Z][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z][a-z√°√©√≠√≥√∫√±]+)*)\b'
                    ]
                    
                    # NUEVO: Patrones para detectar IDs de pacientes (prioridad: UUIDs completos)
                    id_patterns = [
                        r'(?:con\s+)?id\s+([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})',  # UUIDs completos
                        r'(?:paciente\s+)?([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})',  # UUIDs completos sin 'id'
                        r'(?:con\s+)?id\s+([0-9]+)',  # IDs num√©ricos
                        r'(?:paciente\s+)?([0-9]+)',  # IDs num√©ricos sin 'id'
                        r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})',  # UUIDs sueltos
                        r'\b([0-9]{6,})\b',  # IDs num√©ricos largos, solo si no es parte de un UUID
                    ]
                    
                    print(f"üîç DEBUG: Intentando extraer nombres e IDs manualmente de la consulta: '{query}'")
                    
                    # PRIMERO: Intentar extraer IDs (prioridad alta)
                    for pattern in id_patterns:
                        matches = re.findall(pattern, query, re.IGNORECASE)
                        if matches:
                            for match in matches:
                                if match and len(match) > 5:  # Filtrar IDs v√°lidos
                                    extracted_params.append(match)
                                    print(f"‚úÖ DEBUG: ID extra√≠do manualmente: '{match}' -> {extracted_params}")
                                    break
                            if extracted_params:
                                break
                    
                    # SEGUNDO: Si no se encontraron IDs, intentar extraer nombres
                    if not extracted_params:
                        for pattern in specific_name_patterns:
                            matches = re.findall(pattern, query, re.IGNORECASE)
                            if matches:
                                for match in matches:
                                    name = match.strip()
                                    # Filtrar nombres muy cortos o palabras comunes
                                    if len(name) > 3 and not any(common in name.lower() for common in ['paciente', 'diabetes', 'hemoglobina', 'tipo', 'vital', 'record']):
                                        parts = name.split()
                                        
                                        # Si parece un nombre completo (nombre + apellido)
                                        if len(parts) >= 2:
                                            # Normalizar el nombre completo en Python para b√∫squeda exacta
                                            normalized_name = self._normalize_accents_python(name)
                                            extracted_params.append(normalized_name)
                                            print(f"‚úÖ DEBUG: Nombre completo extra√≠do manualmente: '{name}' -> {extracted_params}")
                                            break
                                        # Si es solo un nombre/apellido
                                        else:
                                            normalized_name = self._normalize_accents_python(name)
                                            extracted_params.append(normalized_name)
                                            print(f"‚úÖ DEBUG: Nombre √∫nico extra√≠do manualmente: '{name}' -> {extracted_params}")
                                            break
                                # Salir del bucle de patrones si se encontr√≥ un nombre
                                if extracted_params:
                                    break
                    
                    # Si se encontraron par√°metros, loggear para debugging
                    if extracted_params:
                        print(f"üîç DEBUG: Par√°metros extra√≠dos manualmente: {extracted_params}")
                        
                        # Tambi√©n incluirlos en el an√°lisis m√©dico para referencia futura
                        if 'entities' not in medical_analysis:
                            medical_analysis['entities'] = {}
                        if 'patient_ids' not in medical_analysis['entities']:
                            medical_analysis['entities']['patient_ids'] = []
                        if 'patient_names' not in medical_analysis['entities']:
                            medical_analysis['entities']['patient_names'] = []
                        
                        # Guardar el par√°metro extra√≠do
                        for param in extracted_params:
                            if re.match(r'^[a-f0-9\-]{36}$', param, re.IGNORECASE) or re.match(r'^\d+$', param):
                                # Es un ID
                                if param not in medical_analysis['entities']['patient_ids']:
                                    medical_analysis['entities']['patient_ids'].append(param)
                            else:
                                # Es un nombre
                                if param not in medical_analysis['entities']['patient_names']:
                                    medical_analysis['entities']['patient_names'].append(param)
                    else:
                        print("‚ùì DEBUG: No se pudieron extraer par√°metros manualmente de la consulta")
                    
                    print(f"üîë DEBUG: Par√°metros extra√≠dos finales: {extracted_params}")
            
            if stream_callback and extracted_params:
                stream_callback(f"   - Par√°metros de b√∫squeda detectados: {len(extracted_params)} elemento(s)")
            
            execution_plan = {
                "operation_type": "SELECT",
                "relevant_tables": final_tables,
                "join_conditions": join_conditions,
                "execution_plan": f"Plan para '{query}'",
                "params": extracted_params,  # A√±adir par√°metros extra√≠dos
                "semantic_analysis": medical_analysis
            }

            print(f"üîß DEBUG: Plan de ejecuci√≥n creado con par√°metros: {execution_plan.get('params', [])}")

            generated_sql = await self._llm_generate_smart_sql(query, execution_plan, stream_callback)
            sql_params = execution_plan.get('params', [])
            
            print(f"üîß DEBUG: SQL generado: {generated_sql}")
            print(f"üîß DEBUG: Par√°metros SQL despu√©s de generaci√≥n: {sql_params}")

            if generated_sql.startswith("Error:"):
                return self._create_error_response(f"Error generando SQL: {generated_sql}")

            # La validaci√≥n y regeneraci√≥n de SQL incompleto se mantiene
            validation_result = await self._validate_sql_completeness_with_llm(query, generated_sql, self.column_metadata)
            if validation_result:
                logger.warning(f"‚ö†Ô∏è SQL inicial incompleto detectado: {validation_result.get('razon', 'Sin raz√≥n')}")
                
                if validation_result.get('tablas_faltantes'):
                    logger.info(f"üîÑ Regenerando SQL con contexto de validaci√≥n...")
                    
                    missing_tables = validation_result.get('tablas_faltantes', [])
                    current_and_missing_tables = list(set(final_tables + missing_tables))
                    execution_plan['relevant_tables'] = current_and_missing_tables
                    
                    execution_plan['correction_feedback'] = await self._generate_intelligent_correction_feedback(
                        query, generated_sql, validation_result, current_and_missing_tables
                    )
                    
                    # CR√çTICO: Preservar par√°metros durante regeneraci√≥n
                    print(f"üîß DEBUG: Preservando par√°metros durante regeneraci√≥n: {execution_plan.get('params', [])}")
                    
                    # Intentar regenerar con el feedback inteligente
                    regenerated_sql = await self._llm_generate_smart_sql(query, execution_plan, stream_callback)
                    if regenerated_sql and not regenerated_sql.startswith("Error"):
                        generated_sql = regenerated_sql
                        # Asegurar que los par√°metros se mantienen
                        sql_params = execution_plan.get('params', [])
                        print(f"‚úÖ DEBUG: SQL regenerado con par√°metros preservados: {sql_params}")
                    else:
                        print(f"‚ö†Ô∏è DEBUG: Regeneraci√≥n fall√≥, manteniendo SQL original")
            
            # -----------------------------------------------------------------
            # ETAPA FINAL: Ejecuci√≥n
            # -----------------------------------------------------------------
            print(f"üöÄ DEBUG: Ejecutando con SQL: {generated_sql}")
            print(f"üöÄ DEBUG: Par√°metros finales para ejecuci√≥n: {sql_params}")
            
            result = await self._execute_sql_with_learning(query, generated_sql, start_time, sql_params, stream_callback)
            
            # -----------------------------------------------------------------
            # ETAPA 5: Interpretaci√≥n y Explicaci√≥n
            # -----------------------------------------------------------------
            if result.get('success'):
                if stream_callback:
                    stream_callback("ü©∫ Etapa 5: Interpretaci√≥n cl√≠nica de resultados...")
                
                if not result.get('data'):
                    if stream_callback:
                        stream_callback("   - Analizando ausencia de resultados...")
                    result['explanation'] = await self._llm_interpret_results(query, [], stream_callback)
                else:
                    if stream_callback:
                        stream_callback(f"   - Interpretando {len(result['data'])} resultado(s) encontrado(s)...")
                    interpretation = await self._llm_interpret_results(query, result['data'], stream_callback)
                    result['explanation'] = interpretation
                
                if stream_callback:
                    stream_callback("   ‚úÖ Interpretaci√≥n m√©dica completada")
            else:
                if stream_callback:
                    stream_callback("‚ùå No se pudo generar interpretaci√≥n debido a errores en la ejecuci√≥n")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error cr√≠tico en el flujo de 4 etapas: {e}", exc_info=True)
            import traceback
            print(f"üîç DEBUG - Error completo:")
            print(f"   Tipo de error: {type(e).__name__}")
            print(f"   Mensaje: {str(e)}")
            print(f"   Traceback completo:")
            traceback.print_exc()
            return self._create_error_response(f'Error cr√≠tico procesando la consulta: {str(e)}')

    async def _generate_intelligent_correction_feedback(self, query: str, incomplete_sql: str, 
                                                       validation_result: Dict[str, Any], 
                                                       all_tables: List[str]) -> str:
        """Genera feedback inteligente y gen√©rico para corregir SQL incompleto usando LLM"""
        if not self.llm:
            return f"SQL incompleto. Incluye las tablas: {', '.join(validation_result.get('tablas_faltantes', []))}"
        
        try:
            # Obtener esquema de las tablas relevantes
            schema_info = {}
            for table in all_tables:
                if table in self.column_metadata:
                    schema_info[table] = [col['name'] for col in self.column_metadata[table]['columns'][:10]]
            
            prompt = f"""Eres un experto en bases de datos m√©dicas. Tu tarea es generar instrucciones espec√≠ficas para corregir un SQL incompleto.

CONSULTA ORIGINAL: {query}

SQL INCOMPLETO GENERADO:
{incomplete_sql}

AN√ÅLISIS DE VALIDACI√ìN:
- Raz√≥n por la que est√° incompleto: {validation_result.get('razon', 'No especificada')}
- Tablas faltantes identificadas: {validation_result.get('tablas_faltantes', [])}
- Sugerencia del validador: {validation_result.get('sugerencia', 'No especificada')}

ESQUEMA DE TABLAS DISPONIBLES:
{json.dumps(schema_info, indent=2)}

TAREA: Genera instrucciones espec√≠ficas y claras para corregir el SQL. Las instrucciones deben:

1. Explicar exactamente por qu√© el SQL actual es incompleto
2. Especificar qu√© tablas adicionales se necesitan y por qu√©
3. Sugerir c√≥mo combinar o relacionar las tablas (JOIN vs consultas separadas)
4. Proporcionar ejemplos concretos de SQL corregido
5. Ser gen√©rico - no asumir tipos espec√≠ficos de consulta

FORMATO DE RESPUESTA:
Genera un texto de instrucciones claras y espec√≠ficas que un desarrollador pueda seguir para corregir el SQL.

EJEMPLO DE RESPUESTA:
"Tu SQL actual solo consulta la tabla X, pero para responder completamente la pregunta necesitas tambi√©n la tabla Y porque contiene [explicaci√≥n]. 

Para corregir esto:
1. Incluye la tabla Y en tu consulta
2. Si las tablas tienen relaci√≥n directa, usa JOIN con la condici√≥n [condici√≥n]
3. Si no tienen relaci√≥n directa, genera consultas separadas

Ejemplo de SQL corregido:
[ejemplo de SQL]"

Genera las instrucciones espec√≠ficas para esta situaci√≥n:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}]
            )
            
            feedback = self._extract_response_text(response)
            logger.info(f"üß† Feedback inteligente generado: {feedback[:200]}...")
            return feedback
            
        except Exception as e:
            logger.error(f"Error generando feedback inteligente: {e}")
            # Fallback a feedback b√°sico
            return f"""Tu SQL actual est√° incompleto para responder la pregunta del usuario.

PROBLEMA: {validation_result.get('razon', 'Faltan tablas necesarias')}

SOLUCI√ìN: Incluye las siguientes tablas en tu consulta: {', '.join(validation_result.get('tablas_faltantes', []))}

Analiza qu√© informaci√≥n espec√≠fica necesitas de cada tabla y genera SQL que obtenga todos los datos relevantes para responder la pregunta completamente."""

    async def _enhanced_semantic_analysis(self, query: str, medical_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """An√°lisis sem√°ntico mejorado con contexto m√©dico"""
        
        # Combinar an√°lisis tradicional con contexto m√©dico
        basic_analysis = await self._analyze_query_semantics(query)
        
        # Enriquecer con informaci√≥n m√©dica
        enhanced_analysis = {
            **basic_analysis,
            'medical_concepts': medical_analysis.get('medical_concepts', []),
            'clinical_intent': medical_analysis.get('clinical_intent', ''),
            'complexity_level': medical_analysis.get('complexity_level', 'simple'),
            'risk_factors': medical_analysis.get('risk_factors', [])
        }
        
        return enhanced_analysis

    async def _intelligent_table_mapping(self, semantic_analysis: Dict[str, Any], medical_analysis: Dict[str, Any], stream_callback=None) -> List[str]:
        """Mapeo inteligente de tablas basado en an√°lisis m√©dico - TODO VIA LLM"""
        
        if stream_callback:
            stream_callback("   - Seleccionando tablas relevantes con IA...")
        
        # Si hay LLM, delegar completamente la selecci√≥n
        if self.llm:
            try:
                clinical_intent = medical_analysis.get('clinical_intent', '')
                medical_concepts = medical_analysis.get('medical_concepts', [])
                
                # Obtener lista de TODAS las tablas disponibles
                all_tables = list(self.column_metadata.keys())
                
                prompt = f"""Eres un experto en arquitectura de datos cl√≠nicos.
Analiza el contexto y selecciona las tablas M√ÅS RELEVANTES para responder la consulta.

CONSULTA ORIGINAL: {medical_analysis.get('original_query', '')}
INTENCI√ìN CL√çNICA: {clinical_intent}
CONCEPTOS M√âDICOS: {', '.join(medical_concepts)}

ESQUEMA DISPONIBLE:
{self._get_schema_summary_for_exploration()}

INSTRUCCIONES:
1. Selecciona SOLO las tablas necesarias (m√°ximo 5)
2. Si se buscan datos de pacientes espec√≠ficos, SIEMPRE incluir PATI_PATIENTS
3. Para observaciones/signos vitales, priorizar OBSE_OBSERVATIONS 
4. Ordena por relevancia (m√°s importante primero)

Responde SOLO con JSON:
{{"selected_tables": ["tabla1", "tabla2", ...]}}"""

                resp = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": prompt}]
                )
                
                result = self._try_parse_llm_json(self._extract_response_text(resp))
                if result and result.get("selected_tables"):
                    # Validar que las tablas existan
                    valid_tables = [t for t in result["selected_tables"] if t in self.column_metadata]
                    if valid_tables:
                        if stream_callback:
                            stream_callback(f"   - Tablas seleccionadas: {', '.join(valid_tables[:3])}...")
                        return valid_tables[:5]
                        
            except Exception as e:
                logger.warning(f"Error en selecci√≥n LLM de tablas: {e}")
        
        # Fallback m√≠nimo: tablas m√°s comunes
        if stream_callback:
            stream_callback("   - Usando selecci√≥n b√°sica de tablas...")
        return list(self.column_metadata.keys())[:5]



    async def _execute_sql_with_learning(self, query: str, sql: str, start_time: float, sql_params: Optional[List[Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """Ejecuta SQL usando los m√≥dulos centralizados de limpieza y ejecuci√≥n"""
        
        logger.info(f"üîç SQL original recibido: {sql}")
        logger.info(f"üîç SQL COMPLETO PARA DEPURACI√ìN: {sql}")
        
        if stream_callback:
            stream_callback("üîç Optimizando y ejecutando consulta SQL...")
        
        try:
            # PASO 1: Limpiar y sanitizar el SQL
            if stream_callback:
                stream_callback("   - Limpiando y optimizando SQL...")
            
            # --- REFORZADO: limpiar errores de palabras pegadas antes de todo ---
            sql = self._fix_typo_errors(sql)
            sql = self._basic_sql_cleanup(sql)
            
            cleaned_sql = SQLCleaner.sanitize_for_execution(sql)
            
            # Aplicar correcciones espec√≠ficas de compatibilidad
            cleaned_sql = await self._fix_sql_compatibility(cleaned_sql, stream_callback)
            
            # Aplicar correcciones de sintaxis
            cleaned_sql = SQLCleaner.fix_common_syntax_errors(cleaned_sql)
            
            logger.info(f"‚úÖ SQL limpio y listo: {cleaned_sql[:200]}...")
            
            # PASO 2: Validar sintaxis antes de ejecutar
            if stream_callback:
                stream_callback("   - Validando sintaxis SQL...")
                
            executor = SQLExecutor(self.db_path)
            is_valid, syntax_error = executor.test_query_syntax(cleaned_sql)
            
            if not is_valid:
                logger.error(f"‚ùå Error de sintaxis SQL: {syntax_error}")
                
                # SISTEMA DE RECUPERACI√ìN: Regenerar SQL con informaci√≥n del error
                if stream_callback:
                    stream_callback("   - Error de sintaxis detectado, regenerando SQL...")
                
                # Obtener informaci√≥n del contexto original
                original_query = getattr(self, '_last_query', query)
                original_params = sql_params or []
                
                # Regenerar SQL con informaci√≥n del error
                regenerated_sql = await self._regenerate_sql_with_error_context(
                    original_query, cleaned_sql, syntax_error or "Error de sintaxis desconocido", original_params, stream_callback
                )
                
                if regenerated_sql and not regenerated_sql.startswith("Error"):
                    logger.info(f"üîÑ SQL regenerado exitosamente despu√©s de error")
                    # Ejecutar el SQL regenerado
                    return await self._execute_sql_with_learning(query, regenerated_sql, start_time, original_params, stream_callback)
                else:
                    return {
                        'success': False,
                        'message': f'‚ùå Error de sintaxis SQL: {syntax_error}',
                        'data': [],
                        'sql_query': cleaned_sql,
                        'error': syntax_error
                    }
            
            # PASO 3: Verificar y ajustar par√°metros
            sql_params = sql_params or []
            placeholder_count = cleaned_sql.count('?')
            
            # NORMALIZAR PAR√ÅMETROS si contienen nombres
            normalized_params = []
            for param in sql_params:
                if isinstance(param, str) and param:
                    # Normalizar el par√°metro usando nuestra funci√≥n ROBUSTA
                    normalized_param = self._normalize_accents_python(param)
                    normalized_params.append(normalized_param)
                else:
                    normalized_params.append(param)
            
            sql_params = normalized_params
            
            # DETECCI√ìN ESPECIAL: Si es b√∫squeda de pacientes, usar SQL robusto
            if 'PATI_PATIENTS' in cleaned_sql.upper() and 'PATI_FULL_NAME' in cleaned_sql.upper():
                if stream_callback:
                    stream_callback("   - Detectada b√∫squeda de pacientes, aplicando SQL robusto...")
                
                # Extraer el t√©rmino de b√∫squeda del primer par√°metro
                search_term = sql_params[0] if sql_params else ""
                
                # Usar SQL robusto con sugerencias
                cleaned_sql = self._create_robust_patient_search_sql(search_term, include_suggestions=True)
                sql_params = self._prepare_search_parameters(search_term)
                
                logger.info(f"üîç Aplicado SQL robusto para b√∫squeda de pacientes: {search_term}")
            
            if placeholder_count != len(sql_params):
                logger.warning(f"‚ö†Ô∏è Ajustando par√°metros: {len(sql_params)} ‚Üí {placeholder_count}")
                
                if placeholder_count > len(sql_params):
                    # A√±adir par√°metros duplicados para consultas que requieren el mismo par√°metro m√∫ltiples veces
                    if len(sql_params) > 0:
                        # Repetir el √∫ltimo par√°metro v√°lido
                        last_param = sql_params[-1]
                        sql_params.extend([last_param] * (placeholder_count - len(sql_params)))
                    else:
                        # A√±adir par√°metros vac√≠os
                        sql_params.extend([''] * (placeholder_count - len(sql_params)))
                else:
                    # Truncar par√°metros
                    sql_params = sql_params[:placeholder_count]
                
            # PASO 4: Ejecutar con el m√≥dulo ejecutor
            if stream_callback:
                stream_callback("   - Ejecutando consulta en la base de datos...")
                
            result = executor.execute_query(cleaned_sql, sql_params)
            
            # PASO 5: Procesar resultado
            if result['success']:
                if stream_callback:
                    stream_callback(f"   ‚úÖ Consulta completada: {result['row_count']} resultados en {result['execution_time']:.2f}s")
                
                # PROCESAMIENTO ESPECIAL para b√∫squedas de pacientes
                if 'PATI_PATIENTS' in cleaned_sql.upper() and 'PATI_FULL_NAME' in cleaned_sql.upper():
                    search_term = sql_params[0] if sql_params else ""
                    processed_results = self._process_patient_search_results(result['data'], search_term)
                    
                    return {
                        'success': processed_results['success'],
                        'message': processed_results['message'],
                        'data': processed_results['data'],
                        'exact_matches': processed_results.get('exact_matches', []),
                        'suggestions': processed_results.get('suggestions', []),
                        'sql_query': cleaned_sql,
                        'execution_time': result['execution_time'],
                        'total_time': time.time() - start_time
                    }
                
                # Aprender del √©xito
                await self._learn_from_query_result(query, cleaned_sql, result['row_count'], result['execution_time'])
                
                return {
                    'success': True,
                    'message': f'‚úÖ Encontrados {result["row_count"]} resultados',
                    'data': result['data'],
                    'sql_query': cleaned_sql,
                    'execution_time': result['execution_time'],
                    'total_time': time.time() - start_time
                }
            else:
                if stream_callback:
                    stream_callback(f"   ‚ùå Error ejecutando SQL: {result['error'][:100]}")
                
                # Aprender del error
                await self._learn_from_error(query, result['error'])
                    
                return {
                    'success': False,
                    'message': f'‚ùå Error ejecutando consulta: {result["error"]}',
                    'data': [],
                    'sql_query': cleaned_sql,
                    'error': result['error']
                }
                
        except Exception as e:
            # Manejo de errores generales
            error_msg = str(e)
            logger.error(f"‚ùå Error en _execute_sql_with_learning: {error_msg}")
            
            if stream_callback:
                stream_callback(f"   ‚ùå Error inesperado: {error_msg[:100]}")
            
            return {
                'success': False,
                'message': f'‚ùå Error procesando consulta: {error_msg}',
                'data': [],
                'sql_query': sql,
                'error': error_msg
            }

    def _validate_columns_exist_in_schema(self, sql: str, tables_info: Dict[str, List[str]]) -> Optional[str]:
        """Validaci√≥n estricta: verifica que TODAS las columnas usadas existan en el esquema real"""
        try:
            # Crear un conjunto de todas las columnas v√°lidas con y sin prefijo de tabla
            valid_columns = set()
            for table_name, columns in tables_info.items():
                for column in columns:
                    valid_columns.add(column.upper())  # Sin prefijo
                    valid_columns.add(f"{table_name}.{column}".upper())  # Con prefijo
            
            # Extraer todas las columnas usadas en el SQL
            # Patr√≥n para capturar columnas en SELECT, WHERE, JOIN ON, etc.
            column_patterns = [
                r'SELECT\s+(?:DISTINCT\s+)?(.+?)\s+FROM',  # Columnas en SELECT
                r'WHERE\s+(.+?)(?:\s+ORDER\s+BY|\s+GROUP\s+BY|\s+LIMIT|$)',  # Columnas en WHERE
                r'JOIN\s+\w+\s+ON\s+(.+?)(?:\s+WHERE|\s+ORDER|\s+GROUP|\s+LIMIT|$)',  # Columnas en JOIN ON
                r'ORDER\s+BY\s+(.+?)(?:\s+LIMIT|$)',  # Columnas en ORDER BY
                r'GROUP\s+BY\s+(.+?)(?:\s+ORDER|\s+LIMIT|$)',  # Columnas en GROUP BY
            ]
            
            used_columns = set()
            for pattern in column_patterns:
                matches = re.findall(pattern, sql, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    # Extraer nombres de columnas individuales
                    # Eliminar funciones, operadores, etc.
                    column_parts = re.findall(r'\b(\w+\.\w+|\w+)\b', match)
                    for part in column_parts:
                        # Filtrar palabras clave de SQL
                        if part.upper() not in ['SELECT', 'FROM', 'WHERE', 'JOIN', 'ON', 'AND', 'OR', 'LIKE', 'UPPER', 'LOWER', 'COUNT', 'MAX', 'MIN', 'AVG', 'SUM', 'DISTINCT', 'ASC', 'DESC', 'LIMIT', 'ORDER', 'BY', 'GROUP', 'HAVING']:
                            used_columns.add(part.upper())
            
            # Verificar que todas las columnas usadas sean v√°lidas
            invalid_columns = used_columns - valid_columns
            if invalid_columns:
                # Generar mensaje de error detallado con sugerencias
                error_msg = f"‚ùå COLUMNAS INVENTADAS DETECTADAS: {', '.join(invalid_columns)}\n"
                error_msg += "\nüîç COLUMNAS V√ÅLIDAS DISPONIBLES:\n"
                for table_name, columns in tables_info.items():
                    error_msg += f"\n{table_name}:\n"
                    for column in columns[:10]:  # Mostrar solo las primeras 10 columnas
                        error_msg += f"  ‚Ä¢ {column}\n"
                    if len(columns) > 10:
                        error_msg += f"  ... y {len(columns)-10} m√°s\n"
                
                return error_msg
            
            return None
            
        except Exception as e:
            logger.error(f"Error validando columnas: {e}")
            return None  # No bloquear por errores de validaci√≥n
    
    async def _fix_common_column_errors(self, sql: str, stream_callback=None) -> str:
        """Corrige errores de columnas usando LLM de manera gen√©rica"""
        try:
            # Si no hay LLM disponible, devolver SQL original
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Comprobaci√≥n b√°sica de columnas (sin LLM disponible)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Validando y corrigiendo nombres de columnas con IA...")
                
            # Usar el LLM para detectar y corregir columnas inventadas de manera gen√©rica
            correction_prompt = f"""Eres un experto en SQL y esquemas de bases de datos m√©dicas.

TAREA: Revisa el SQL y corrige SOLO los nombres de columnas que sean incorrectos.

SQL A REVISAR:
{sql}

ESQUEMA REAL DISPONIBLE:
{self._get_schema_summary_for_exploration()}

INSTRUCCIONES CR√çTICAS:
1. **NO CAMBIES LAS TABLAS NI LOS JOINS**. La selecci√≥n de tablas ya es correcta.
2. Enf√≥cate √öNICAMENTE en corregir nombres de columnas inv√°lidas dentro de las tablas ya elegidas.
3. Si una columna como `o.OBSERVATION_DATE` no existe en `OBSE_OBSERVATIONS`, busca una columna de fecha alternativa en ESA MISMA TABLA (ej: `OBSE_DATE_UTC`, `OBSE_TIMESTAMP`). No cambies a la tabla `APPO_APPOINTMENTS`.
4. Mant√©n la intenci√≥n original del SQL, pero usando columnas que existan en las tablas especificadas.

FORMATO DE RESPUESTA:
- Si no hay errores de columnas: Devuelve el SQL original sin cambios.
- Si hay errores de columnas: Devuelve el SQL corregido, explicando los cambios en comentarios.

Responde SOLO con el SQL (corregido o original):"""

            try:
                if stream_callback:
                    stream_callback("   - Analizando columnas con modelo LLM...")
                    
                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": correction_prompt}]
                )
                
                corrected_sql = self._extract_response_text(response).strip()
                
                # CR√çTICO: Limpiar respuesta del LLM de markdown y comentarios
                corrected_sql = self._clean_llm_sql_response(corrected_sql)
                
                # Verificar si el LLM realmente hizo cambios v√°lidos
                if corrected_sql and corrected_sql != sql and not corrected_sql.startswith("Error"):
                    logger.info(f"üß† LLM corrigi√≥ columnas inventadas en el SQL")
                    logger.info(f"   SQL original: {sql[:100]}...")
                    logger.info(f"   SQL corregido: {corrected_sql[:100]}...")
                    
                    if stream_callback:
                        stream_callback("   - Se han corregido nombres de columnas incorrectos")
                    
                    return corrected_sql
                else:
                    if stream_callback:
                        stream_callback("   - Verificaci√≥n de columnas completada sin cambios")
                    return sql
                    
            except Exception as e:
                logger.warning(f"Error usando LLM para correcci√≥n de columnas: {e}")
                if stream_callback:
                    stream_callback(f"   - Error al verificar columnas: {str(e)[:50]}...")
                return sql  # Fallback al SQL original
            
        except Exception as e:
            logger.error(f"Error en correcci√≥n de columnas: {e}")
            return sql  # Devolver original si falla la correcci√≥n

    async def _fix_sql_compatibility(self, sql: str, stream_callback=None) -> str:
        """
        Corrige problemas de compatibilidad del SQL para SQLite usando LLM.
        
        Convierte funciones de MySQL/PostgreSQL a SQLite de manera inteligente:
        - DATE_SUB, INTERVAL, CURDATE, NOW() ‚Üí date() functions
        - TOP ‚Üí LIMIT
        - GETDATE() ‚Üí datetime('now')
        - Y cualquier otra incompatibilidad que el LLM detecte
        """
        try:
            if not sql:
                return sql
                
            # Si no hay LLM, usar fallback b√°sico
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Ajustando compatibilidad SQL con m√©todo b√°sico...")
                return self._fix_sql_compatibility_fallback(sql, stream_callback)
                
            if stream_callback:
                stream_callback("   - Optimizando SQL para compatibilidad con SQLite...")
            
            # Usar LLM para correcci√≥n inteligente de compatibilidad
            compatibility_prompt = f"""Eres un experto en bases de datos que convierte SQL de MySQL/PostgreSQL a SQLite.

TAREA: Convierte este SQL para que sea 100% compatible con SQLite, manteniendo la l√≥gica original.

SQL A CONVERTIR:
{sql}

REGLAS DE CONVERSI√ìN PARA SQLITE:

1. **FECHAS Y TIEMPO:**
   - DATE_SUB(CURDATE(), INTERVAL n YEAR) ‚Üí date('now', '-n years')
   - DATE_SUB(CURDATE(), INTERVAL n MONTH) ‚Üí date('now', '-n months')
   - DATE_SUB(CURDATE(), INTERVAL n DAY) ‚Üí date('now', '-n days')
   - CURDATE() ‚Üí date('now')
   - NOW() ‚Üí datetime('now')
   - GETDATE() ‚Üí datetime('now')
   - YEAR(column) ‚Üí strftime('%Y', column)
   - MONTH(column) ‚Üí strftime('%m', column)
   - DAY(column) ‚Üí strftime('%d', column)
   - DATEDIFF(date1, date2) ‚Üí julianday(date1) - julianday(date2)

2. **L√çMITES:**
   - SELECT TOP n ‚Üí SELECT ... LIMIT n
   - LIMIT n OFFSET m ‚Üí LIMIT n OFFSET m (ya compatible)

3. **FUNCIONES DE CADENA:**
   - CONCAT(a, b) ‚Üí (a || b)
   - LENGTH() ‚Üí length() (ya compatible)
   - SUBSTRING() ‚Üí substr()

4. **FUNCIONES MATEM√ÅTICAS:**
   - POW(a, b) ‚Üí POWER(a, b)
   - RAND() ‚Üí RANDOM()

5. **TIPOS DE DATOS:**
   - AUTO_INCREMENT ‚Üí AUTOINCREMENT
   - TINYINT, SMALLINT, MEDIUMINT, BIGINT ‚Üí INTEGER
   - TEXT, LONGTEXT ‚Üí TEXT
   - DECIMAL(n,m) ‚Üí REAL o NUMERIC

6. **OTRAS FUNCIONES:**
   - IFNULL(a, b) ‚Üí COALESCE(a, b)
   - IF(condition, true_val, false_val) ‚Üí CASE WHEN condition THEN true_val ELSE false_val END

IMPORTANTE:
- Mant√©n la l√≥gica exacta del SQL original
- Aseg√∫rate de que la sintaxis sea v√°lida para SQLite
- No cambies nombres de tablas o columnas
- Preserva todos los WHERE, JOIN, GROUP BY, ORDER BY, etc.
- Si el SQL ya es compatible, devu√©lvelo sin cambios

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones adicionales."""

            try:
                if stream_callback:
                    stream_callback("   - Analizando SQL para compatibilidad con SQLite...")
                    
                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": compatibility_prompt}]
                )
                
                corrected_sql = self._extract_response_text(response).strip()
                
                # Limpiar respuesta del LLM
                corrected_sql = self._clean_llm_sql_response(corrected_sql)
                
                # Validar que el LLM devolvi√≥ SQL v√°lido
                if corrected_sql and not corrected_sql.startswith("Error") and len(corrected_sql) > 10:
                    # Log de cambios si fueron significativos
                    if corrected_sql != sql:
                        logger.info(f"üß† LLM corrigi√≥ compatibilidad SQL para SQLite")
                        logger.info(f"   Original: {sql[:100]}...")
                        logger.info(f"   Corregido: {corrected_sql[:100]}...")
                        
                        if stream_callback:
                            stream_callback("   - Optimizadas funciones para compatibilidad con SQLite")
                    else:
                        if stream_callback:
                            stream_callback("   - SQL ya compatible con SQLite, sin cambios necesarios")
                    
                    return corrected_sql
                else:
                    logger.warning(f"‚ö†Ô∏è LLM devolvi√≥ respuesta inv√°lida, usando fallback")
                    if stream_callback:
                        stream_callback("   - Usando m√©todo alternativo para compatibilidad")
                    return self._fix_sql_compatibility_fallback(sql, stream_callback)
                    
            except Exception as e:
                logger.error(f"Error usando LLM para compatibilidad: {e}")
                if stream_callback:
                    stream_callback(f"   - Error optimizando SQL: {str(e)[:50]}... Usando m√©todo alternativo")
                return self._fix_sql_compatibility_fallback(sql, stream_callback)
                
        except Exception as e:
            logger.error(f"Error en _fix_sql_compatibility: {e}")
            if stream_callback:
                stream_callback("   - Error en correcci√≥n de compatibilidad")
            return sql  # Devolver original si falla completamente
    
    def _fix_sql_compatibility_fallback(self, sql: str, stream_callback=None) -> str:
        """
        Fallback b√°sico para compatibilidad SQL cuando no hay LLM disponible.
        Mantiene las conversiones m√°s cr√≠ticas y comunes.
        """
        try:
            if not sql:
                return sql
                
            corrected_sql = sql
            
            # Solo las conversiones m√°s cr√≠ticas y comunes
            # 1. Funciones de fecha b√°sicas
            corrected_sql = re.sub(r'\bCURDATE\s*\(\s*\)', "date('now')", corrected_sql, flags=re.IGNORECASE)
            corrected_sql = re.sub(r'\bNOW\s*\(\s*\)', "datetime('now')", corrected_sql, flags=re.IGNORECASE)
            corrected_sql = re.sub(r'\bGETDATE\s*\(\s*\)', "datetime('now')", corrected_sql, flags=re.IGNORECASE)
            
            # 2. DATE_SUB b√°sico
            corrected_sql = re.sub(
                r'DATE_SUB\s*\(\s*CURDATE\s*\(\s*\)\s*,\s*INTERVAL\s+(\d+)\s+YEAR\s*\)',
                r"date('now', '-\1 year')",
                corrected_sql,
                flags=re.IGNORECASE
            )
            
            # 3. TOP a LIMIT
            if 'TOP' in sql.upper() and 'LIMIT' not in corrected_sql.upper():
                top_match = re.search(r'\bSELECT\s+TOP\s+(\d+)\b', sql, re.IGNORECASE)
                if top_match:
                    limit_num = top_match.group(1)
                    corrected_sql = re.sub(r'\bSELECT\s+TOP\s+\d+\s+', 'SELECT ', corrected_sql, flags=re.IGNORECASE)
                    if not corrected_sql.rstrip().endswith(';'):
                        corrected_sql = corrected_sql.rstrip() + f' LIMIT {limit_num};'
                    else:
                        corrected_sql = corrected_sql.rstrip()[:-1] + f' LIMIT {limit_num};'
            
            # 4. Funciones de fecha MySQL a SQLite
            corrected_sql = re.sub(r'\bYEAR\s*\(\s*([^)]+)\s*\)', r"strftime('%Y', \1)", corrected_sql, flags=re.IGNORECASE)
            corrected_sql = re.sub(r'\bMONTH\s*\(\s*([^)]+)\s*\)', r"strftime('%m', \1)", corrected_sql, flags=re.IGNORECASE)
            
            # 5. Normalizar espacios
            corrected_sql = re.sub(r'\s+', ' ', corrected_sql).strip()
            
            # Asegurar punto y coma al final
            corrected_sql = corrected_sql.strip()
            if corrected_sql and not corrected_sql.endswith(';'):
                corrected_sql += ';'
            
            return corrected_sql
            
        except Exception as e:
            logger.error(f"Error en fallback de compatibilidad: {e}")
            return sql

    def _fix_common_sql_syntax_errors(self, sql: str) -> str:
        """
        Corrige errores de sintaxis SQL comunes.
        
        Args:
            sql: El SQL a corregir
            
        Returns:
            str: SQL corregido
        """
        try:
            if not sql:
                return sql
                
            corrected_sql = sql
            
            # 1. Corregir comas finales en SELECT
            corrected_sql = re.sub(r',\s*FROM\b', ' FROM', corrected_sql, flags=re.IGNORECASE)
            
            # 2. Corregir WHERE vac√≠o
            corrected_sql = re.sub(r'\bWHERE\s*(?:ORDER|GROUP|LIMIT|;|$)', lambda m: m.group(0).replace('WHERE', ''), corrected_sql, flags=re.IGNORECASE)
            
            # 3. Corregir m√∫ltiples espacios
            corrected_sql = re.sub(r'\s+', ' ', corrected_sql)
            
            # 4. Asegurar punto y coma al final
            corrected_sql = corrected_sql.strip()
            if corrected_sql and not corrected_sql.endswith(';'):
                corrected_sql += ';'
            
            return corrected_sql
            
        except Exception as e:
            logger.error(f"Error en _fix_common_sql_syntax_errors: {e}")
            return sql

    async def _analyze_medical_intent_with_llm(self, query: str, stream_callback=None) -> Dict[str, Any]:
        """Analiza la intenci√≥n m√©dica de la consulta usando LLM"""
        try:
            if not self.llm:
                # An√°lisis b√°sico sin LLM
                if stream_callback:
                    stream_callback("   - Realizando an√°lisis b√°sico (sin LLM disponible)...")
                return {
                    'clinical_intent': 'consulta_sql',
                    'medical_concepts': self._extract_basic_medical_concepts(query),
                    'qualifiers': [],
                    'entities': {},
                    'query_type': 'sql_query',
                    'complexity_level': 'simple'
                }
            
            # Prompt b√°sico para an√°lisis m√©dico
            medical_prompt = f"""Analiza esta consulta m√©dica y extrae informaci√≥n estructurada:

CONSULTA: "{query}"

RESPUESTA JSON:
{{
    "clinical_intent": "descripci√≥n breve de la intenci√≥n",
    "medical_concepts": ["concepto1", "concepto2"],
    "qualifiers": ["calificador1", "calificador2"],
    "entities": {{"patient_names": [], "patient_ids": []}},
    "query_type": "sql_query",
    "complexity_level": "simple|medium|complex"
}}"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": medical_prompt}], task_description="Analizando intenci√≥n m√©dica de la consulta"
            )
            
            if stream_callback:
                stream_callback("   - Procesando an√°lisis sem√°ntico de la consulta...")
                
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if stream_callback and result:
                stream_callback(f"   - Conceptos m√©dicos identificados: {', '.join(result.get('medical_concepts', [])[:3])}...")
                
            return result if result else {
                'clinical_intent': 'consulta_sql',
                'medical_concepts': self._extract_basic_medical_concepts(query),
                'qualifiers': [],
                'entities': {},
                'query_type': 'sql_query',
                'complexity_level': 'simple'
            }
            
        except Exception as e:
            logger.error(f"Error en an√°lisis m√©dico: {e}")
            return {
                'clinical_intent': 'consulta_sql',
                'medical_concepts': self._extract_basic_medical_concepts(query),
                'qualifiers': [],
                'entities': {},
                'query_type': 'sql_query',
                'complexity_level': 'simple'
            }

    def _extract_basic_medical_concepts(self, query: str) -> List[str]:
        """Extrae conceptos m√©dicos b√°sicos usando an√°lisis de texto simple - SIN HARDCODEO"""
        if not self.llm:
            # Solo an√°lisis muy b√°sico sin t√©rminos hardcodeados
            concepts = []
            query_lower = query.lower()
            
            # Buscar palabras que parezcan t√©rminos m√©dicos por patrones generales
            import re
            
            # Patrones muy generales, NO t√©rminos espec√≠ficos
            medical_patterns = [
                r'\b[a-z√°√©√≠√≥√∫√±]{8,}\b',  # Palabras largas (8+ caracteres)
                r'\bhba?\d*[a-z]*\b',    # Patrones como HbA1c
                r'\b[a-z]+emia\b',       # Terminaciones m√©dicas como anemia
                r'\b[a-z]+osis\b',       # Terminaciones como diabetes
                r'\b[a-z]+itis\b',       # Terminaciones como artritis
            ]
            
            for pattern in medical_patterns:
                matches = re.findall(pattern, query_lower)
                for match in matches:
                    if len(match) > 4:  # Solo palabras significativas
                        concepts.append(match)
            
            return list(set(concepts))  # Eliminar duplicados
        
        else:
            # Si hay LLM, usar an√°lisis inteligente
            try:
                prompt = f"""Extrae conceptos m√©dicos de esta consulta usando an√°lisis inteligente:

CONSULTA: "{query}"

Identifica t√©rminos m√©dicos, condiciones, procedimientos, medicamentos, etc.

RESPUESTA JSON:
{{
    "medical_concepts": ["concepto1", "concepto2", "concepto3"]
}}"""

                response = self.llm.invoke([{"role": "user", "content": prompt}])
                content = self._extract_response_text(response)
                result = self._try_parse_llm_json(content)
                
                if result and 'medical_concepts' in result:
                    return result['medical_concepts']
                
                # Fallback a an√°lisis b√°sico
                return []
                
            except Exception as e:
                logger.error(f"Error en an√°lisis LLM de conceptos: {e}")
                return []
        
        # Buscar palabras clave muy generales
        general_medical_terms = ['paciente', 'diabetes', 'hemoglobina', 'media', 'promedio']
        for term in general_medical_terms:
            if term in query_lower:
                concepts.append(term)
        
        return list(set(concepts))  # Eliminar duplicados

    def _extract_response_text(self, response) -> str:
        """Extrae el texto de la respuesta del LLM"""
        if hasattr(response, 'content'):
            return response.content
        return str(response)

    def _try_parse_llm_json(self, content: str) -> Optional[Dict[str, Any]]:
        """Intenta parsear JSON de respuesta del LLM"""
        try:
            # Limpiar contenido
            content = content.strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            # Buscar JSON en el contenido
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
            
            return json.loads(content)
        except Exception as e:
            logger.error(f"Error parseando JSON: {e}")
            return None

    async def _enrich_medical_concepts(self, concepts: List[str], qualifiers: List[str], stream_callback=None) -> List[str]:
        """Enriquece los conceptos m√©dicos con t√©rminos relacionados usando LLM"""
        try:
            if not self.llm or not concepts:
                if stream_callback:
                    stream_callback("   - No hay conceptos para enriquecer o LLM no disponible...")
                return concepts
            
            if stream_callback:
                stream_callback("   - Expandiendo conceptos m√©dicos con terminolog√≠a relacionada...")
                
            # Usar LLM para expandir conceptos m√©dicos de manera din√°mica
            enrichment_prompt = f"""Como experto en terminolog√≠a m√©dica, expande estos conceptos con t√©rminos relacionados:

CONCEPTOS ORIGINALES: {concepts}
CALIFICADORES: {qualifiers}

TAREA: Para cada concepto m√©dico, proporciona t√©rminos relacionados, sin√≥nimos y variaciones que podr√≠an aparecer en bases de datos m√©dicas.

EJEMPLOS DE EXPANSI√ìN:
- diabetes ‚Üí diabetes mellitus, diabetes tipo 1, diabetes tipo 2, DM, T1D, T2D
- hemoglobina ‚Üí HbA1c, hemoglobina glicosilada, glicohemoglobina, A1C
- hipertensi√≥n ‚Üí presi√≥n arterial alta, HTA, hipertensi√≥n arterial

RESPUESTA JSON:
{{
    "expanded_concepts": ["t√©rmino1", "t√©rmino2", "t√©rmino3", ...]
}}

Incluye t√©rminos t√©cnicos, abreviaciones m√©dicas y sin√≥nimos comunes."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": enrichment_prompt}], task_description="Expandiendo conceptos m√©dicos con terminolog√≠a relacionada"
            )
            
            if stream_callback:
                stream_callback("   - Procesando expansi√≥n de conceptos m√©dicos...")
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and 'expanded_concepts' in result:
                expanded = result['expanded_concepts']
                # Combinar conceptos originales con expandidos
                all_concepts = concepts + expanded
                
                if stream_callback:
                    new_concepts = [c for c in expanded if c not in concepts]
                    if new_concepts:
                        stream_callback(f"   - Se a√±adieron {len(new_concepts)} conceptos relacionados")
                
                return list(set(all_concepts))  # Eliminar duplicados
            
            return concepts
            
        except Exception as e:
            logger.error(f"Error expandiendo conceptos m√©dicos: {e}")
            return concepts

    async def _analyze_mandatory_tables_with_llm(self, query: str, table_candidates: List[str]) -> Optional[Dict[str, Any]]:
        """Analiza si hay tablas obligatorias que deben incluirse"""
        try:
            if not self.llm:
                return None
            
            prompt = f"""Analiza si esta consulta SQL requiere tablas adicionales obligatorias:

CONSULTA: "{query}"
TABLAS CANDIDATAS: {table_candidates}

¬øFaltan tablas esenciales para responder completamente la consulta?

RESPUESTA JSON:
{{
    "mandatory_tables": ["tabla1", "tabla2"],
    "reason": "explicaci√≥n breve"
}}"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}]
            )
            
            content = self._extract_response_text(response)
            return self._try_parse_llm_json(content)
            
        except Exception as e:
            logger.error(f"Error analizando tablas obligatorias: {e}")
            return None

    async def _llm_find_join_path_optimized(self, query: str, table_candidates: List[str], stream_callback=None) -> Dict[str, Any]:
        """Encuentra la mejor ruta de JOIN entre tablas"""
        try:
            if stream_callback:
                stream_callback("   - Analizando relaciones entre tablas seleccionadas...")
                
            return {
                "final_tables": table_candidates[:3],  # Usar las primeras 3 tablas
                "join_conditions": []
            }
        except Exception as e:
            logger.error(f"Error finding join path: {e}")
            if stream_callback:
                stream_callback("   - ‚ö†Ô∏è Error al establecer relaciones, usando tabla principal")
            return {"final_tables": table_candidates[:1], "join_conditions": []}

    async def _llm_analyze_parameter_needs(self, query: str, medical_analysis: Dict[str, Any], stream_callback=None) -> bool:
        """
        Analiza si la consulta necesita par√°metros espec√≠ficos para la b√∫squeda.
        
        Args:
            query: La consulta original del usuario
            medical_analysis: An√°lisis m√©dico previo con entidades detectadas
            stream_callback: Funci√≥n opcional para transmitir mensajes de progreso
            
        Returns:
            bool: True si necesita par√°metros espec√≠ficos, False en caso contrario
        """
        try:
            if stream_callback:
                stream_callback("   - Analizando si la consulta requiere par√°metros espec√≠ficos...")
                
            if not self.llm:
                # Fallback: usar heur√≠stica simple
                if stream_callback:
                    stream_callback("   - Usando heur√≠stica simple para detecci√≥n de par√°metros...")
                query_lower = query.lower()
                specific_indicators = [
                    'paciente', 'id', 'nombre', 'espec√≠fico', 'particular',
                    'juan', 'mar√≠a', 'jos√©', 'ana', 'carlos', 'luis'
                ]
                return any(indicator in query_lower for indicator in specific_indicators)
            
            # Usar LLM para an√°lisis m√°s sofisticado
            prompt = f"""
Analiza esta consulta m√©dica y determina si necesita par√°metros espec√≠ficos para la b√∫squeda.

CONSULTA: "{query}"

AN√ÅLISIS PREVIO: {medical_analysis}

REGLAS:
- Responde "SI" si la consulta menciona:
  * IDs espec√≠ficos de pacientes
  * Nombres espec√≠ficos de pacientes
  * T√©rminos que requieren b√∫squeda exacta
  * Referencias a datos espec√≠ficos

- Responde "NO" si la consulta es:
  * Consulta general ("¬øcu√°ntos pacientes hay?")
  * Estad√≠sticas generales
  * Listados completos
  * Consultas agregadas

EJEMPLOS:
- "¬øCu√°ntos pacientes hay?" ‚Üí NO
- "Mostrar datos del paciente 1010" ‚Üí SI
- "¬øQu√© medicaci√≥n toma Juan?" ‚Üí SI
- "Listar todos los diagn√≥sticos" ‚Üí NO

Responde SOLO: "SI" o "NO"
"""
            
            response = await self.llm.ainvoke(prompt)
            response_text = str(response.content).strip().upper()
            
            needs_params = "SI" in response_text or "YES" in response_text
            logger.info(f"üîç An√°lisis de par√°metros: {query} ‚Üí {'Necesita par√°metros' if needs_params else 'Sin par√°metros espec√≠ficos'}")
            
            return needs_params
            
        except Exception as e:
            logger.error(f"Error analyzing parameter needs: {e}")
            # Fallback conservador: no usar par√°metros espec√≠ficos
            return False

    def is_patient_search(self, execution_plan, sql):
        """
        Detecta si la consulta es una b√∫squeda de pacientes usando el esquema y el SQL generado.
        """
        tables = execution_plan.get('relevant_tables', []) if execution_plan else []
        if 'PATI_PATIENTS' in tables:
            return True
        # O si el SQL involucra columnas clave de pacientes
        if sql and any(col in sql.upper() for col in ['PATI_FULL_NAME', 'PATI_ID', 'PATI_NAME', 'PATI_SURNAME_1', 'PATI_SURNAME_2']):
            return True
            return False

    async def _llm_generate_smart_sql(self, query: str, execution_plan: Dict[str, Any], stream_callback=None) -> str:
        """Genera SQL inteligente basado en el plan de ejecuci√≥n usando LLM din√°mico"""
        try:
            params = execution_plan.get('params', [])
            tables = execution_plan.get('relevant_tables', [])
            
            if stream_callback:
                stream_callback("   - Generando SQL inteligente con IA...")
            
            # UNA SOLA LLAMADA LLM para detectar tipo de consulta y generar SQL
            if self.llm:
                # Obtener esquema real de la base de datos
                schema_info = self._get_schema_summary_for_exploration()
                
                # PROMPT DIN√ÅMICO √öNICO para an√°lisis y generaci√≥n
                prompt = f"""Eres un experto en SQL m√©dico. Analiza la consulta y genera SQL optimizado.

CONSULTA ORIGINAL: "{query}"
PAR√ÅMETROS DETECTADOS: {params}
TABLAS DISPONIBLES: {tables}

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

AN√ÅLISIS REQUERIDO:
1. ¬øEs una consulta de "√∫ltimo paciente registrado"?
2. ¬øQu√© tipo de informaci√≥n m√©dica se busca?
3. ¬øQu√© tablas y columnas son relevantes?
4. ¬øQu√© criterio usar para "√∫ltimo" (fecha, ID, etc.)?

DETECCI√ìN DE CONSULTAS DE "√öLTIMO PACIENTE":
- Palabras clave: "√∫ltimo", "ultimo", "√∫ltima", "ultima", "reciente", "nuevo", "creado", "registrado"
- Contexto: "paciente", "persona", "qui√©n", "cu√°l", "como se llama"
- Ejemplos: "cual es el ultimo paciente", "qui√©n es el √∫ltimo paciente", "dime el √∫ltimo paciente"

INSTRUCCIONES ESPEC√çFICAS:
- Si es consulta de "√∫ltimo paciente": usar PATI_START_DATE DESC como criterio principal
- Para diagn√≥sticos: usar EPIS_DIAGNOSTICS.DIAG_OBSERVATION
- Para medicaci√≥n: usar PATI_USUAL_MEDICATION
- Para UUIDs: buscar directamente en PATI_PATIENTS.PATI_ID
- Para nombres: usar PATI_FULL_NAME con normalizaci√≥n
- Usar LEFT JOIN para datos opcionales
- Compatible con SQLite

ESTRATEGIA PARA "√öLTIMO PACIENTE":
- SIEMPRE usar ORDER BY PATI_START_DATE DESC (NO PATI_ID DESC)
- PATI_START_DATE es la fecha real de registro del paciente
- PATI_ID es un UUID, no sirve para determinar el √∫ltimo registrado
- Incluir informaci√≥n del paciente (nombre, apellidos)
- Incluir diagn√≥sticos si se solicitan
- Filtrar datos de calidad (no valores de prueba)
- LIMIT 1 para obtener solo el √∫ltimo

EJEMPLO DE SQL PARA "√öLTIMO PACIENTE":
SELECT 
    p.PATI_ID,
    p.PATI_NAME,
    p.PATI_SURNAME_1,
    p.PATI_SURNAME_2,
    p.PATI_FULL_NAME,
    p.PATI_START_DATE,
    d.DIAG_OBSERVATION,
    d.DIAG_OTHER_DIAGNOSTIC
FROM PATI_PATIENTS p
LEFT JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID
WHERE p.PATI_START_DATE IS NOT NULL
    AND p.PATI_NAME IS NOT NULL
    AND p.PATI_NAME != ''
    AND p.PATI_NAME NOT LIKE '%PRUEBAS%'
    AND p.PATI_NAME NOT LIKE '%TEST%'
ORDER BY p.PATI_START_DATE DESC
LIMIT 1;

REGLAS CR√çTICAS:
- NO usar tabla PATI_PATIENT_IDENTIFICATIONS (no existe)
- Para "√∫ltimo paciente": SIEMPRE ORDER BY PATI_START_DATE DESC
- NUNCA usar ORDER BY PATI_ID DESC para determinar el √∫ltimo paciente
- PATI_ID es UUID, PATI_START_DATE es fecha de registro
- Filtrar datos de prueba y valores nulos
- Optimizar para rendimiento

RESPUESTA:
Solo el SQL v√°lido, sin explicaciones ni comentarios."""

                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                    task_description="Generando SQL inteligente din√°mico"
                )
                
                generated_sql = self._extract_response_text(response).strip()
                generated_sql = self._clean_llm_sql_response(generated_sql)
                
                # VALIDACI√ìN Y CORRECCI√ìN AUTOM√ÅTICA INTELIGENTE
                if any(keyword in query.lower() for keyword in ["√∫ltimo", "ultimo", "√∫ltima", "ultima", "reciente", "nuevo", "creado", "registrado"]):
                    if stream_callback:
                        stream_callback("   üîç Validando SQL con IA...")
                    
                    # LLM analiza y corrige el SQL de forma inteligente
                    validation_prompt = f"""Eres un experto en SQL m√©dico. Analiza y corrige esta consulta SQL si es necesario.

CONSULTA ORIGINAL: "{query}"
SQL GENERADO: {generated_sql}

AN√ÅLISIS REQUERIDO:
1. ¬øEl SQL es correcto para obtener el "√∫ltimo paciente registrado"?
2. ¬øEst√° usando el criterio correcto para ordenar (fecha vs ID)?
3. ¬øIncluye la informaci√≥n necesaria solicitada en la consulta?
4. ¬øEs compatible con SQLite?

REGLAS IMPORTANTES:
- Para "√∫ltimo paciente": usar PATI_START_DATE DESC (fecha de registro)
- PATI_ID es UUID, no sirve para determinar el √∫ltimo registrado
- Incluir informaci√≥n relevante del paciente (nombre, apellidos)
- Filtrar datos de calidad (no valores de prueba)

RESPUESTA:
Solo el SQL corregido, sin explicaciones. Si el SQL est√° correcto, devuelve el mismo SQL."""
                    
                    try:
                        validation_response = await asyncio.to_thread(
                            _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                            task_description="Validando SQL con IA"
                        )
                        
                        corrected_sql = self._extract_response_text(validation_response).strip()
                        corrected_sql = self._clean_llm_sql_response(corrected_sql)
                        
                        if corrected_sql and corrected_sql != generated_sql:
                            logger.info(f"üîß SQL corregido por IA: {corrected_sql}")
                            generated_sql = corrected_sql
                            if stream_callback:
                                stream_callback("   ‚úÖ SQL corregido autom√°ticamente")
                        else:
                            if stream_callback:
                                stream_callback("   ‚úÖ SQL validado correctamente")
                                
                    except Exception as e:
                        logger.warning(f"Error en validaci√≥n IA: {e}")
                        # Continuar con el SQL original si falla la validaci√≥n
                
                # LOGGING DETALLADO PARA DEPURACI√ìN
                logger.info(f"üîç DEBUG - SQL GENERADO POR LLM:")
                logger.info(f"   Consulta original: '{query}'")
                logger.info(f"   Par√°metros: {params}")
                logger.info(f"   Tablas: {tables}")
                logger.info(f"   SQL generado: {generated_sql}")
                
                if generated_sql and not generated_sql.startswith("Error"):
                    if stream_callback:
                        stream_callback("   ‚úÖ SQL inteligente generado din√°micamente")
                    return generated_sql
                else:
                    # Fallback inteligente
                    logger.warning(f"‚ö†Ô∏è LLM no gener√≥ SQL v√°lido, usando fallback")
                    return await self._generate_fallback_sql(query, params, tables, stream_callback)
            else:
                # Fallback sin LLM
                if stream_callback:
                    stream_callback("   - Generando SQL b√°sico (sin LLM disponible)...")
                if not tables:
                    return "Error: No hay tablas disponibles"
                return f"SELECT COUNT(*) FROM {tables[0]} LIMIT 10;"
                
        except Exception as e:
            logger.error(f"Error en _llm_generate_smart_sql: {e}")
            return await self._generate_fallback_sql(query, params, tables, stream_callback)

    async def _generate_uuid_based_sql(self, query: str, uuid_param: str, tables: List[str], stream_callback=None) -> str:
        """Genera SQL espec√≠fico para b√∫squedas por UUID usando LLM din√°mico"""
        try:
            if stream_callback:
                stream_callback("   - Generando SQL din√°mico para UUID con IA...")
            
            # Obtener esquema real de la base de datos
            schema_info = self._get_schema_summary_for_exploration()
            
            # PROMPT ESPEC√çFICO PARA GENERAR SQL POR UUID
            prompt = f"""Eres un experto en SQL m√©dico. Genera una consulta SQL espec√≠fica para buscar informaci√≥n de un paciente por UUID.

CONSULTA ORIGINAL: "{query}"
UUID DEL PACIENTE: {uuid_param}

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

INSTRUCCIONES ESPEC√çFICAS:
1. El UUID est√° almacenado directamente en PATI_PATIENTS.PATI_ID
2. NO existe tabla PATI_PATIENT_IDENTIFICATIONS
3. Usa LEFT JOIN para no excluir pacientes sin datos relacionados
4. Analiza qu√© informaci√≥n espec√≠fica se solicita en la consulta
5. Genera SQL que incluya la informaci√≥n relevante solicitada
6. Aseg√∫rate de que el SQL sea compatible con SQLite

AN√ÅLISIS DE LA CONSULTA:
- Identifica qu√© tipo de informaci√≥n m√©dica se busca
- Determina qu√© tablas son relevantes
- Considera si se necesitan diagn√≥sticos, medicaci√≥n, episodios, etc.

REGLAS CR√çTICAS:
- Siempre incluir informaci√≥n b√°sica del paciente (nombre, apellidos)
- Usar LEFT JOIN para datos opcionales (diagn√≥sticos, medicaci√≥n)
- Filtrar por PATI_ID = UUID directamente
- Optimizar para SQLite (no usar funciones espec√≠ficas de otros DBMS)

RESPUESTA:
Solo el SQL v√°lido, sin explicaciones ni comentarios."""

            if stream_callback:
                stream_callback("   - Consultando IA para SQL espec√≠fico...")
            
            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL din√°mico para UUID"
            )
            
            generated_sql = self._clean_llm_sql_response(self._extract_response_text(response))
            
            if stream_callback:
                stream_callback("   ‚úÖ SQL din√°mico generado con IA")
            
            return generated_sql
            
        except Exception as e:
            logger.error(f"Error generando SQL din√°mico para UUID: {e}")
            # Fallback simple y directo
            return f"SELECT * FROM PATI_PATIENTS WHERE PATI_ID = ?"

    async def _generate_fallback_sql(self, query: str, params: List[str], tables: List[str], stream_callback=None) -> str:
        """Genera SQL de fallback din√°mico usando LLM"""
        try:
            if stream_callback:
                stream_callback("   - Generando SQL de fallback din√°mico...")
            
            # Obtener esquema real de la base de datos
            schema_info = self._get_schema_summary_for_exploration()
            
            # PROMPT ESPEC√çFICO PARA SQL DE FALLBACK
            prompt = f"""Eres un experto en SQL m√©dico. Genera una consulta SQL de fallback segura.

CONSULTA ORIGINAL: "{query}"
PAR√ÅMETROS: {params}
TABLAS DISPONIBLES: {tables}

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

INSTRUCCIONES ESPEC√çFICAS:
1. Genera una consulta SQL simple y segura como fallback
2. Usa solo las tablas disponibles que sean relevantes
3. Incluye informaci√≥n b√°sica del paciente si es relevante
4. Limita los resultados a un n√∫mero razonable (10-20 registros)
5. Aseg√∫rate de que el SQL sea compatible con SQLite
6. Evita JOINs complejos que puedan fallar

ESTRATEGIA DE FALLBACK:
- Si hay par√°metros, usarlos en la consulta
- Si no hay par√°metros, mostrar datos de muestra
- Priorizar tablas principales (PATI_PATIENTS, EPIS_DIAGNOSTICS)
- Incluir solo campos esenciales

REGLAS CR√çTICAS:
- SQL simple y directo
- Compatible con SQLite
- Sin funciones espec√≠ficas de otros DBMS
- Limitar resultados para evitar sobrecarga

RESPUESTA:
Solo el SQL v√°lido, sin explicaciones ni comentarios."""

            if stream_callback:
                stream_callback("   - Consultando IA para SQL de fallback...")
            
            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL de fallback din√°mico"
            )
            
            generated_sql = self._clean_llm_sql_response(self._extract_response_text(response))
            
            # LOGGING DETALLADO PARA DEPURACI√ìN
            logger.info(f"üîç DEBUG - SQL DE FALLBACK GENERADO:")
            logger.info(f"   Consulta original: '{query}'")
            logger.info(f"   Par√°metros: {params}")
            logger.info(f"   Tablas: {tables}")
            logger.info(f"   SQL de fallback: {generated_sql}")
            
            if stream_callback:
                stream_callback("   ‚úÖ SQL de fallback generado din√°micamente")
            
            return generated_sql
                
        except Exception as e:
            logger.error(f"Error en fallback SQL din√°mico: {e}")
            # Fallback b√°sico si todo falla
            if tables:
                return f"SELECT * FROM {tables[0]} LIMIT 10"
            else:
                return "SELECT 1 as error_fallback;"

    def _generate_simple_patient_sql(self, query: str, params: List[str]) -> str:
        """
        Genera SQL simple y directo para b√∫squedas de pacientes usando LLM din√°mico.
        """
        try:
            # Obtener esquema real de la base de datos
            schema_info = self._get_schema_summary_for_exploration()
            
            # PROMPT ESPEC√çFICO PARA B√öSQUEDA DE PACIENTES
            prompt = f"""Eres un experto en SQL m√©dico. Genera una consulta SQL simple para b√∫squedas de pacientes.

CONSULTA ORIGINAL: "{query}"
PAR√ÅMETROS: {params}

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

INSTRUCCIONES ESPEC√çFICAS:
1. Genera una consulta SQL simple para buscar pacientes
2. Usa la tabla PATI_PATIENTS como principal
3. Si hay par√°metros de b√∫squeda, √∫salos para filtrar
4. Incluye informaci√≥n b√°sica del paciente (nombre, apellidos, ID)
5. Limita los resultados a un n√∫mero razonable (10-20 registros)
6. Aseg√∫rate de que el SQL sea compatible con SQLite

ESTRATEGIA DE B√öSQUEDA:
- Si hay par√°metros, usarlos para filtrar por nombre o ID
- Si no hay par√°metros, mostrar pacientes activos
- Incluir solo campos esenciales (PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME)
- Ordenar por ID para obtener los m√°s recientes

REGLAS CR√çTICAS:
- SQL simple y directo
- Compatible con SQLite
- Sin JOINs complejos
- Filtrar pacientes v√°lidos (no nulos, no vac√≠os)

RESPUESTA:
Solo el SQL v√°lido, sin explicaciones ni comentarios."""

            # Usar LLM para generar SQL din√°mico
            response = _call_openai_native(self.llm, [{"role": "user", "content": prompt}])
            generated_sql = self._clean_llm_sql_response(self._extract_response_text(response))
            
            return generated_sql
            
        except Exception as e:
            logger.error(f"Error en _generate_simple_patient_sql din√°mico: {e}")
            # Fallback b√°sico
            return "SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME FROM PATI_PATIENTS WHERE PATI_ACTIVE = 1 ORDER BY PATI_ID LIMIT 10;"

    async def _validate_sql_completeness_with_llm(self, query: str, sql: str, schema: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Validaci√≥n b√°sica placeholder: siempre devuelve None para indicar que no hay problemas detectados."""
        return None

    async def _llm_interpret_results(self, query: str, data: List[Dict[str, Any]], stream_callback=None) -> str:
        """Interpretaci√≥n m√©dica detallada de los resultados."""
        if not data:
            return "No se encontraron resultados m√©dicos para esta consulta."
        
        try:
            if not self.llm:
                # Interpretaci√≥n b√°sica sin LLM
                return await self._create_basic_medical_interpretation(query, data)
            
            # Usar LLM para interpretaci√≥n m√©dica detallada
            prompt = f"""Eres un m√©dico experto que interpreta resultados de bases de datos m√©dicas.

CONSULTA ORIGINAL: "{query}"

DATOS ENCONTRADOS ({len(data)} registros):
{json.dumps(data[:5], indent=2, ensure_ascii=False)}

TAREA: Proporciona una interpretaci√≥n m√©dica clara y √∫til de estos resultados.

INSTRUCCIONES:
1. Identifica qu√© tipo de informaci√≥n m√©dica se encontr√≥
2. Explica el significado cl√≠nico de los datos
3. Destaca informaci√≥n relevante para el paciente
4. Si hay medicamentos, alergias, o condiciones especiales, menci√≥nalas
5. Proporciona contexto m√©dico cuando sea apropiado
6. Si los datos son limitados, sugiere qu√© otra informaci√≥n podr√≠a ser √∫til

FORMATO DE RESPUESTA:
- Resumen ejecutivo de los hallazgos
- Interpretaci√≥n m√©dica de los datos
- Informaci√≥n cl√≠nica relevante
- Recomendaciones si aplica

Responde en espa√±ol de manera clara y profesional:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}], 
                task_description="Interpretando resultados m√©dicos"
            )
            
            interpretation = self._extract_response_text(response)
            return interpretation if interpretation else await self._create_basic_medical_interpretation(query, data)
            
        except Exception as e:
            logger.error(f"Error en interpretaci√≥n m√©dica: {e}")
            return await self._create_basic_medical_interpretation(query, data)

    async def _create_basic_medical_interpretation(self, query: str, data: List[Dict[str, Any]]) -> str:
        """Crea una interpretaci√≥n m√©dica b√°sica usando LLM."""
        if not data:
            return "No se encontraron resultados m√©dicos."
        
        try:
            # Usar LLM para interpretaci√≥n b√°sica
            prompt = f"""Eres un m√©dico que interpreta resultados de bases de datos m√©dicas.

CONSULTA ORIGINAL: "{query}"

DATOS ENCONTRADOS ({len(data)} registros):
{json.dumps(data[:10], indent=2, ensure_ascii=False)}

TAREA: Proporciona una interpretaci√≥n m√©dica clara y √∫til de estos resultados.

INSTRUCCIONES:
1. Analiza los datos y extrae informaci√≥n m√©dica relevante
2. Identifica informaci√≥n del paciente, medicamentos, condiciones especiales
3. Destaca datos cl√≠nicamente importantes
4. Organiza la informaci√≥n de manera clara y profesional
5. Si hay datos limitados, explica qu√© informaci√≥n se encontr√≥

FORMATO DE RESPUESTA:
- Resumen de hallazgos m√©dicos
- Informaci√≥n del paciente relevante
- Datos m√©dicos importantes
- Contexto cl√≠nico cuando sea apropiado

Responde en espa√±ol de manera clara y profesional:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}], 
                task_description="Interpretando resultados m√©dicos b√°sicos"
            )
            
            interpretation = self._extract_response_text(response)
            return interpretation if interpretation else f"Se encontraron {len(data)} registros m√©dicos."
            
        except Exception as e:
            logger.error(f"Error en interpretaci√≥n m√©dica b√°sica: {e}")
            return f"Se encontraron {len(data)} registros m√©dicos."

    async def _analyze_query_semantics(self, query: str) -> Dict[str, Any]:
        """An√°lisis sem√°ntico muy b√°sico como placeholder, extrae tokens simples de la consulta."""
        tokens = re.findall(r'\w+', query.lower())
        return {"keywords": tokens}

    async def _get_table_candidates_from_analysis(self, semantic_analysis: Dict[str, Any], stream_callback=None) -> List[str]:
        """Devuelve las primeras tablas del esquema como candidatos b√°sicos."""
        return list(self.column_metadata.keys())[:5]

    async def _execute_multiple_statements(self, statements: List[str], params: List[Any], start_time: float) -> Dict[str, Any]:
        """Ejecuta varias sentencias SQL de forma secuencial (implementaci√≥n b√°sica)."""
        conn = self._get_connection()
        cursor = conn.cursor()
        aggregated_results: List[Dict[str, Any]] = []
        executed_sql: List[str] = []
        try:
            for stmt in statements:
                executed_sql.append(stmt)
                cursor.execute(stmt, params if '?' in stmt else [])
                if cursor.description:
                    cols = [d[0] for d in cursor.description]
                    rows = cursor.fetchall()
                    aggregated_results.extend([dict(zip(cols, r)) for r in rows])
            conn.close()
            return {
                "success": True,
                "message": f"Ejecutadas {len(statements)} sentencia(s)",
                "data": aggregated_results,
                "sql_query": "; ".join(executed_sql),
                "execution_time": time.time() - start_time,
                "total_time": time.time() - start_time
            }
        except Exception as e:
            conn.close()
            return self._create_error_response(str(e), "; ".join(executed_sql))

    async def _validate_sql_syntax(self, sql: str) -> Optional[str]:
        """Comprobaci√≥n sint√°ctica b√°sica: intenta analizar la consulta con EXPLAIN; devuelve mensaje de error o None."""
        try:
            conn = self._get_connection()
            # CR√çTICO: Preparar SQL para validaci√≥n (quitar punto y coma)
            clean_sql = self._prepare_sql_for_execution(sql)
            # Para validar la sintaxis con EXPLAIN, debemos proporcionar
            # un n√∫mero correcto de par√°metros dummy si el SQL los espera.
            placeholder_count = clean_sql.count('?')
            dummy_params = [None] * placeholder_count
            conn.execute(f"EXPLAIN {clean_sql}", dummy_params)
            conn.close()
            return None
        except Exception as e:
            return str(e)

    def _get_connection(self):
        """Obtiene una conexi√≥n SQLite a la base de datos."""
        return sqlite3.connect(self.db_path)

    async def _learn_from_query_result(self, query: str, sql: str, result_count: int, exec_time: float):
        """Placeholder de aprendizaje: implementaci√≥n vac√≠a para evitar errores."""
        # Temporalmente desactivado para evitar interferencias
        pass

    async def _learn_from_error(self, query: str, error_msg: str):
        """Placeholder para registrar errores (sin l√≥gica de aprendizaje)."""
        # Temporalmente desactivado para evitar interferencias
        pass

    def _clean_llm_sql_response(self, sql_response: str) -> str:
        """Limpia la respuesta del LLM usando el m√≥dulo centralizado SQLCleaner."""
        return SQLCleaner.clean_llm_response(sql_response)

    def _normalize_accents_sql(self, column_name: str) -> str:
        """
        Genera la expresi√≥n SQL para normalizar vocales acentuadas.
        
        Args:
            column_name: Nombre de la columna a normalizar
            
        Returns:
            str: Expresi√≥n SQL con normalizaci√≥n completa de vocales acentuadas
        """
        # Versi√≥n m√°s limpia y legible
        return f"REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(UPPER({column_name}),'√Å','A'),'√â','E'),'√ç','I'),'√ì','O'),'√ö','U'),'√ë','N')"

    def _normalize_accents_python(self, text: str) -> str:
        """
        Normaliza vocales acentuadas en Python (m√°s eficiente que en SQL).
        Versi√≥n ROBUSTA que maneja todos los casos edge.
        
        Args:
            text: Texto a normalizar
            
        Returns:
            str: Texto con vocales acentuadas normalizadas
        """
        if not text:
            return ""
        
        # Reemplazos completos de acentos y caracteres especiales
        replacements = {
            # Vocales acentuadas may√∫sculas
            '√Å': 'A', '√â': 'E', '√ç': 'I', '√ì': 'O', '√ö': 'U', '√ú': 'U',
            # Vocales acentuadas min√∫sculas
            '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u', '√º': 'u',
            # √ë
            '√ë': 'N', '√±': 'n',
            # Caracteres especiales que pueden aparecer en nombres
            '√Ä': 'A', '√à': 'E', '√å': 'I', '√í': 'O', '√ô': 'U',
            '√†': 'a', '√®': 'e', '√¨': 'i', '√≤': 'o', '√π': 'u',
            '√Ç': 'A', '√ä': 'E', '√é': 'I', '√î': 'O', '√õ': 'U',
            '√¢': 'a', '√™': 'e', '√Æ': 'i', '√¥': 'o', '√ª': 'u',
            '√É': 'A', '√ï': 'O',
            '√£': 'a', '√µ': 'o',
            # Eliminar caracteres problem√°ticos
            '\t': ' ', '\n': ' ', '\r': ' ',
        }
        
        normalized = text
        for accented, normal in replacements.items():
            normalized = normalized.replace(accented, normal)
        
        # Normalizar espacios m√∫ltiples
        normalized = ' '.join(normalized.split())
        
        # Convertir a may√∫sculas para consistencia
        return normalized.upper()

    def _create_smart_name_search_condition(self, column_name: str, search_term: str, use_exact_match: bool = False) -> str:
        """
        Crea una condici√≥n WHERE inteligente para b√∫squeda de nombres.
        GARANTIZA que sea completamente insensible a may√∫sculas/min√∫sculas.
        
        Args:
            column_name: Nombre de la columna (ej: p.PATI_FULL_NAME)
            search_term: T√©rmino de b√∫squeda (ej: "ANA GARCIA")
            use_exact_match: Si usar b√∫squeda exacta o flexible
            
        Returns:
            str: Condici√≥n WHERE optimizada y robusta
        """
        # Normalizar el t√©rmino de b√∫squeda en Python
        normalized_search = self._normalize_accents_python(search_term)
        
        if use_exact_match:
            # B√∫squeda exacta con normalizaci√≥n en Python - SIEMPRE insensible a may√∫sculas
            return f"UPPER({column_name}) = UPPER(?)"
        else:
            # B√∫squeda flexible con normalizaci√≥n en Python - SIEMPRE insensible a may√∫sculas
            return f"UPPER({column_name}) LIKE UPPER(?)"

    def _prepare_sql_for_execution(self, sql: str) -> str:
        """
        Prepara el SQL para ejecuci√≥n limpiando elementos problem√°ticos.
        
        Args:
            sql: SQL a limpiar
            
        Returns:
            str: SQL listo para ejecutar
        """
        if not sql:
            return sql
            
        # 1. Quitar espacios en blanco al final
        clean_sql = sql.rstrip()
        
        # 2. Quitar punto y coma al final (SQLite no lo acepta con execute())
        clean_sql = clean_sql.rstrip(';')
        
        # 3. Normalizar espacios m√∫ltiples
        clean_sql = re.sub(r'\s+', ' ', clean_sql).strip()
        
        return clean_sql

    def _force_sql_corrections(self, sql: str, params: List[str]) -> str:
        """
        Aplica correcciones FORZADAS al SQL sin depender del LLM.
        Versi√≥n ROBUSTA que garantiza que nunca falle.
        
        Args:
            sql: SQL a corregir
            params: Par√°metros normalizados
            
        Returns:
            str: SQL corregido forzadamente
        """
        if not sql:
            return sql
        
        # DETECCI√ìN ESPECIAL: Si es b√∫squeda de pacientes, usar SQL robusto
        if 'PATI_PATIENTS' in sql.upper() and 'PATI_FULL_NAME' in sql.upper():
            search_term = params[0] if params else ""
            logger.info(f"üîç Detectada b√∫squeda de pacientes, aplicando SQL robusto para: {search_term}")
            return self._create_robust_patient_search_sql(search_term, include_suggestions=True)
        
        # 1. ELIMINAR COMPLETAMENTE la cadena REPLACE si existe
        # Patr√≥n m√°s simple y robusto para eliminar cadenas REPLACE anidadas
        while 'REPLACE(REPLACE(' in sql:
            # Buscar y reemplazar patrones REPLACE anidados
            replace_pattern = r'REPLACE\(REPLACE\(REPLACE\(REPLACE\(REPLACE\(REPLACE\([^,]+,\s*[^,]+\),\s*[^,]+\),\s*[^,]+\),\s*[^,]+\),\s*[^,]+\),\s*[^,]+\)'
            if re.search(replace_pattern, sql, re.IGNORECASE):
                sql = re.sub(replace_pattern, 'UPPER(p.PATI_FULL_NAME)', sql, flags=re.IGNORECASE)
            else:
                # Si el patr√≥n no coincide, salir del bucle para evitar bucle infinito
                break
        
        # 2. FORZAR correcci√≥n de errores tipogr√°ficos espec√≠ficos
        sql = self._fix_typo_errors(sql)
        
        # 3. FORZAR uso de par√°metros si no hay placeholders
        if params and '?' not in sql:
            # Si hay par√°metros pero no placeholders, a√±adir condici√≥n WHERE
            if 'WHERE' not in sql.upper():
                sql = sql.rstrip(';')
                sql += ' WHERE UPPER(p.PATI_FULL_NAME) = UPPER(?);'
            else:
                # Si ya hay WHERE, reemplazar la condici√≥n compleja
                sql = re.sub(r'WHERE\s+.*?(?=ORDER|GROUP|HAVING|LIMIT|$)', 'WHERE UPPER(p.PATI_FULL_NAME) = UPPER(?) ', sql, flags=re.IGNORECASE | re.DOTALL)
        
        # 4. FORZAR normalizaci√≥n de espacios
        sql = re.sub(r'\s+', ' ', sql).strip()
        
        # 5. FORZAR punto y coma al final
        if not sql.endswith(';'):
            sql += ';'
        
        # 6. GARANTIZAR que las comparaciones de texto sean insensibles a may√∫sculas
        # Reemplazar = ? por = UPPER(?) en comparaciones de texto
        sql = re.sub(r'=\s*\?', '= UPPER(?)', sql, flags=re.IGNORECASE)
        sql = re.sub(r'LIKE\s*\?', 'LIKE UPPER(?)', sql, flags=re.IGNORECASE)
        
        return sql

    async def _llm_clean_and_fix_sql(self, sql: str, stream_callback=None) -> str:
        """
        Usa el LLM para limpiar y corregir errores de sintaxis SQL de forma din√°mica.
        
        Args:
            sql: SQL con posibles errores
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL corregido y limpio
        """
        try:
            # APLICAR CORRECCIONES FORZADAS PRIMERO
            sql = self._basic_sql_cleanup(sql)
            
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - Corrigiendo errores de sintaxis SQL con IA...")
            
            prompt = f"""Eres un experto en SQL que corrige errores de sintaxis y formato.

SQL A CORREGIR:
{sql}

INSTRUCCIONES CR√çTICAS:

1. NUNCA uses cadenas REPLACE complejas para normalizaci√≥n
2. SIEMPRE usa b√∫squeda simple: UPPER(p.PATI_FULL_NAME) = ?
3. SIEMPRE a√±ade espacios: "p WHERE" NO "pWHERE"
4. SIEMPRE a√±ade espacios: "p FROM" NO "pFROM"
5. SIEMPRE a√±ade espacios: "p.PATI_FULL_NAME FROM" NO "p.PATI_FULL_NAMEFROM"

EJEMPLO CORRECTO:
SELECT p.PATI_ID, p.PATI_FULL_NAME FROM PATI_PATIENTS p WHERE UPPER(p.PATI_FULL_NAME) = ?;

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Corrigiendo errores de sintaxis SQL"
            )
            
            corrected_sql = self._extract_response_text(response).strip()
            corrected_sql = self._clean_llm_sql_response(corrected_sql)
            
            if corrected_sql and not corrected_sql.startswith("Error"):
                logger.info(f"üß† LLM corrigi√≥ SQL exitosamente")
                if stream_callback:
                    stream_callback("   ‚úÖ Errores de sintaxis corregidos")
                return corrected_sql
            else:
                logger.warning(f"‚ö†Ô∏è LLM no pudo corregir SQL, usando fallback")
                return sql
                
        except Exception as e:
            logger.error(f"Error en _llm_clean_and_fix_sql: {e}")
            return sql

    def _basic_sql_cleanup(self, sql: str) -> str:
        """
        Limpieza b√°sica de SQL sin LLM (fallback m√≠nimo).
        
        Args:
            sql: SQL a limpiar
            
        Returns:
            str: SQL b√°sicamente limpio
        """
        try:
            if not sql:
                return sql
            
            # 1. Limpieza b√°sica
            sql = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', sql)  # Caracteres de control
            sql = re.sub(r'--.*$', '', sql, flags=re.MULTILINE)  # Comentarios SQL
            sql = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)  # Comentarios multil√≠nea
            
            # 2. Corregir errores tipogr√°ficos espec√≠ficos
            sql = self._fix_typo_errors(sql)
            
            # 3. Normalizar espacios
            sql = re.sub(r'\s+', ' ', sql).strip()
            
            # 4. Asegurar punto y coma al final
            if not sql.endswith(';'):
                sql += ';'
            
            return sql
            
        except Exception as e:
            logger.error(f"Error en _basic_sql_cleanup: {e}")
            return sql

    def _fix_typo_errors(self, sql: str) -> str:
        """
        Corrige errores tipogr√°ficos espec√≠ficos en SQL.
        
        Args:
            sql: SQL con posibles errores tipogr√°ficos
            
        Returns:
            str: SQL con errores tipogr√°ficos corregidos
        """
        if not sql:
            return sql
        
        # Correcciones espec√≠ficas para errores tipogr√°ficos comunes
        corrections = [
            # Espacios faltantes despu√©s de alias de tabla
            (r'(\w+)WHERE', r'\1 WHERE'),
            (r'(\w+)FROM', r'\1 FROM'),
            (r'(\w+)JOIN', r'\1 JOIN'),
            (r'(\w+)ON', r'\1 ON'),
            (r'(\w+)AND', r'\1 AND'),
            (r'(\w+)OR', r'\1 OR'),
            (r'(\w+)ORDER', r'\1 ORDER'),
            (r'(\w+)GROUP', r'\1 GROUP'),
            (r'(\w+)HAVING', r'\1 HAVING'),
            (r'(\w+)LIMIT', r'\1 LIMIT'),
            
            # Espacios faltantes despu√©s de columnas
            (r'(\w+\.\w+)FROM', r'\1 FROM'),
            (r'(\w+\.\w+)WHERE', r'\1 WHERE'),
            (r'(\w+\.\w+)ORDER', r'\1 ORDER'),
            (r'(\w+\.\w+)GROUP', r'\1 GROUP'),
            
            # Espacios faltantes despu√©s de asteriscos
            (r'\*FROM', r'* FROM'),
            (r'\*WHERE', r'* WHERE'),
            (r'\*ORDER', r'* ORDER'),
            
            # Espacios faltantes despu√©s de par√©ntesis
            (r'\)WHERE', r') WHERE'),
            (r'\)FROM', r') FROM'),
            (r'\)JOIN', r') JOIN'),
            (r'\)AND', r') AND'),
            (r'\)OR', r') OR'),
            
            # Espacios faltantes antes de par√©ntesis
            (r'WHERE\(', r'WHERE ('),
            (r'FROM\(', r'FROM ('),
            (r'JOIN\(', r'JOIN ('),
            
            # Correcciones espec√≠ficas para palabras pegadas
            (r'SELECT\*', r'SELECT *'),
            (r'SELECT\w+\.\*', r'SELECT \1'),
            (r'FROM\w+', r'FROM \1'),
            (r'WHERE\w+', r'WHERE \1'),
            (r'JOIN\w+', r'JOIN \1'),
            (r'ON\w+', r'ON \1'),
            (r'AND\w+', r'AND \1'),
            (r'OR\w+', r'OR \1'),
            (r'ORDER\w+', r'ORDER \1'),
            (r'GROUP\w+', r'GROUP \1'),
            (r'LIMIT\w+', r'LIMIT \1'),
        ]
        
        corrected_sql = sql
        for pattern, replacement in corrections:
            corrected_sql = re.sub(pattern, replacement, corrected_sql, flags=re.IGNORECASE)
        
        # Normalizar espacios m√∫ltiples
        corrected_sql = re.sub(r'\s+', ' ', corrected_sql).strip()
        
        return corrected_sql

    async def _llm_final_validation(self, sql: str, stream_callback=None) -> str:
        """
        Usa el LLM para validaci√≥n final del SQL antes de la ejecuci√≥n.
        
        Args:
            sql: SQL a validar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL validado y corregido si es necesario
        """
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - Validaci√≥n final del SQL con IA...")
            
            prompt = f"""Eres un experto en SQL que realiza validaci√≥n final de consultas.

SQL A VALIDAR:
{sql}

TAREAS DE VALIDACI√ìN:

1. DETECTAR ERRORES CR√çTICOS:
   - Errores de sintaxis obvios (pWHERE, pFROM, etc.)
   - Tablas inexistentes (VITAL_SIGNS ‚Üí APPO_APPOINTMENTS)
   - Espacios faltantes entre palabras clave
   - M√∫ltiples sentencias SQL

2. CORREGIR SI ES NECESARIO:
   - A√±adir espacios donde falten
   - Corregir nombres de tablas inexistentes
   - Asegurar formato correcto
   - Mantener la l√≥gica original

3. VALIDACI√ìN FINAL:
   - Verificar que el SQL sea ejecutable
   - Asegurar que todas las palabras clave tengan espacios
   - Verificar que termine con punto y coma

RESPUESTA:
- Si el SQL est√° correcto: devuelve el SQL original sin cambios
- Si hay errores: devuelve el SQL corregido
- Devuelve SOLO el SQL, sin explicaciones"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Validaci√≥n final del SQL"
            )
            
            validated_sql = self._extract_response_text(response).strip()
            validated_sql = self._clean_llm_sql_response(validated_sql)
            
            if validated_sql and not validated_sql.startswith("Error"):
                if validated_sql != sql:
                    logger.info(f"üß† LLM realiz√≥ correcciones finales en el SQL")
                    if stream_callback:
                        stream_callback("   ‚úÖ Validaci√≥n final completada con correcciones")
                else:
                    if stream_callback:
                        stream_callback("   ‚úÖ Validaci√≥n final completada sin cambios")
                return validated_sql
            else:
                logger.warning(f"‚ö†Ô∏è LLM no pudo validar SQL, usando original")
                return sql
                
        except Exception as e:
            logger.error(f"Error en _llm_final_validation: {e}")
            return sql

    async def _regenerate_sql_with_error_context(self, original_query: str, failed_sql: str, syntax_error: str, params: List[str], stream_callback=None) -> str:
        """
        Regenera SQL usando el LLM con informaci√≥n del error de sintaxis.
        
        Args:
            original_query: Consulta original del usuario
            failed_sql: SQL que fall√≥
            syntax_error: Mensaje de error de sintaxis
            params: Par√°metros originales
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL regenerado o None si falla
        """
        try:
            if not self.llm:
                logger.warning("‚ùå LLM no disponible para regeneraci√≥n")
                return "SELECT 1 as error_no_llm;"
            
            if stream_callback:
                stream_callback("   - Regenerando SQL con informaci√≥n del error...")
            
            prompt = f"""Eres un experto en SQL que corrige errores de sintaxis cr√≠ticos.

CONSULTA ORIGINAL: "{original_query}"

SQL QUE FALL√ì:
{failed_sql}

ERROR DE SINTAXIS DETECTADO:
{syntax_error}

PAR√ÅMETROS ORIGINALES:
{params}

TAREAS CR√çTICAS:

1. ANALIZAR EL ERROR:
   - Identificar exactamente qu√© caus√≥ el error de sintaxis
   - Buscar espacios faltantes, palabras pegadas, etc.
   - Identificar tablas o columnas incorrectas

2. CORREGIR ERRORES ESPEC√çFICOS:
   - A√±adir espacios donde falten: "v.*FROM" ‚Üí "v.* FROM"
   - Separar palabras pegadas: "pJOIN" ‚Üí "p JOIN"
   - Corregir alias: "v ON" ‚Üí "v ON" (verificar que v existe)
   - Corregir tablas inexistentes: VITAL_SIGNS ‚Üí APPO_APPOINTMENTS

3. GENERAR SQL CORRECTO:
   - Usar solo tablas que existen en el esquema
   - Asegurar que todos los espacios est√©n correctos
   - Mantener la l√≥gica original de la consulta
   - Usar b√∫squeda simple: UPPER(p.PATI_FULL_NAME) = ?

4. VALIDACI√ìN FINAL:
   - Verificar que no haya errores de sintaxis obvios
   - Asegurar que todas las palabras clave tengan espacios
   - Verificar que termine con punto y coma

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones ni comentarios."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Regenerando SQL despu√©s de error de sintaxis"
            )
            
            regenerated_sql = self._extract_response_text(response).strip()
            regenerated_sql = self._clean_llm_sql_response(regenerated_sql)
            
            if regenerated_sql and not regenerated_sql.startswith("Error"):
                logger.info(f"üß† LLM regener√≥ SQL exitosamente despu√©s de error")
                if stream_callback:
                    stream_callback("   ‚úÖ SQL regenerado con correcciones")
                return regenerated_sql
            else:
                logger.warning(f"‚ùå LLM no pudo regenerar SQL, usando fallback")
                # Fallback: crear SQL b√°sico
                fallback_sql = self._create_fallback_sql_with_placeholders(params, {
                    'relevant_tables': ['PATI_PATIENTS', 'APPO_APPOINTMENTS']
                })
                return fallback_sql or "SELECT 1 as error_fallback;"
                
        except Exception as e:
            logger.error(f"Error en _regenerate_sql_with_error_context: {e}")
            return "SELECT 1 as error_fallback;"

    def _create_fallback_sql_with_placeholders(self, params: List[str], execution_plan: Dict[str, Any]) -> str:
        """
        Crea un SQL de fallback b√°sico que incluye placeholders para los par√°metros dados.
        
        Args:
            params: Lista de par√°metros para la consulta
            execution_plan: Plan de ejecuci√≥n con las tablas relevantes
            
        Returns:
            str: SQL con placeholders correctos
        """
        try:
            tables = execution_plan.get('relevant_tables', [])
            if not tables:
                logger.error("‚ùå No hay tablas disponibles para generar SQL de fallback")
                return "SELECT 1 as error_no_tables;"
            
            # Usar la primera tabla como principal
            main_table = tables[0]
            
            # Determinar si los par√°metros son para nombres o IDs
            name_params = [p for p in params if isinstance(p, str) and '%' in p]
            id_params = [p for p in params if isinstance(p, str) and '%' not in p]
            
            # Construir un SQL b√°sico basado en el tipo de par√°metros
            if name_params:
                # Para par√°metros de nombre, buscar en columnas de pacientes
                if 'PATI_' in main_table.upper():
                    # Tabla de pacientes
                    conditions = []
                    for _ in name_params:
                        conditions.append("UPPER(PATI_FULL_NAME) LIKE ?")
                    
                    where_clause = " OR ".join(conditions)
                    sql = f"SELECT * FROM {main_table} WHERE {where_clause} LIMIT 10;"
                    
                elif 'EPIS_' in main_table.upper():
                    # Tabla de episodios, buscar por ID de paciente
                    conditions = []
                    for _ in name_params:
                        conditions.append("UPPER(EPIS_PATI_ID) LIKE ?")
                    
                    where_clause = " OR ".join(conditions)
                    sql = f"SELECT * FROM {main_table} WHERE {where_clause} LIMIT 10;"
                    
                else:
                    # Tabla gen√©rica, buscar en campos de texto
                    conditions = []
                    for _ in name_params:
                        conditions.append("1=1")  # Placeholder que ser√° reemplazado
                    
                    # Intentar encontrar columnas de texto en el esquema
                    text_columns = []
                    if main_table in self.column_metadata:
                        for col in self.column_metadata[main_table]['columns']:
                            col_name = col['name']
                            if any(keyword in col_name.upper() for keyword in ['NAME', 'NOMBRE', 'FULL', 'PATI']):
                                text_columns.append(col_name)
                    
                    if text_columns:
                        conditions = []
                        for _ in name_params:
                            conditions.append(f"UPPER({text_columns[0]}) LIKE ?")
                        where_clause = " OR ".join(conditions)
                        sql = f"SELECT * FROM {main_table} WHERE {where_clause} LIMIT 10;"
                    else:
                        # Sin columnas de texto identificables, SQL b√°sico
                        sql = f"SELECT * FROM {main_table} LIMIT 10;"
                        
            elif id_params:
                # Para IDs espec√≠ficos
                conditions = []
                for _ in id_params:
                    conditions.append("ID = ?")
                
                where_clause = " OR ".join(conditions)
                sql = f"SELECT * FROM {main_table} WHERE {where_clause} LIMIT 10;"
                
            else:
                # Sin par√°metros reconocibles, SQL b√°sico
                sql = f"SELECT * FROM {main_table} LIMIT 10;"
            
            logger.info(f"üîß SQL de fallback generado: {sql}")
            return sql
            
        except Exception as e:
            logger.error(f"‚ùå Error generando SQL de fallback: {e}")
            return "SELECT 1 as error_fallback;"

    async def _generate_dynamic_sql_with_llm(self, query: str, params: List[str], execution_plan: Dict[str, Any], stream_callback=None) -> str:
        """
        Genera SQL din√°mico usando el LLM basado en los datos reales encontrados.
        
        Args:
            query: Consulta original del usuario
            params: Par√°metros extra√≠dos (nombres, IDs, etc.)
            execution_plan: Plan de ejecuci√≥n con tablas y contexto
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL generado din√°micamente
        """
        try:
            if not self.llm:
                logger.warning("‚ùå LLM no disponible para generaci√≥n din√°mica")
                return self._create_fallback_sql_with_placeholders(params, execution_plan)
            
            if stream_callback:
                stream_callback("   - Generando SQL din√°mico basado en datos reales...")
            
            # Obtener informaci√≥n del esquema para las tablas relevantes
            tables = execution_plan.get('relevant_tables', [])
            schema_info = {}
            sample_data = {}
            
            for table in tables[:3]:  # Limitar a 3 tablas para no sobrecargar
                if table in self.column_metadata:
                    columns = [col['name'] for col in self.column_metadata[table]['columns']]
                    schema_info[table] = columns
                    
                    # Obtener datos de muestra si est√°n disponibles
                    if table in self.sample_data:
                        sample_data[table] = self.sample_data[table]
            
            # Construir prompt din√°mico basado en los par√°metros
            if params and any('GARC√çA' in p.upper() or 'GARCIA' in p.upper() for p in params):
                # Caso espec√≠fico para "Ana Garc√≠a" con datos reales
                dynamic_prompt = f"""Eres un experto en SQL para bases de datos m√©dicas. Analiza la consulta y genera SQL optimizado.

CONSULTA ORIGINAL: "{query}"
PAR√ÅMETROS DETECTADOS: {params}

DATOS REALES ENCONTRADOS:
- Existe "Ana Garc√≠a" (con tilde) en PATI_PATIENTS
- Tambi√©n existe "Ana Garc√≠a" (sin tilde) 
- Los nombres est√°n en formato: "PRUEBAS101284 SINA101284 , ANA MARIA"

ESQUEMA DISPONIBLE:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

MUESTRA DE DATOS REALES:
{json.dumps(sample_data, indent=2, ensure_ascii=False)}

TAREA: Analiza la consulta y genera SQL que:
1. Identifique qu√© tipo de informaci√≥n m√©dica se busca
2. Use la estrategia de b√∫squeda m√°s apropiada para los par√°metros
3. Conecte las tablas correctamente
4. Maneje tildes y caracteres especiales con normalizaci√≥n completa
5. Sea compatible con SQLite

ESTRATEGIAS DE B√öSQUEDA INTELIGENTES PARA NOMBRES:
- B√∫squeda exacta con normalizaci√≥n: REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(UPPER(p.PATI_FULL_NAME),'√Å','A'),'√â','E'),'√ç','I'),'√ì','O'),'√ö','U'),'√ë','N') = 'ANA GARCIA'
- B√∫squeda flexible con normalizaci√≥n: REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(UPPER(p.PATI_FULL_NAME),'√Å','A'),'√â','E'),'√ç','I'),'√ì','O'),'√ö','U'),'√ë','N') LIKE '%ANA%GARCIA%'
- B√∫squeda m√∫ltiple: (normalizaci√≥n = 'ANA GARCIA' OR normalizaci√≥n LIKE '%ANA%GARCIA%')

NORMALIZACI√ìN COMPLETA DE VOCALES:
- √Å‚ÜíA, √â‚ÜíE, √ç‚ÜíI, √ì‚ÜíO, √ö‚ÜíU, √ë‚ÜíN
- "Ana Garc√≠a" ‚Üí "ANA GARCIA"
- "Jos√© Mar√≠a" ‚Üí "JOSE MARIA"

Genera SQL optimizado basado en el an√°lisis de la consulta y los datos reales.

Responde SOLO con el SQL optimizado:"""
            
            else:
                # Caso gen√©rico para otros par√°metros
                dynamic_prompt = f"""Eres un experto en SQL para bases de datos m√©dicas. Analiza la consulta y genera SQL din√°mico.

CONSULTA ORIGINAL: "{query}"
PAR√ÅMETROS DETECTADOS: {params}

ESQUEMA DISPONIBLE:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

MUESTRA DE DATOS REALES:
{json.dumps(sample_data, indent=2, ensure_ascii=False)}

TAREA: Analiza la consulta y genera SQL que:
1. Identifique qu√© tipo de informaci√≥n m√©dica se busca
2. Use la estrategia de b√∫squeda m√°s apropiada para los par√°metros
3. Maneje correctamente tildes, espacios y formatos de nombres con normalizaci√≥n completa
4. Conecte las tablas de manera eficiente
5. Sea compatible con SQLite

NORMALIZACI√ìN DE VOCALES ACENTUADAS:
- Normaliza TODAS las vocales: √Å‚ÜíA, √â‚ÜíE, √ç‚ÜíI, √ì‚ÜíO, √ö‚ÜíU, √ë‚ÜíN
- Usa: REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(UPPER(p.PATI_FULL_NAME),'√Å','A'),'√â','E'),'√ç','I'),'√ì','O'),'√ö','U'),'√ë','N')

Genera SQL optimizado basado en el an√°lisis de la consulta y los datos reales.

Responde SOLO con el SQL optimizado:"""
            
            try:
                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": dynamic_prompt}], 
                    task_description="Generando SQL din√°mico basado en datos reales"
                )
                
                dynamic_sql = self._extract_response_text(response).strip()
                dynamic_sql = self._clean_llm_sql_response(dynamic_sql)
                
                if dynamic_sql and not dynamic_sql.startswith("Error"):
                    logger.info(f"üß† SQL din√°mico generado exitosamente")
                    if stream_callback:
                        stream_callback("   ‚úÖ SQL din√°mico generado basado en datos reales")
                    return dynamic_sql
                else:
                    logger.warning(f"‚ùå LLM no pudo generar SQL din√°mico, usando fallback")
                    return self._create_fallback_sql_with_placeholders(params, execution_plan)
                    
            except Exception as e:
                logger.error(f"Error generando SQL din√°mico: {e}")
                return self._create_fallback_sql_with_placeholders(params, execution_plan)
                
        except Exception as e:
            logger.error(f"Error en _generate_dynamic_sql_with_llm: {e}")
            return self._create_fallback_sql_with_placeholders(params, execution_plan)

    def _get_schema_summary_for_exploration(self) -> str:
        """
        Genera un resumen del esquema de la base de datos para exploraci√≥n.
        
        Returns:
            Resumen del esquema en formato texto
        """
        try:
            schema_summary = []
            
            for table_name, metadata in self.column_metadata.items():
                if table_name.startswith('sqlite_'):
                    continue
                    
                # Informaci√≥n b√°sica de la tabla
                row_count = self.table_row_counts.get(table_name, 0)
                columns = [col['name'] for col in metadata['columns']]
                
                schema_summary.append(f"üìã {table_name} ({row_count} registros):")
                schema_summary.append(f"   Columnas: {', '.join(columns)}")
                
                # Agregar datos de muestra si est√°n disponibles
                if table_name in self.sample_data:
                    sample = self.sample_data[table_name]
                    if sample:
                        schema_summary.append(f"   Muestra: {sample[0] if isinstance(sample, list) else sample}")
                
                schema_summary.append("")  # L√≠nea en blanco
            
            return "\n".join(schema_summary)
            
        except Exception as e:
            logger.error(f"Error generando resumen del esquema: {e}")
            return "Error generando resumen del esquema"

    def _process_patient_search_results(self, data: List[Dict[str, Any]], search_term: str) -> Dict[str, Any]:
        """
        Procesa resultados de b√∫squeda de pacientes y genera sugerencias inteligentes.
        
        Args:
            data: Resultados de la consulta SQL
            search_term: T√©rmino de b√∫squeda original
            
        Returns:
            Dict[str, Any]: Resultados procesados con sugerencias
        """
        if not data:
            return {
                'success': False,
                'message': f'‚ùå No se encontr√≥ ning√∫n paciente con el nombre "{search_term}"',
                'suggestions': [],
                'data': []
            }
        
        # Separar coincidencias exactas de sugerencias
        exact_matches = []
        suggestions = []
        
        for row in data:
            if 'match_type' in row:
                if row['match_type'] == 1:
                    exact_matches.append(row)
                else:
                    suggestions.append(row)
            else:
                # Si no hay match_type, asumir que son coincidencias exactas
                exact_matches.append(row)
        
        # Preparar mensaje de respuesta
        if exact_matches:
            if len(exact_matches) == 1:
                message = f'‚úÖ Encontrado 1 paciente: {exact_matches[0]["PATI_FULL_NAME"]}'
            else:
                message = f'‚úÖ Encontrados {len(exact_matches)} pacientes'
            
            # A√±adir sugerencias si hay
            if suggestions:
                message += f'\nüí° Tambi√©n encontr√© {len(suggestions)} pacientes similares:'
                for i, suggestion in enumerate(suggestions[:3], 1):
                    message += f'\n   {i}. {suggestion["PATI_FULL_NAME"]}'
        else:
            # Solo sugerencias
            message = f'‚ùì No encontr√© coincidencias exactas para "{search_term}"'
            if suggestions:
                message += f'\nüí° ¬øQuiz√°s te refieres a uno de estos pacientes?'
                for i, suggestion in enumerate(suggestions[:5], 1):
                    message += f'\n   {i}. {suggestion["PATI_FULL_NAME"]}'
            else:
                message += f'\nüí° No encontr√© pacientes similares. Verifica el nombre e intenta de nuevo.'
        
        return {
            'success': True,
            'message': message,
            'exact_matches': exact_matches,
            'suggestions': suggestions,
            'data': data,
            'search_term': search_term
        }

    def _create_fallback_patient_search(self, search_term: str) -> str:
        """
        Crea SQL de fallback para b√∫squeda de pacientes cuando fallan otros m√©todos.
        
        Args:
            search_term: T√©rmino de b√∫squeda
            
        Returns:
            str: SQL de fallback simple y robusto
        """
        # SQL ultra-simple que NUNCA puede fallar
        return """
        SELECT p.PATI_ID, p.PATI_FULL_NAME, p.PATI_USUAL_MEDICATION, p.PATI_LAST_VISIT
        FROM PATI_PATIENTS p 
        WHERE UPPER(p.PATI_FULL_NAME) LIKE UPPER(?)
        ORDER BY p.PATI_FULL_NAME
        LIMIT 20
        """

    def _create_robust_patient_search_sql(self, search_term: str, include_suggestions: bool = True) -> str:
        """
        Genera un SQL robusto para b√∫squeda de pacientes por nombre, insensible a may√∫sculas y tildes.
        Si include_suggestions es True, tambi√©n busca sugerencias similares.
        """
        # Normalizar el t√©rmino de b√∫squeda en Python
        normalized_search = self._normalize_accents_python(search_term)
        # B√∫squeda exacta y flexible
        sql = f'''
        SELECT 
            p.PATI_ID, 
            p.PATI_CLINICAL_HISTORY_ID, 
            p.PATI_NAME, 
            p.PATI_SURNAME_1, 
            p.PATI_SURNAME_2, 
            p.PATI_FULL_NAME,
            1 as match_type
        FROM PATI_PATIENTS p 
        WHERE UPPER(p.PATI_FULL_NAME) = UPPER(?)
        '''
        if include_suggestions:
            sql += '''
            UNION
            SELECT 
                p.PATI_ID, 
                p.PATI_CLINICAL_HISTORY_ID, 
                p.PATI_NAME, 
                p.PATI_SURNAME_1, 
                p.PATI_SURNAME_2, 
                p.PATI_FULL_NAME,
                0 as match_type
            FROM PATI_PATIENTS p 
            WHERE UPPER(p.PATI_FULL_NAME) LIKE UPPER(?) AND UPPER(p.PATI_FULL_NAME) != UPPER(?)
            '''
        sql += '\nORDER BY match_type DESC, p.PATI_FULL_NAME LIMIT 20;'
        return sql

    def _prepare_search_parameters(self, search_term: str) -> list:
        """
        Prepara los par√°metros para la b√∫squeda robusta de pacientes.
        Devuelve una lista de par√°metros para el SQL generado.
        """
        normalized = self._normalize_accents_python(search_term)
        return [normalized, f"%{normalized}%", normalized] if normalized else [""]

    async def _validate_patient_exists_dynamic(self, patient_id: str, stream_callback=None) -> bool:
        """Valida din√°micamente si un paciente existe usando LLM"""
        try:
            if stream_callback:
                stream_callback("   - Validando existencia del paciente...")
            
            # Obtener esquema real de la base de datos
            schema_info = self._get_schema_summary_for_exploration()
            
            # PROMPT ESPEC√çFICO PARA VALIDAR EXISTENCIA
            prompt = f"""Eres un experto en validaci√≥n de bases de datos m√©dicas. Valida si un paciente existe.

ID DEL PACIENTE: {patient_id}

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

INSTRUCCIONES ESPEC√çFICAS:
1. Genera una consulta SQL simple para verificar si el paciente existe
2. Usa la tabla PATI_PATIENTS
3. Busca por PATI_ID exacto
4. La consulta debe ser r√°pida y eficiente
5. Solo necesitas verificar existencia, no obtener datos completos

ESTRATEGIA DE VALIDACI√ìN:
- Usar COUNT(*) para verificar existencia
- Filtrar por PATI_ID exacto
- Consulta simple y directa
- Compatible con SQLite

REGLAS CR√çTICAS:
- SQL simple y directo
- Solo verificar existencia
- No JOINs complejos
- Optimizado para velocidad

RESPUESTA:
Solo el SQL v√°lido, sin explicaciones ni comentarios."""

            if stream_callback:
                stream_callback("   - Consultando IA para validaci√≥n...")
            
            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Validando existencia de paciente"
            )
            
            validation_sql = self._clean_llm_sql_response(self._extract_response_text(response))
            
            # Ejecutar la consulta de validaci√≥n
            executor = SQLExecutor(self.db_path)
            result = executor.execute_query(validation_sql, [patient_id])
            
            exists = result.get('success', False) and result.get('row_count', 0) > 0
            
            if stream_callback:
                if exists:
                    stream_callback("   ‚úÖ Paciente encontrado")
                else:
                    stream_callback("   ‚ùå Paciente no encontrado")
            
            return exists
            
        except Exception as e:
            logger.error(f"Error validando existencia de paciente: {e}")
            return False





