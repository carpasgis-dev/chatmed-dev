"""
GreetingAgent - Agente de Saludos Inteligente y Personal v2.0
============================================================

Agente especializado en manejar saludos, informaci√≥n del sistema y consultas generales
con capacidades avanzadas de an√°lisis de contexto, personalizaci√≥n y memoria de usuarios.

üß† FILOSOF√çA: 100% din√°mico sin hardcodeo, usando LLM para comprensi√≥n contextual
‚ö° CARACTER√çSTICAS: Auto-adaptativo, conversacional, transparente sobre capacidades

Desarrollado por Carmen Pascual para ChatMed 2.0 - Sistema de Agentes M√©dicos con IA
"""

import logging
import os
import re
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple, Union
from langchain.llms.base import BaseLLM
from langchain.schema import HumanMessage, AIMessage, BaseMessage, SystemMessage
from collections import defaultdict
import pickle
from pathlib import Path

# Configuraci√≥n de logging
logging.basicConfig(level=os.getenv("LOG_LEVEL", "ERROR"))  # Cambiar de WARNING a ERROR
logger = logging.getLogger("GreetingAgent")

class IntelligentGreetingAgent:
    """
    üß† Agente conversacional avanzado que usa LLM para manejar interacciones no t√©cnicas
    siguiendo la filosof√≠a de ChatMed: 100% din√°mico, sin hardcodeo.
    """
    
    def __init__(self, llm: Optional[BaseLLM] = None):
        """
        Inicializa el agente conversacional inteligente.
        
        Args:
            llm: Una instancia de un modelo de lenguaje compatible con LangChain.
        """
        if not llm:
            raise ValueError("Se requiere una instancia de un modelo de lenguaje (LLM).")
        self.llm = llm
        self.conversation_history = []
        
        # üß† SISTEMA DE INFORMACI√ìN DIN√ÅMICO
        self.system_info = {
            "name": "ChatMed 2.0",
            "version": "2.0 Flexible",
            "description": "Un sistema de IA m√©dica multi-agente dise√±ado para ayudar a profesionales de la salud",
            "creator": "Carmen Pascual (@carpasgis-dev) en Laberit",
            "philosophy": "100% din√°mico sin hardcodeo - Todo se decide usando IA en tiempo real",
            "technologies": {
                "frameworks": [
                    "LangChain - Framework principal para orquestaci√≥n de LLMs",
                    "OpenAI GPT-4 - Modelo de lenguaje base para razonamiento",
                    "Bio.Entrez - API para acceso a bases de datos biom√©dicas (PubMed, GenBank)",
                    "FHIR - Est√°ndar para interoperabilidad en salud",
                    "SQLite - Base de datos local para almacenamiento cl√≠nico"
                ],
                "databases": [
                    "PubMed - Literatura m√©dica y estudios cient√≠ficos",
                    "GenBank - Datos gen√≥micos y secuencias",
                    "ClinicalTrials.gov - Ensayos cl√≠nicos activos y completados",
                    "Europe PMC - Literatura biom√©dica europea",
                    "AEMPS - Informaci√≥n de medicamentos autorizados en Espa√±a",
                    "Semantic Scholar - Literatura acad√©mica con an√°lisis de impacto"
                ]
            },
            "agents": {
                "BioChatAgent": {
                    "purpose": "B√∫squeda inteligente de literatura cient√≠fica",
                    "capabilities": [
                        "Buscar estudios en PubMed con queries optimizadas",
                        "Acceder a ensayos cl√≠nicos en ClinicalTrials.gov",
                        "Consultar secuencias gen√©ticas en GenBank",
                        "Analizar literatura en Semantic Scholar y Europe PMC",
                        "Verificar medicamentos en AEMPS",
                        "S√≠ntesis inteligente de m√∫ltiples fuentes"
                    ]
                },
                "SQLAgentRobust": {
                    "purpose": "An√°lisis inteligente de datos m√©dicos",
                    "capabilities": [
                        "Consultas SQL din√°micas sin hardcodeo",
                        "Auto-exploraci√≥n del esquema de base de datos",
                        "Mapeo inteligente de conceptos m√©dicos a tablas",
                        "Sistema de auto-correcci√≥n iterativa",
                        "Aprendizaje adaptativo de patrones exitosos"
                    ]
                },
                "FHIRMedicalAgent": {
                    "purpose": "Procesamiento de informaci√≥n cl√≠nica",
                    "capabilities": [
                        "Procesamiento de notas cl√≠nicas con IA",
                        "Conversi√≥n autom√°tica SQL‚ÜîFHIR",
                        "Validaci√≥n FHIR autom√°tica",
                        "Gesti√≥n inteligente de recursos relacionados",
                        "Mapeo din√°mico de campos sin hardcodeo"
                    ]
                },
                "GreetingAgent": {
                    "purpose": "Interacci√≥n conversacional y ayuda",
                    "capabilities": [
                        "Conversaciones naturales y contextuales",
                        "Explicaci√≥n de capacidades del sistema",
                        "Ayuda y orientaci√≥n para usuarios",
                        "An√°lisis inteligente de intenciones del usuario"
                    ]
                }
            }
        }
        
        # üß† SISTEMA DE AN√ÅLISIS CONTEXTUAL
        self.context_analyzer = {
            "last_interaction_type": None,
            "user_expertise_level": "unknown",  # unknown, beginner, intermediate, expert
            "conversation_flow": [],
            "detected_needs": []
        }
        
        logger.info("‚úÖ IntelligentGreetingAgent v2.0 (100% din√°mico) inicializado.")

    async def process_query(self, *, query: str, **kwargs) -> Dict[str, Any]:
        """
        üß† Procesa la consulta del usuario usando an√°lisis contextual inteligente
        siguiendo la filosof√≠a de ChatMed: 100% din√°mico sin patrones hardcodeados.
        """
        try:
            # üß† AN√ÅLISIS CONTEXTUAL PREVIO
            context_analysis = await self._analyze_user_context(query)
            
            # Actualizar historial conversacional
            self.conversation_history.append(f"Usuario: {query}")
            
            # üß† GENERAR RESPUESTA INTELIGENTE
            response_text = await self._generate_intelligent_response(query, context_analysis)
            
            # Actualizar contexto conversacional
            self.conversation_history.append(f"Asistente: {response_text}")
            self._update_conversation_context(query, response_text, context_analysis)
            
            # Mantener historial limitado
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            return {"success": True, "message": response_text}
            
        except Exception as e:
            logger.error(f"Error durante el procesamiento en GreetingAgent: {e}")
            return {
                "success": False,
                "message": "Lo siento, estoy teniendo problemas para procesar tu solicitud en este momento. ¬øPodr√≠as reformular tu pregunta?"
            }

    async def _analyze_user_context(self, query: str) -> Dict[str, Any]:
        """
        üß† An√°lisis contextual inteligente de la consulta del usuario
        sin patrones hardcodeados, usando comprensi√≥n sem√°ntica.
        """
        if not self.llm:
            return {"type": "unknown", "intent": "general", "complexity": "low"}
        
        context_prompt = f"""Eres un analista experto en interacciones conversacionales para sistemas de IA m√©dica. Analiza esta consulta para entender el contexto y la intenci√≥n del usuario.

**CONSULTA DEL USUARIO:**
"{query}"

**HISTORIAL CONVERSACIONAL RECIENTE:**
{chr(10).join(self.conversation_history[-4:]) if self.conversation_history else "No hay historial previo"}

**TU AN√ÅLISIS DEBE INCLUIR:**

1. **Tipo de Interacci√≥n:**
   - greeting: Saludo inicial o casual
   - help_request: Solicitud de ayuda o informaci√≥n sobre capacidades
   - system_inquiry: Pregunta sobre el funcionamiento del sistema
   - follow_up: Pregunta de seguimiento sobre algo anterior
   - clarification: Solicitud de aclaraci√≥n o m√°s detalles

2. **Intenci√≥n Principal:**
   - get_capabilities: Quiere saber qu√© puede hacer el sistema
   - understand_system: Quiere entender c√≥mo funciona
   - get_help: Necesita orientaci√≥n para usar el sistema
   - casual_chat: Conversaci√≥n informal
   - technical_info: Busca informaci√≥n t√©cnica espec√≠fica

3. **Nivel de Experiencia Percibido:**
   - beginner: Usuario nuevo o con poca experiencia
   - intermediate: Usuario con alguna experiencia
   - expert: Usuario experimentado o t√©cnico

4. **Tono Apropiado:**
   - friendly_casual: Amigable e informal
   - professional_helpful: Profesional pero accesible
   - technical_detailed: T√©cnico y detallado

Responde SOLO con JSON v√°lido:
{{
  "interaction_type": "tipo",
  "main_intent": "intenci√≥n",
  "expertise_level": "nivel",
  "appropriate_tone": "tono",
  "key_topics": ["tema1", "tema2"],
  "response_strategy": "estrategia recomendada"
}}"""

        try:
            response = await self.llm.ainvoke(context_prompt)
            content = str(response)
            
            # MEJORADO: Parsing m√°s robusto de JSON
            try:
                # Estrategia 1: Intentar parsear directamente
                return json.loads(content)
            except json.JSONDecodeError:
                # Estrategia 2: Buscar JSON con regex m√°s robusto
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    try:
                        return json.loads(json_match.group(0))
                    except json.JSONDecodeError:
                        # Estrategia 3: Limpiar contenido y reintentar
                        cleaned_content = content.strip()
                        # Remover texto antes y despu√©s del JSON
                        cleaned_content = re.sub(r'^[^{]*', '', cleaned_content)
                        cleaned_content = re.sub(r'[^}]*$', '', cleaned_content)
                        try:
                            return json.loads(cleaned_content)
                        except json.JSONDecodeError:
                            pass
                
                # Si todo falla, usar fallback b√°sico
                logger.debug(f"No se pudo parsear JSON del LLM, usando fallback. Contenido: {content[:200]}...")
                return {
                    "interaction_type": "greeting",
                    "main_intent": "get_help",
                    "expertise_level": "beginner",
                    "appropriate_tone": "friendly_casual",
                    "key_topics": ["help"],
                    "response_strategy": "provide_overview"
                }
                
        except Exception as e:
            # MEJORADO: Log m√°s espec√≠fico sin warning
            logger.debug(f"Error en an√°lisis contextual (no cr√≠tico): {str(e)[:100]}...")
            return {
                "interaction_type": "greeting",
                "main_intent": "get_help",
                "expertise_level": "beginner",
                "appropriate_tone": "friendly_casual",
                "key_topics": ["help"],
                "response_strategy": "provide_overview"
            }

    async def _generate_intelligent_response(self, query: str, context: Dict[str, Any]) -> str:
        """
        üß† Genera respuesta inteligente basada en el an√°lisis contextual
        adapt√°ndose din√°micamente al usuario y la situaci√≥n.
        """
        # Construir informaci√≥n del sistema de forma din√°mica
        system_overview = self._build_dynamic_system_overview(context)
        
        # Historial conversacional para contexto
        history_str = "\n".join(self.conversation_history[-4:]) if self.conversation_history else "No hay historial previo"
        
        # üß† PROMPT INTELIGENTE ADAPTATIVO
        response_prompt = f"""Eres ChatMed 2.0, un asistente de IA m√©dico avanzado y conversacional. Tu personalidad se adapta al contexto del usuario.

**AN√ÅLISIS CONTEXTUAL DE ESTA INTERACCI√ìN:**
- Tipo de interacci√≥n: {context.get('interaction_type', 'greeting')}
- Intenci√≥n principal: {context.get('main_intent', 'get_help')}
- Nivel de experiencia del usuario: {context.get('expertise_level', 'beginner')}
- Tono apropiado: {context.get('appropriate_tone', 'friendly_casual')}
- Temas clave: {', '.join(context.get('key_topics', ['general']))}
- Estrategia de respuesta: {context.get('response_strategy', 'provide_overview')}

**TU INFORMACI√ìN INTERNA (usa seg√∫n sea relevante):**
{system_overview}

**HISTORIAL CONVERSACIONAL RECIENTE:**
{history_str}

**INSTRUCCIONES ADAPTATIVAS:**

1. **Adapta tu respuesta** al nivel de experiencia detectado:
   - Beginner: Explicaciones simples, ejemplos pr√°cticos, lenguaje accesible
   - Intermediate: Balance entre detalle t√©cnico y claridad
   - Expert: Informaci√≥n t√©cnica detallada, terminolog√≠a especializada

2. **Ajusta tu tono** seg√∫n el contexto:
   - Friendly_casual: C√°lido, conversacional, usa emojis ocasionalmente
   - Professional_helpful: Profesional pero accesible, enfoque en utilidad
   - Technical_detailed: Preciso, detallado, terminolog√≠a t√©cnica apropiada

3. **Enf√≥cate en la intenci√≥n principal**:
   - Get_capabilities: Explica qu√© puedes hacer de forma pr√°ctica
   - Understand_system: Describe c√≥mo funcionas y tu arquitectura
   - Get_help: Proporciona orientaci√≥n espec√≠fica y ejemplos
   - Casual_chat: Mant√©n conversaci√≥n natural y amigable
   - Technical_info: Proporciona detalles t√©cnicos precisos

4. **S√© transparente y honesto** sobre tus capacidades y limitaciones

5. **Incluye ejemplos pr√°cticos** cuando sea apropiado

**CONSULTA ACTUAL DEL USUARIO:**
"{query}"

**TU RESPUESTA ADAPTATIVA:**"""

        try:
            response = await self.llm.ainvoke(response_prompt)
            # Verificar si la respuesta es un objeto con atributo content o una cadena directa
            if isinstance(response, str):
                response_text = response
            else:
                response_text = getattr(response, 'content', str(response))
            return response_text.strip()
            
        except Exception as e:
            logger.error(f"Error generando respuesta inteligente: {e}")
            return "Lo siento, estoy teniendo dificultades para procesar tu consulta. ¬øPodr√≠as intentar de nuevo?"

    def _build_dynamic_system_overview(self, context: Dict[str, Any]) -> str:
        """
        üß† Construye descripci√≥n del sistema adaptada al contexto del usuario
        """
        expertise_level = context.get('expertise_level', 'beginner')
        main_intent = context.get('main_intent', 'get_help')
        
        overview_parts = []
        
        # Informaci√≥n b√°sica siempre incluida
        overview_parts.append(f"**Sistema:** {self.system_info['name']} (Versi√≥n: {self.system_info['version']})")
        overview_parts.append(f"**Descripci√≥n:** {self.system_info['description']}")
        overview_parts.append(f"**Filosof√≠a:** {self.system_info['philosophy']}")
        
        # Informaci√≥n de agentes seg√∫n el nivel de experiencia
        if main_intent in ['get_capabilities', 'understand_system'] or expertise_level != 'beginner':
            overview_parts.append("\n**Agentes Especializados:**")
            
            for agent_name, agent_info in self.system_info['agents'].items():
                overview_parts.append(f"\n‚Ä¢ **{agent_name}**: {agent_info['purpose']}")
                
                if expertise_level in ['intermediate', 'expert']:
                    # Incluir capacidades detalladas para usuarios m√°s avanzados
                    capabilities = agent_info['capabilities'][:3]  # Primeras 3 capacidades
                    for cap in capabilities:
                        overview_parts.append(f"  - {cap}")
        
        # Informaci√≥n t√©cnica para usuarios avanzados
        if expertise_level == 'expert' and main_intent == 'understand_system':
            overview_parts.append(f"\n**Tecnolog√≠as Principales:**")
            for tech in self.system_info['technologies']['frameworks'][:3]:
                overview_parts.append(f"  - {tech}")
        
        return "\n".join(overview_parts)

    def _update_conversation_context(self, query: str, response: str, context: Dict[str, Any]):
        """Actualiza el contexto conversacional para futuras interacciones"""
        self.context_analyzer['last_interaction_type'] = context.get('interaction_type')
        self.context_analyzer['user_expertise_level'] = context.get('expertise_level', 'unknown')
        self.context_analyzer['conversation_flow'].append({
            'timestamp': datetime.now(),
            'user_query': query[:100],  # Truncar para privacidad
            'interaction_type': context.get('interaction_type'),
            'main_intent': context.get('main_intent')
        })
        
        # Mantener solo las √∫ltimas 5 interacciones
        if len(self.context_analyzer['conversation_flow']) > 5:
            self.context_analyzer['conversation_flow'] = self.context_analyzer['conversation_flow'][-5:]

# Alias para compatibilidad
GreetingAgent = IntelligentGreetingAgent