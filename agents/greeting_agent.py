"""
GreetingAgent - Agente de Saludos Inteligente y Personal v2.0
============================================================

Agente especializado en manejar saludos, informaciÃ³n del sistema y consultas generales
con capacidades avanzadas de anÃ¡lisis de contexto, personalizaciÃ³n y memoria de usuarios.

ðŸ§  FILOSOFÃA: 100% dinÃ¡mico sin hardcodeo, usando LLM para comprensiÃ³n contextual
âš¡ CARACTERÃSTICAS: Auto-adaptativo, conversacional, transparente sobre capacidades

Desarrollado por Carmen Pascual para ChatMed 2.0 - Sistema de Agentes MÃ©dicos con IA
"""

import logging
import os
import re
import json
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple, Union
from langchain.llms.base import BaseLLM
from langchain.schema import HumanMessage, AIMessage, BaseMessage, SystemMessage
from collections import defaultdict
import pickle
from pathlib import Path

# ConfiguraciÃ³n de logging
logging.basicConfig(level=os.getenv("LOG_LEVEL", "ERROR"))  # Cambiar de WARNING a ERROR
logger = logging.getLogger("GreetingAgent")

class IntelligentGreetingAgent:
    """
    ðŸ§  Agente conversacional avanzado que usa LLM para manejar interacciones no tÃ©cnicas
    siguiendo la filosofÃ­a de ChatMed: 100% dinÃ¡mico, sin hardcodeo.
    """
    
    def __init__(self, llm: Optional[BaseLLM] = None):
        """
        Inicializa el agente conversacional inteligente.
        
        Args:
            llm: Una instancia de un modelo de lenguaje compatible con LangChain.
        """
        if not llm:
            raise ValueError("Se requiere una instancia de un modelo de lenguaje (LLM).")
        self.llm = llm
        self.conversation_history = []
        
        # ðŸ§  SISTEMA DE INFORMACIÃ“N DINÃMICO
        self.system_info = {
            "name": "ChatMed 2.0",
            "version": "2.0 Flexible",
            "description": "Un sistema de IA mÃ©dica multi-agente diseÃ±ado para ayudar a profesionales de la salud",
            "creator": "Carmen Pascual (@carpasgis-dev) en Laberit",
            "philosophy": "100% dinÃ¡mico sin hardcodeo - Todo se decide usando IA en tiempo real",
            "technologies": {
                "frameworks": [
                    "LangChain - Framework principal para orquestaciÃ³n de LLMs",
                    "OpenAI GPT-4 - Modelo de lenguaje base para razonamiento",
                    "Bio.Entrez - API para acceso a bases de datos biomÃ©dicas (PubMed, GenBank)",
                    "FHIR - EstÃ¡ndar para interoperabilidad en salud",
                    "SQLite - Base de datos local para almacenamiento clÃ­nico"
                ],
                "databases": [
                    "PubMed - Literatura mÃ©dica y estudios cientÃ­ficos",
                    "GenBank - Datos genÃ³micos y secuencias",
                    "ClinicalTrials.gov - Ensayos clÃ­nicos activos y completados",
                    "Europe PMC - Literatura biomÃ©dica europea",
                    "AEMPS - InformaciÃ³n de medicamentos autorizados en EspaÃ±a",
                    "Semantic Scholar - Literatura acadÃ©mica con anÃ¡lisis de impacto"
                ]
            },
            "agents": {
                "BioChatAgent": {
                    "purpose": "BÃºsqueda inteligente de literatura cientÃ­fica",
                    "capabilities": [
                        "Buscar estudios en PubMed con queries optimizadas",
                        "Acceder a ensayos clÃ­nicos en ClinicalTrials.gov",
                        "Consultar secuencias genÃ©ticas en GenBank",
                        "Analizar literatura en Semantic Scholar y Europe PMC",
                        "Verificar medicamentos en AEMPS",
                        "SÃ­ntesis inteligente de mÃºltiples fuentes"
                    ]
                },
                "SQLAgentRobust": {
                    "purpose": "AnÃ¡lisis inteligente de datos mÃ©dicos",
                    "capabilities": [
                        "Consultas SQL dinÃ¡micas sin hardcodeo",
                        "Auto-exploraciÃ³n del esquema de base de datos",
                        "Mapeo inteligente de conceptos mÃ©dicos a tablas",
                        "Sistema de auto-correcciÃ³n iterativa",
                        "Aprendizaje adaptativo de patrones exitosos"
                    ]
                },
                "FHIRMedicalAgent": {
                    "purpose": "Procesamiento de informaciÃ³n clÃ­nica",
                    "capabilities": [
                        "Procesamiento de notas clÃ­nicas con IA",
                        "ConversiÃ³n automÃ¡tica SQLâ†”FHIR",
                        "ValidaciÃ³n FHIR automÃ¡tica",
                        "GestiÃ³n inteligente de recursos relacionados",
                        "Mapeo dinÃ¡mico de campos sin hardcodeo"
                    ]
                },
                "GreetingAgent": {
                    "purpose": "InteracciÃ³n conversacional y ayuda",
                    "capabilities": [
                        "Conversaciones naturales y contextuales",
                        "ExplicaciÃ³n de capacidades del sistema",
                        "Ayuda y orientaciÃ³n para usuarios",
                        "AnÃ¡lisis inteligente de intenciones del usuario"
                    ]
                }
            }
        }
        
        # ðŸ§  SISTEMA DE ANÃLISIS CONTEXTUAL
        self.context_analyzer = {
            "last_interaction_type": None,
            "user_expertise_level": "unknown",  # unknown, beginner, intermediate, expert
            "conversation_flow": [],
            "detected_needs": []
        }
        
        logger.info("âœ… IntelligentGreetingAgent v2.0 (100% dinÃ¡mico) inicializado.")

    async def process_query(self, *, query: str, **kwargs) -> Dict[str, Any]:
        """
        ðŸ§  Procesa la consulta del usuario usando anÃ¡lisis contextual inteligente
        siguiendo la filosofÃ­a de ChatMed: 100% dinÃ¡mico sin patrones hardcodeados.
        """
        try:
            # ðŸ§  ANÃLISIS CONTEXTUAL PREVIO
            context_analysis = await self._analyze_user_context(query)
            
            # Actualizar historial conversacional
            self.conversation_history.append(f"Usuario: {query}")
            
            # ðŸ§  GENERAR RESPUESTA INTELIGENTE
            response_text = await self._generate_intelligent_response(query, context_analysis)
            
            # Actualizar contexto conversacional
            self.conversation_history.append(f"Asistente: {response_text}")
            self._update_conversation_context(query, response_text, context_analysis)
            
            # Mantener historial limitado
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            return {"success": True, "message": response_text}
            
        except Exception as e:
            logger.error(f"Error durante el procesamiento en GreetingAgent: {e}")
            return {
                "success": False,
                "message": "Lo siento, estoy teniendo problemas para procesar tu solicitud en este momento. Â¿PodrÃ­as reformular tu pregunta?"
            }

    async def _analyze_user_context(self, query: str) -> Dict[str, Any]:
        """
        ðŸ§  AnÃ¡lisis contextual inteligente de la consulta del usuario
        sin patrones hardcodeados, usando comprensiÃ³n semÃ¡ntica.
        """
        if not self.llm:
            return {"type": "unknown", "intent": "general", "complexity": "low"}
        
        context_prompt = f"""Eres un analista experto en interacciones conversacionales para sistemas de IA mÃ©dica. Analiza esta consulta para entender el contexto y la intenciÃ³n del usuario.

**CONSULTA DEL USUARIO:**
"{query}"

**HISTORIAL CONVERSACIONAL RECIENTE:**
{chr(10).join(self.conversation_history[-4:]) if self.conversation_history else "No hay historial previo"}

**TU ANÃLISIS DEBE INCLUIR:**

1. **Tipo de InteracciÃ³n:**
   - greeting: Saludo inicial o casual
   - help_request: Solicitud de ayuda o informaciÃ³n sobre capacidades
   - system_inquiry: Pregunta sobre el funcionamiento del sistema
   - follow_up: Pregunta de seguimiento sobre algo anterior
   - clarification: Solicitud de aclaraciÃ³n o mÃ¡s detalles

2. **IntenciÃ³n Principal:**
   - get_capabilities: Quiere saber quÃ© puede hacer el sistema
   - understand_system: Quiere entender cÃ³mo funciona
   - get_help: Necesita orientaciÃ³n para usar el sistema
   - casual_chat: ConversaciÃ³n informal
   - technical_info: Busca informaciÃ³n tÃ©cnica especÃ­fica

3. **Nivel de Experiencia Percibido:**
   - beginner: Usuario nuevo o con poca experiencia
   - intermediate: Usuario con alguna experiencia
   - expert: Usuario experimentado o tÃ©cnico

4. **Tono Apropiado:**
   - friendly_casual: Amigable e informal
   - professional_helpful: Profesional pero accesible
   - technical_detailed: TÃ©cnico y detallado

Responde SOLO con JSON vÃ¡lido:
{{
  "interaction_type": "tipo",
  "main_intent": "intenciÃ³n",
  "expertise_level": "nivel",
  "appropriate_tone": "tono",
  "key_topics": ["tema1", "tema2"],
  "response_strategy": "estrategia recomendada"
}}"""

        try:
            response = await self.llm.ainvoke(context_prompt)
            content = str(response)
            
            # MEJORADO: Parsing mÃ¡s robusto de JSON
            try:
                # Estrategia 1: Intentar parsear directamente
                return json.loads(content)
            except json.JSONDecodeError:
                # Estrategia 2: Buscar JSON con regex mÃ¡s robusto
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    try:
                        return json.loads(json_match.group(0))
                    except json.JSONDecodeError:
                        # Estrategia 3: Limpiar contenido y reintentar
                        cleaned_content = content.strip()
                        # Remover texto antes y despuÃ©s del JSON
                        cleaned_content = re.sub(r'^[^{]*', '', cleaned_content)
                        cleaned_content = re.sub(r'[^}]*$', '', cleaned_content)
                        try:
                            return json.loads(cleaned_content)
                        except json.JSONDecodeError:
                            pass
                
                # Si todo falla, usar fallback bÃ¡sico
                logger.debug(f"No se pudo parsear JSON del LLM, usando fallback. Contenido: {content[:200]}...")
                return {
                    "interaction_type": "greeting",
                    "main_intent": "get_help",
                    "expertise_level": "beginner",
                    "appropriate_tone": "friendly_casual",
                    "key_topics": ["help"],
                    "response_strategy": "provide_overview"
                }
                
        except Exception as e:
            # MEJORADO: Log mÃ¡s especÃ­fico sin warning
            logger.debug(f"Error en anÃ¡lisis contextual (no crÃ­tico): {str(e)[:100]}...")
            return {
                "interaction_type": "greeting",
                "main_intent": "get_help",
                "expertise_level": "beginner",
                "appropriate_tone": "friendly_casual",
                "key_topics": ["help"],
                "response_strategy": "provide_overview"
            }

    async def _generate_intelligent_response(self, query: str, context: Dict[str, Any]) -> str:
        """
        ðŸ§  Genera respuesta inteligente basada en el anÃ¡lisis contextual
        adaptÃ¡ndose dinÃ¡micamente al usuario y la situaciÃ³n.
        """
        # Construir informaciÃ³n del sistema de forma dinÃ¡mica
        system_overview = self._build_dynamic_system_overview(context)
        
        # Historial conversacional para contexto
        history_str = "\n".join(self.conversation_history[-4:]) if self.conversation_history else "No hay historial previo"
        
        # ðŸ§  PROMPT INTELIGENTE ADAPTATIVO
        response_prompt = f"""Eres ChatMed 2.0, un asistente de IA mÃ©dico avanzado y conversacional. Tu personalidad se adapta al contexto del usuario.

**ANÃLISIS CONTEXTUAL DE ESTA INTERACCIÃ“N:**
- Tipo de interacciÃ³n: {context.get('interaction_type', 'greeting')}
- IntenciÃ³n principal: {context.get('main_intent', 'get_help')}
- Nivel de experiencia del usuario: {context.get('expertise_level', 'beginner')}
- Tono apropiado: {context.get('appropriate_tone', 'friendly_casual')}
- Temas clave: {', '.join(context.get('key_topics', ['general']))}
- Estrategia de respuesta: {context.get('response_strategy', 'provide_overview')}

**TU INFORMACIÃ“N INTERNA (usa segÃºn sea relevante):**
{system_overview}

**HISTORIAL CONVERSACIONAL RECIENTE:**
{history_str}

**INSTRUCCIONES ADAPTATIVAS:**

1. **Adapta tu respuesta** al nivel de experiencia detectado:
   - Beginner: Explicaciones simples, ejemplos prÃ¡cticos, lenguaje accesible
   - Intermediate: Balance entre detalle tÃ©cnico y claridad
   - Expert: InformaciÃ³n tÃ©cnica detallada, terminologÃ­a especializada

2. **Ajusta tu tono** segÃºn el contexto:
   - Friendly_casual: CÃ¡lido, conversacional, usa emojis ocasionalmente
   - Professional_helpful: Profesional pero accesible, enfoque en utilidad
   - Technical_detailed: Preciso, detallado, terminologÃ­a tÃ©cnica apropiada

3. **EnfÃ³cate en la intenciÃ³n principal**:
   - Get_capabilities: Explica quÃ© puedes hacer de forma prÃ¡ctica
   - Understand_system: Describe cÃ³mo funcionas y tu arquitectura
   - Get_help: Proporciona orientaciÃ³n especÃ­fica y ejemplos
   - Casual_chat: MantÃ©n conversaciÃ³n natural y amigable
   - Technical_info: Proporciona detalles tÃ©cnicos precisos

4. **SÃ© transparente y honesto** sobre tus capacidades y limitaciones

5. **Incluye ejemplos prÃ¡cticos** cuando sea apropiado

**CONSULTA ACTUAL DEL USUARIO:**
"{query}"

**TU RESPUESTA ADAPTATIVA:**"""

        try:
            response = await self.llm.ainvoke(response_prompt)
            # Verificar si la respuesta es un objeto con atributo content o una cadena directa
            if isinstance(response, str):
                response_text = response
            else:
                response_text = getattr(response, 'content', str(response))
            return response_text.strip()
            
        except Exception as e:
            logger.error(f"Error generando respuesta inteligente: {e}")
            return "Lo siento, estoy teniendo dificultades para procesar tu consulta. Â¿PodrÃ­as intentar de nuevo?"

    def _build_dynamic_system_overview(self, context: Dict[str, Any]) -> str:
        """
        ðŸ§  Construye descripciÃ³n del sistema adaptada al contexto del usuario
        """
        expertise_level = context.get('expertise_level', 'beginner')
        main_intent = context.get('main_intent', 'get_help')
        
        overview_parts = []
        
        # InformaciÃ³n bÃ¡sica siempre incluida
        overview_parts.append(f"**Sistema:** {self.system_info['name']} (VersiÃ³n: {self.system_info['version']})")
        overview_parts.append(f"**DescripciÃ³n:** {self.system_info['description']}")
        overview_parts.append(f"**FilosofÃ­a:** {self.system_info['philosophy']}")
        
        # InformaciÃ³n de agentes segÃºn el nivel de experiencia
        if main_intent in ['get_capabilities', 'understand_system'] or expertise_level != 'beginner':
            overview_parts.append("\n**Agentes Especializados:**")
            
            for agent_name, agent_info in self.system_info['agents'].items():
                overview_parts.append(f"\nâ€¢ **{agent_name}**: {agent_info['purpose']}")
                
                if expertise_level in ['intermediate', 'expert']:
                    # Incluir capacidades detalladas para usuarios mÃ¡s avanzados
                    capabilities = agent_info['capabilities'][:3]  # Primeras 3 capacidades
                    for cap in capabilities:
                        overview_parts.append(f"  - {cap}")
        
        # InformaciÃ³n tÃ©cnica para usuarios avanzados
        if expertise_level == 'expert' and main_intent == 'understand_system':
            overview_parts.append(f"\n**TecnologÃ­as Principales:**")
            for tech in self.system_info['technologies']['frameworks'][:3]:
                overview_parts.append(f"  - {tech}")
        
        return "\n".join(overview_parts)

    def _update_conversation_context(self, query: str, response: str, context: Dict[str, Any]):
        """Actualiza el contexto conversacional para futuras interacciones"""
        self.context_analyzer['last_interaction_type'] = context.get('interaction_type')
        self.context_analyzer['user_expertise_level'] = context.get('expertise_level', 'unknown')
        self.context_analyzer['conversation_flow'].append({
            'timestamp': datetime.now(),
            'user_query': query[:100],  # Truncar para privacidad
            'interaction_type': context.get('interaction_type'),
            'main_intent': context.get('main_intent')
        })
        
        # Mantener solo las Ãºltimas 5 interacciones
        if len(self.context_analyzer['conversation_flow']) > 5:
            self.context_analyzer['conversation_flow'] = self.context_analyzer['conversation_flow'][-5:]

# Alias para compatibilidad
GreetingAgent = IntelligentGreetingAgent