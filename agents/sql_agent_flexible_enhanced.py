#!/usr/bin/env python3
"""
üß† SQL Agent Completamente Inteligente v5.0 - Versi√≥n Avanzada Modular
======================================================================
Sistema que usa SOLO LLM para cada tarea espec√≠fica, sin hardcodeo ni patrones.
Incorporando las funcionalidades m√°s avanzadas del clean de forma modular.
"""
import logging
import sqlite3
import json
import re
import os
import asyncio
import time
import traceback
import itertools
from typing import Dict, List, Any, Union, Optional, Tuple
from pathlib import Path
from langchain.schema import SystemMessage, HumanMessage
from datetime import datetime
import math
import ast
import hashlib


# Import del m√≥dulo sql_agent_tools para funcionalidades modulares
try:
    from .sql_agent_tools import SQLAgentTools
except ImportError:
    from sql_agent_tools import SQLAgentTools

# Import de los nuevos m√≥dulos de utilidades
try:
    from ..utils.sql_cleaner import SQLCleaner
    from ..utils.sql_executor import SQLExecutor
    from ..utils.fhir_mapping_corrector import correct_fhir_mapping_result
except ImportError:
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from utils.sql_cleaner import SQLCleaner
    from utils.sql_executor import SQLExecutor
    from utils.fhir_mapping_corrector import correct_fhir_mapping_result

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SQLAgentIntelligent_v5.0")

class MockResponse:
    def __init__(self, content: str):
        self.content = content

def _call_openai_native(client, messages, temperature=0.1, max_tokens=4000, task_description="Consultando modelo de IA") -> MockResponse:
    """
    Funci√≥n de compatibilidad para llamar a OpenAI nativo con streaming, logging y reintentos.
    """
    import time
    import random
    
    max_retries = 3
    base_delay = 1.0
    
    for attempt in range(max_retries):
        try:
            # Logging m√°s conciso
            from openai import OpenAI
            native_client = OpenAI()

            if isinstance(messages, list):
                openai_messages = []
                for msg in messages:
                    role = "user"
                    content = ""
                    if hasattr(msg, 'content'):
                        content = str(msg.content)
                        if isinstance(msg, SystemMessage):
                            role = "system"
                        elif isinstance(msg, HumanMessage):
                            role = "user"
                    elif isinstance(msg, dict) and "role" in msg and "content" in msg:
                        role = str(msg["role"])
                        content = str(msg["content"])
                    else:
                        content = str(msg)
                    openai_messages.append({"role": role, "content": content})
            else:
                content = messages.content if hasattr(messages, 'content') else str(messages)
                openai_messages = [{"role": "user", "content": str(content)}]

            # Mostrar progreso con intento
            if attempt > 0:
                print(f"   üí° {task_description} (intento {attempt + 1}/{max_retries})...", end="", flush=True)
            else:
                print(f"   üí° {task_description}...", end="", flush=True)
            
            # Siempre usar streaming para que se muestre el progreso en tiempo real
            stream_buffer: List[str] = []
            
            try:
                resp_stream = native_client.chat.completions.create(
                    model="gpt-4o",
                    messages=openai_messages,  # type: ignore
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=True,
                )
                
                for chunk in resp_stream:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, "content") and delta.content:
                        token = delta.content
                        stream_buffer.append(token)
                        # Mostrar progreso visual
                        if len(stream_buffer) % 10 == 0:  # Cada 10 tokens
                            print(".", end="", flush=True)
                            
                print(" ‚úì")  # Finalizar l√≠nea de progreso
                content = "".join(stream_buffer)

                if not content.strip():
                    content = '{"success": false, "message": "Error: Respuesta vac√≠a del LLM"}'

                # Si llegamos aqu√≠, la llamada fue exitosa
                if attempt > 0:
                    print(f"   ‚úÖ Llamada exitosa despu√©s de {attempt + 1} intentos")

                return MockResponse(content)
                
            except Exception as api_error:
                print(" ‚ùå")  # Finalizar l√≠nea de progreso con error
                error_msg = str(api_error).lower()
                
                # Errores que merecen reintento
                if any(keyword in error_msg for keyword in [
                    'server had an error', 'timeout', 'rate limit', 'quota exceeded',
                    'service unavailable', 'internal server error', 'bad gateway'
                ]):
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                        print(f"   ‚ö†Ô∏è Error de API (intento {attempt + 1}/{max_retries}): {api_error}")
                        print(f"   ‚è≥ Reintentando en {delay:.2f} segundos...")
                        time.sleep(delay)
                        continue
                    else:
                        print(f"   ‚ùå ERROR EN LLM: Error de API despu√©s de {max_retries} intentos: {api_error}")
                        logger.error(f"Error en _call_openai_native (SQLAgent): {api_error}", exc_info=True)
                        return MockResponse('{"success": false, "message": "Error de API despu√©s de m√∫ltiples intentos"}')
                else:
                    # Error que no merece reintento
                    print(f"   ‚ùå ERROR EN LLM: {api_error}")
                    logger.error(f"Error en _call_openai_native (SQLAgent): {api_error}", exc_info=True)
                    return MockResponse('{"success": false, "message": "Error en llamada a OpenAI API"}')

        except Exception as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
                print(f"   ‚ö†Ô∏è Error general (intento {attempt + 1}/{max_retries}): {e}")
                print(f"   ‚è≥ Reintentando en {delay:.2f} segundos...")
                time.sleep(delay)
                continue
            else:
                error_msg = f"Error en llamada OpenAI del SQLAgent: {str(e)}"
                print(f"   ‚ùå ERROR EN LLM: {error_msg}")
                logger.error(f"Error en _call_openai_native (SQLAgent): {e}", exc_info=True)
                return MockResponse('{"success": false, "message": "Error cr√≠tico en la llamada al LLM."}')
    
    # Si llegamos aqu√≠, todos los intentos fallaron
    return MockResponse('{"success": false, "message": "Error: Todos los intentos de llamada al LLM fallaron"}')

class SQLAgentIntelligentEnhanced:
    def __init__(self, db_path: str, llm=None, medgemma_agent=None):
        """
        Inicializa el agente SQL inteligente mejorado con cach√© inteligente y MedGemma.
        
        Args:
            db_path: Ruta a la base de datos SQLite
            llm: Cliente LLM (opcional)
            medgemma_agent: Agente MedGemma para an√°lisis cl√≠nico (opcional)
        """
        self.db_path = db_path
        print(f"üîç SQLAgent usando base de datos: {db_path}")
        self.llm = llm
        self.medgemma_agent = medgemma_agent
        self.schema = {}
        self.column_metadata = {}
        self.table_info = {}
        
        # CACH√â INTELIGENTE: Almacena resultados para reutilizaci√≥n
        self._schema_cache = {}  # Cach√© de esquemas por tabla
        self._mapping_cache = {}  # Cach√© de mapeos exitosos
        self._validation_cache = {}  # Cach√© de validaciones previas
        self._table_selection_cache = {}  # Cach√© de selecci√≥n de tablas
        self._id_validation_cache = {}  # Cach√© de validaci√≥n de IDs
        self._field_mapping_cache = {}  # Cach√© de mapeo de campos
        
        # Configuraci√≥n de cach√©
        self._cache_ttl = 3600  # 1 hora de TTL
        self._cache_timestamps = {}  # Timestamps para TTL
        
        # Sistema modular usando SQLAgentTools con LLM
        self.schema_tools = SQLAgentTools(db_path, llm=llm)
        self.sql_cleaner = SQLCleaner()
        self.sql_executor = SQLExecutor(db_path)
        
        # Inicializar componentes
        self._initialize_schema_with_tools()
        self._initialize_column_metadata()
        
        # Configuraci√≥n de logging mejorada
        self.logger = logging.getLogger("SQLAgentEnhanced")
        self.logger.setLevel(logging.INFO)
        
        # Formato de logging personalizado
        formatter = logging.Formatter(
            '\n%(asctime)s [%(levelname)s] %(message)s',
            datefmt='%H:%M:%S'
        )
        
        # Handler para consola con colores
        ch = logging.StreamHandler()
        ch.setFormatter(formatter)
        self.logger.addHandler(ch)
        
        # CR√çTICO: Para mantener el ID del paciente actual
        self._current_patient_id = None

    def _initialize_schema_with_tools(self):
        """Inicializa el esquema usando las herramientas modulares"""
        try:
            self.schema_tools.introspect_schema(use_cache=True)
            logger.info("‚úÖ Esquema inicializado usando herramientas modulares")
        except Exception as e:
            logger.error(f"Error inicializando esquema: {e}")

    def _initialize_column_metadata(self):
        """Inicializa column_metadata para compatibilidad con otros agentes"""
        try:
            # Inicializaci√≥n b√°sica para compatibilidad
            self.column_metadata = {}
            logger.info("‚úÖ Column metadata inicializado para compatibilidad")
        except Exception as e:
            logger.error(f"Error inicializando column metadata: {e}")
            self.column_metadata = {}

    async def _get_cached_schema_info(self, table_name: Optional[str] = None) -> str:
        """Devuelve el esquema real de la base de datos (stub para compatibilidad)."""
        return self._get_real_schema_info()

    async def process_query(self, query: str, stream_callback=None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        üß† Procesamiento gen√©rico de consultas SQL usando LLM para mapeo autom√°tico
        """
        start_time = time.time()
        
        try:
            if stream_callback:
                stream_callback("üîç Analizando consulta con LLM...")
            
            # PASO 1: Generar SQL usando LLM con prompts espec√≠ficos y din√°micos
            try:
                if stream_callback:
                    stream_callback("ü§ñ Generando SQL con IA din√°mica...")
                
                # Obtener esquema de la base de datos
                schema_info = self._get_real_schema_info()
                
                # PROMPT 1: An√°lisis m√©dico espec√≠fico
                analysis_prompt = f"""Eres un experto en an√°lisis de consultas m√©dicas.

CONSULTA: "{query}"

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

TAREA: Analiza la consulta m√©dica y extrae informaci√≥n clave.

AN√ÅLISIS M√âDICO ESPEC√çFICO:
1. Identificar el tipo de consulta (conteo, selecci√≥n, b√∫squeda)
2. Identificar la entidad principal (pacientes, diagn√≥sticos, medicamentos)
3. Identificar condiciones m√©dicas espec√≠ficas (diabetes, hipertensi√≥n, c√°ncer, etc.)
4. Identificar campos de b√∫squeda m√©dica (DIAG_OBSERVATION, DIAG_DESCRIPTION)
5. Identificar tablas m√©dicas relevantes

ESTRATEGIA M√âDICA:
- Para diagn√≥sticos: Buscar en EPIS_DIAGNOSTICS.DIAG_OBSERVATION
- Para conteos: Usar COUNT(*) desde PATI_PATIENTS
- Para medicaci√≥n: Usar PATI_USUAL_MEDICATION
- Para condiciones espec√≠ficas: Usar LIKE '%termino%' en campos de texto

RESPUESTA JSON:
{{
    "tipo_consulta": "conteo|seleccion|busqueda",
    "entidad_principal": "pacientes|diagnosticos|medicamentos",
    "condicion_medica": "diabetes|hipertension|cancer|etc",
    "campos_busqueda": ["DIAG_OBSERVATION", "DIAG_DESCRIPTION"],
    "tablas_principales": ["PATI_PATIENTS", "EPIS_DIAGNOSTICS"],
    "operacion": "count|select|join"
}}"""
                
                analysis_response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": analysis_prompt}],
                    task_description="Analizando consulta"
                )
                
                analysis = self._try_parse_llm_json(self._extract_response_text(analysis_response))
                
                # PROMPT 2: Generaci√≥n de SQL m√©dico espec√≠fico
                sql_prompt = f"""Eres un experto en SQL m√©dico. Genera SQL para esta consulta.

CONSULTA: "{query}"
AN√ÅLISIS: {json.dumps(analysis, indent=2, ensure_ascii=False) if analysis else '{}'}

REGLAS B√ÅSICAS:
- Para diagn√≥sticos: JOIN PATI_PATIENTS p ON p.PATI_ID = d.PATI_ID
- Para medicaci√≥n: usar PATI_USUAL_MEDICATION.PAUM_OBSERVATIONS
- Para conteos: COUNT(DISTINCT p.PATI_ID)
- Buscar en DIAG_OBSERVATION con LIKE '%termino%'

RESPUESTA: SOLO el SQL v√°lido."""
                
                response = _call_openai_native(self.llm, [{"role": "user", "content": sql_prompt}], task_description="Generando SQL espec√≠fico")
                
                sql = self._extract_response_text(response).strip()
                sql = self._clean_llm_sql_response(sql)
                
                if stream_callback:
                    stream_callback("‚úÖ SQL generado con IA espec√≠fica")
                
                # PASO 3: Validar y corregir SQL si es necesario
                if sql and not sql.startswith("SELECT COUNT(*) FROM HEAL_DIABETES_INDICATORS"):
                    validation_prompt = f"""Eres un experto en validaci√≥n de SQL m√©dico.

SQL GENERADO:
{sql}

CONSULTA ORIGINAL:
"{query}"

AN√ÅLISIS PREVIO:
{json.dumps(analysis, indent=2, ensure_ascii=False) if analysis else '{}'}

TAREA: Valida si el SQL es apropiado para la consulta m√©dica.

PROBLEMAS ESPEC√çFICOS A DETECTAR:
1. Para consultas de diabetes: ¬øBusca en campos de texto libre (DIAG_OBSERVATION, DIAG_DESCRIPTION)?
2. Para conteos m√©dicos: ¬øCuenta desde la tabla principal de pacientes?
3. Para condiciones m√©dicas: ¬øUsa LIKE '%termino%' para b√∫squedas flexibles?
4. Para diagn√≥sticos: ¬øBusca en campos de observaci√≥n m√©dica?
5. Para medicamentos: ¬øUsa PAUM_OBSERVATIONS para ranking real de medicamentos?
6. Para ranking de medicamentos: ¬øSELECT PAUM_OBSERVATIONS, COUNT(*) FROM PATI_USUAL_MEDICATION WHERE PAUM_OBSERVATIONS IS NOT NULL?
7. Para medicamentos m√°s prescritos: ¬øAgrupa por PAUM_OBSERVATIONS para obtener medicamentos reales prescritos?

CRITERIOS DE VALIDACI√ìN:
- Para diagn√≥sticos m√©dicos debe buscar en campos de texto libre
- Para conteos debe usar COUNT(*) desde tabla de pacientes
- Para b√∫squedas m√©dicas debe usar LIKE con comodines
- Para condiciones espec√≠ficas debe buscar en campos de observaci√≥n

RESPUESTA:
- Si el SQL es correcto: Devuelve el SQL original
- Si necesita correcci√≥n: Devuelve el SQL corregido
- Devuelve SOLO el SQL, sin explicaciones"""
                    
                    validation_response = _call_openai_native(self.llm, [{"role": "user", "content": validation_prompt}], task_description="Validando SQL")
                    
                    validated_sql = self._extract_response_text(validation_response).strip()
                    validated_sql = self._clean_llm_sql_response(validated_sql)
                    
                    if validated_sql and validated_sql != sql:
                        sql = validated_sql
                        if stream_callback:
                            stream_callback("‚úÖ SQL corregido despu√©s de validaci√≥n")
                    
            except Exception as e:
                if stream_callback:
                    stream_callback("‚ö†Ô∏è Error en generaci√≥n SQL, usando fallback...")

                # Fallback: SQL b√°sico
                sql = "SELECT COUNT(*) FROM PATI_PATIENTS"
            
            # MOSTRAR SQL GENERADO PARA DEPURACI√ìN
            if stream_callback:
                stream_callback(f"üîç SQL GENERADO: {sql}")
            
            if stream_callback:
                stream_callback("üîß Ejecutando consulta...")
            
            # PASO 2: Ejecutar SQL usando la funci√≥n robusta que maneja errores
            result = await self._execute_sql_with_llm_validation(query, sql, start_time, stream_callback=stream_callback)
            
            if not result.get("success"):
                return result  # Devolver el error directamente
            
            # Extraer datos del resultado exitoso
            formatted_results = result.get("data", [])
            interpretation = result.get("message", "Consulta completada")
            
            # Interpretar resultados din√°micamente
            interpretation = await self._interpret_results_generic(query, formatted_results, stream_callback)
            
            return {
                "success": True,
                "message": interpretation,
                "data": formatted_results,
                "sql": sql,
                "count": len(formatted_results)
            }
            
            # Los resultados ya est√°n procesados en _execute_sql_with_llm_validation
            pass
                
        except Exception as e:
            logger.error(f"Error en process_query: {e}")
            
            # FALLBACK: Usar herramientas gen√©ricas de SQL
            try:
                if stream_callback:
                    stream_callback("üîÑ Activando fallback con herramientas gen√©ricas...")
                
                # Usar herramientas gen√©ricas como √∫ltimo recurso
                fallback_sql = await self._use_generic_sql_tools(query, stream_callback)
                
                if fallback_sql:
                    # Intentar ejecutar el SQL de fallback
                    fallback_result = await self._execute_sql_with_llm_validation(query, fallback_sql, start_time, stream_callback=stream_callback)
                    
                    if fallback_result.get("success"):
                        if stream_callback:
                            stream_callback("‚úÖ Fallback exitoso con herramientas gen√©ricas")
                        return fallback_result
                    else:
                        return {
                            "success": False,
                            "message": f"Error en consulta SQL (fallback tambi√©n fall√≥): {str(e)}",
                            "sql": fallback_sql
                        }
                else:
                    return {
                        "success": False,
                        "message": f"Error procesando consulta: {str(e)}",
                        "sql": sql if 'sql' in locals() else ""
                    }
                    
            except Exception as fallback_error:
                logger.error(f"Error en fallback: {fallback_error}")
                return {
                    "success": False,
                    "message": f"Error cr√≠tico en consulta SQL: {str(e)}",
                    "sql": sql if 'sql' in locals() else ""
                }
    
    async def _interpret_results_generic(self, query: str, results: List[Dict[str, Any]], stream_callback=None) -> str:
        """Interpretaci√≥n din√°mica de resultados usando LLM"""
        count = len(results) if results else 0
        
        if count == 0:
            return "No se encontraron resultados para esta consulta."
        
        if not self.llm:
            return f"Encontrados {count} registros."
        
        try:
            # Crear prompt para interpretaci√≥n din√°mica
            sample_data = results[:3] if results else []
            
            prompt = f"""Eres un experto en interpretaci√≥n de resultados de bases de datos m√©dicas.

CONSULTA ORIGINAL: "{query}"
N√öMERO DE RESULTADOS: {count}

MUESTRA DE DATOS:
{json.dumps(sample_data, indent=2, ensure_ascii=False)}

TAREA: Analiza la consulta y los datos para generar una respuesta clara y √∫til.

REGLAS ESPEC√çFICAS:
- Si la consulta pide "cu√°ntos pacientes con diabetes": Responde con el n√∫mero total
- Si la consulta pide "qu√© medicaci√≥n tienen": Lista las medicaciones encontradas
- Si la consulta combina conteo y medicaci√≥n: Responde con ambos aspectos
- Para diabetes: Enf√≥cate en el conteo de pacientes y sus medicaciones
- Para medicaci√≥n: Muestra las medicaciones espec√≠ficas encontradas
- Usa lenguaje natural y m√©dico apropiado
- Si no hay datos, explica por qu√© no se encontraron resultados

RESPUESTA: Genera una respuesta clara y estructurada que responda directamente a la consulta."""

            response = _call_openai_native(self.llm, [{"role": "user", "content": prompt}], task_description="Interpretando resultados din√°micamente")
            
            interpretation = self._extract_response_text(response).strip()
            
            if stream_callback:
                stream_callback("   ‚úÖ Resultados interpretados din√°micamente")
            
            return interpretation if interpretation else f"Encontrados {count} registros."
            
        except Exception as e:
            logger.error(f"Error en interpretaci√≥n din√°mica: {e}")
            return f"Encontrados {count} registros."

    async def _llm_analyze_semantics(self, query: str, stream_callback=None) -> Dict[str, Any]:
        """An√°lisis sem√°ntico completamente con LLM - SIN HARDCODEO"""
        try:
            if not self.llm:
                return {'intent': 'sql_query', 'entities': [], 'concepts': []}
            
            prompt = f"""Eres un experto en an√°lisis sem√°ntico de consultas m√©dicas.

ANALIZA esta consulta: "{query}"

TAREA: Extrae informaci√≥n sem√°ntica completa usando solo tu conocimiento, sin patrones predefinidos.

RESPUESTA JSON:
{{
    "intent": "descripci√≥n de la intenci√≥n principal",
    "entities": ["entidad1", "entidad2"],
    "concepts": ["concepto1", "concepto2"],
    "query_type": "tipo de consulta",
    "complexity": "simple|medium|complex",
    "medical_focus": "enfoque m√©dico espec√≠fico"
}}"""

            response = _call_openai_native(self.llm, [{"role": "user", "content": prompt}], task_description="Analizando sem√°ntica de la consulta")
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if stream_callback and result:
                stream_callback(f"   - Intenci√≥n detectada: {result.get('intent', 'N/A')}")
            
            return result if result else {'intent': 'sql_query', 'entities': [], 'concepts': []}
            
        except Exception as e:
            logger.error(f"Error en an√°lisis sem√°ntico: {e}")
            return {'intent': 'sql_query', 'entities': [], 'concepts': []}

    async def _llm_map_medical_concepts(self, query: str, semantic_analysis: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """Mapeo de conceptos m√©dicos completamente con LLM - SIN HARDCODEO"""
        try:
            if not self.llm:
                return {'medical_concepts': [], 'clinical_intent': 'query'}
            
            prompt = f"""Eres un experto en terminolog√≠a m√©dica y conceptos cl√≠nicos.

CONSULTA: "{query}"
AN√ÅLISIS SEM√ÅNTICO: {semantic_analysis}

TAREA: Identifica conceptos m√©dicos espec√≠ficos usando solo tu conocimiento m√©dico, sin patrones predefinidos.

RESPUESTA JSON:
{{
    "medical_concepts": ["concepto_m√©dico1", "concepto_m√©dico2"],
    "clinical_intent": "intenci√≥n cl√≠nica espec√≠fica",
    "medical_entities": ["entidad_m√©dica1", "entidad_m√©dica2"],
    "specialized_terms": ["t√©rmino_especializado1", "t√©rmino_especializado2"]
}}"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Mapeando conceptos m√©dicos"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if stream_callback and result:
                concepts = result.get('medical_concepts', [])
                stream_callback(f"   - Conceptos m√©dicos: {', '.join(concepts[:3])}...")
            
            return result if result else {'medical_concepts': [], 'clinical_intent': 'query'}
            
        except Exception as e:
            logger.error(f"Error en mapeo m√©dico: {e}")
            return {'medical_concepts': [], 'clinical_intent': 'query'}

    async def _llm_select_tables(self, query: str, medical_mapping: Dict[str, Any], stream_callback=None) -> List[str]:
        """Selecci√≥n de tablas completamente con LLM - SIN HARDCODEO"""
        try:
            if not self.llm:
                return list(self.schema_tools.get_schema().keys())[:3]
            
            # Usar el nuevo sistema inteligente sin hardcodeo
            medical_concepts = medical_mapping.get('medical_concepts', [])
            return await self._llm_select_relevant_tables_intelligent(query, medical_concepts, stream_callback)
            
        except Exception as e:
            logger.error(f"Error en selecci√≥n de tablas: {e}")
            return list(self.schema_tools.get_schema().keys())[:3]

    async def _llm_analyze_relationships(self, query: str, tables: List[str], stream_callback=None) -> Dict[str, Any]:
        """An√°lisis de relaciones completamente con LLM - SIN HARDCODEO"""
        try:
            if not self.llm:
                return {'join_conditions': [], 'relationships': []}
            
            fk_graph = self.schema_tools.get_fk_graph()
            schema = self.schema_tools.get_schema()
            
            # Obtener informaci√≥n de relaciones para las tablas seleccionadas
            relationship_info = {}
            for table in tables:
                if table in fk_graph:
                    relationship_info[table] = fk_graph[table]
                if table in schema:
                    relationship_info[f"{table}_columns"] = [col['name'] for col in schema[table]]
            
            prompt = f"""Eres un experto en relaciones de bases de datos m√©dicas.

CONSULTA: "{query}"
TABLAS SELECCIONADAS: {tables}

INFORMACI√ìN DE RELACIONES:
{json.dumps(relationship_info, indent=2)}

TAREA: Analiza las relaciones entre tablas usando solo tu conocimiento, sin patrones predefinidos.

RESPUESTA JSON:
{{
    "join_conditions": [{{"table1": "tabla1", "table2": "tabla2", "condition": "condici√≥n"}}],
    "relationships": ["relaci√≥n1", "relaci√≥n2"],
    "join_strategy": "estrategia de uni√≥n recomendada"
}}"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Analizando relaciones entre tablas"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if stream_callback and result:
                joins = result.get('join_conditions', [])
                stream_callback(f"   - Relaciones detectadas: {len(joins)} join(s)")
            
            return result if result else {'join_conditions': [], 'relationships': []}
            
        except Exception as e:
            logger.error(f"Error en an√°lisis de relaciones: {e}")
            return {'join_conditions': [], 'relationships': []}

    async def _llm_generate_sql(self, query: str, tables: List[str], relationships: Dict[str, Any], stream_callback=None) -> str:
        """Generaci√≥n de SQL con prompts cortos y espec√≠ficos"""
        try:
            if not self.llm:
                return f"SELECT * FROM {tables[0]} LIMIT 10;"
            
            # DETECTAR SI ES CONSULTA DE DIAGN√ìSTICO
            query_lower = query.lower()
            diagnosis_keywords = ['s√≠ndrome', 'diabetes', 'c√°ncer', 'hipertensi√≥n', 'asma', 'epilepsia', 'depresi√≥n', 'ansiedad', 'ovario poliqu√≠stico']
            
            if any(keyword in query_lower for keyword in diagnosis_keywords):
                # USAR PROMPT CORTO PARA DIAGN√ìSTICOS
                condition = next((keyword for keyword in diagnosis_keywords if keyword in query_lower), 'condici√≥n')
                sql = await self._generate_diagnosis_sql_simple(query, condition)
                if stream_callback:
                    stream_callback("   ‚úÖ SQL de diagn√≥stico generado")
                return sql
            
            # DETECTAR SI ES CONSULTA DE √öLTIMO PACIENTE USANDO LLM
            if self.llm:
                detection_prompt = f"""Analiza esta consulta y determina si se refiere al √öLTIMO PACIENTE registrado en la base de datos.

CONSULTA: "{query}"

CRITERIOS PARA DETECTAR CONSULTAS DE √öLTIMO PACIENTE:
- Palabras clave: "√∫ltimo", "ultimo", "√∫ltima", "ultima", "reciente", "creado", "registrado"
- Frases: "√∫ltimo paciente", "ultimo paciente", "√∫ltimo paciente creado", "ultimo paciente creado"
- Preguntas: "¬øCu√°l es el √∫ltimo paciente?", "¬øQui√©n es el √∫ltimo paciente?", "¬øDime el √∫ltimo paciente?"
- Variaciones: "cual es el ultimo", "cu√°l es el √∫ltimo", "dime el ultimo", "dime el √∫ltimo", "quien es el ultimo", "qui√©n es el √∫ltimo"

Responde SOLO con "S√ç" si es una consulta de √∫ltimo paciente, o "NO" si no lo es."""

                try:
                    detection_response = _call_openai_native(self.llm, detection_prompt)
                    detection_result = self._extract_response_text(detection_response).strip().upper()
                    
                    if "S√ç" in detection_result or "SI" in detection_result:
                        print(f"   üîç DETECTADO POR LLM: Consulta de √∫ltimo paciente - '{query}'")
                        sql = await self._generate_last_patient_sql_simple(query)
                        if stream_callback:
                            stream_callback("   ‚úÖ SQL de √∫ltimo paciente generado")
                        return sql
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Error en detecci√≥n LLM: {e}")
                    # Fallback a detecci√≥n b√°sica si LLM falla
                    last_patient_keywords = ['√∫ltimo', 'ultimo', '√∫ltima', 'ultima', 'reciente', 'creado', 'registrado', '√∫ltimo paciente', 'ultimo paciente']
                    if any(keyword in query_lower for keyword in last_patient_keywords):
                        print(f"   üîç DETECTADO POR FALLBACK: Consulta de √∫ltimo paciente - '{query}'")
                        sql = await self._generate_last_patient_sql_simple(query)
                        if stream_callback:
                            stream_callback("   ‚úÖ SQL de √∫ltimo paciente generado")
                        return sql
            
            # PROMPT CORTO PARA OTRAS CONSULTAS
            sql_prompt = f"""Genera SQL para: "{query}"

REGLAS:
- Para diagn√≥sticos: JOIN PATI_PATIENTS p ON p.PATI_ID = d.PATI_ID
- Para medicaci√≥n: usar PATI_USUAL_MEDICATION.PAUM_OBSERVATIONS
- Para conteos: COUNT(DISTINCT p.PATI_ID)
- Buscar en DIAG_OBSERVATION con LIKE '%termino%'
- Para √∫ltimo paciente: usar PATI_ID DESC (NO PATI_START_DATE)
- Para nombres: usar PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME

SQL:"""
            
            response = _call_openai_native(self.llm, sql_prompt)
            sql = self._extract_response_text(response).strip()
            sql = self._clean_llm_sql_response(sql)
            
            if stream_callback:
                stream_callback("   ‚úÖ SQL generado con IA din√°mica")
            
            return sql if sql and not sql.startswith("Error") else f"SELECT * FROM {tables[0]} LIMIT 10;"
            
        except Exception as e:
            logger.error(f"Error en generaci√≥n de SQL: {e}")
            return f"SELECT * FROM {tables[0]} LIMIT 10;"

    async def _generate_diagnosis_sql_simple(self, query: str, condition: str) -> str:
        """Genera SQL espec√≠fico para diagn√≥sticos con prompt corto"""
        try:
            if not self.llm:
                return f"SELECT p.PATI_ID, d.DIAG_OBSERVATION FROM PATI_PATIENTS p JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%{condition}%'"
            
            prompt = f"""Genera SQL para buscar pacientes con {condition}.

REGLAS:
- JOIN PATI_PATIENTS p ON p.PATI_ID = d.PATI_ID
- Buscar en d.DIAG_OBSERVATION LIKE '%{condition}%'
- Incluir p.PATI_ID y d.DIAG_OBSERVATION

SQL:"""
            
            response = _call_openai_native(self.llm, prompt)
            sql = self._extract_response_text(response).strip()
            
            return sql if sql and sql.upper().startswith('SELECT') else f"SELECT p.PATI_ID, d.DIAG_OBSERVATION FROM PATI_PATIENTS p JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%{condition}%'"
            
        except Exception as e:
            logger.error(f"Error en SQL de diagn√≥stico: {e}")
            return f"SELECT p.PATI_ID, d.DIAG_OBSERVATION FROM PATI_PATIENTS p JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%{condition}%'"

    async def _generate_last_patient_sql_simple(self, query: str) -> str:
        """Genera SQL espec√≠fico para √∫ltimo paciente con doble llamada al LLM"""
        try:
            if not self.llm:
                return "SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME FROM PATI_PATIENTS ORDER BY PATI_ID DESC LIMIT 1"
            
            # PRIMERA LLAMADA: Detectar si es consulta de √∫ltimo paciente
            detection_prompt = f"""Analiza esta consulta y determina si se refiere al √öLTIMO PACIENTE registrado en la base de datos.

CONSULTA: "{query}"

CRITERIOS PARA DETECTAR CONSULTAS DE √öLTIMO PACIENTE:
- Palabras clave: "√∫ltimo", "ultimo", "√∫ltima", "ultima", "reciente", "creado", "registrado"
- Frases: "√∫ltimo paciente", "ultimo paciente", "√∫ltimo paciente creado", "ultimo paciente creado"
- Preguntas: "¬øCu√°l es el √∫ltimo paciente?", "¬øQui√©n es el √∫ltimo paciente?", "¬øDime el √∫ltimo paciente?"

Responde SOLO con "S√ç" si es una consulta de √∫ltimo paciente, o "NO" si no lo es."""

            print(f"   üîç PRIMERA LLAMADA: Detectando consulta de √∫ltimo paciente...")
            detection_response = _call_openai_native(self.llm, detection_prompt)
            detection_result = self._extract_response_text(detection_response).strip().upper()
            
            if "S√ç" not in detection_result and "SI" not in detection_result:
                print(f"   ‚ùå No se detect√≥ como consulta de √∫ltimo paciente")
                return "SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME FROM PATI_PATIENTS ORDER BY PATI_ID DESC LIMIT 1"
            
            # SEGUNDA LLAMADA: Generar SQL optimizado para √∫ltimo paciente
            sql_prompt = f"""Genera una consulta SQL optimizada para obtener informaci√≥n del √öLTIMO PACIENTE registrado en la base de datos.

CONSULTA ORIGINAL: "{query}"

REGLAS OBLIGATORIAS:
- Usar SOLO PATI_ID DESC para determinar el √∫ltimo paciente (NO usar PATI_START_DATE ni PATI_UPDATE_DATE)
- Incluir campos: PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME
- Usar ORDER BY PATI_ID DESC LIMIT 1
- Tabla: PATI_PATIENTS

EJEMPLO CORRECTO:
SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME 
FROM PATI_PATIENTS 
ORDER BY PATI_ID DESC 
LIMIT 1

IMPORTANTE:
- NUNCA usar ORDER BY PATI_START_DATE DESC
- NUNCA usar ORDER BY PATI_UPDATE_DATE DESC
- SIEMPRE usar ORDER BY PATI_ID DESC

SQL:"""

            print(f"   üß† SEGUNDA LLAMADA: Generando SQL optimizado para √∫ltimo paciente...")
            sql_response = _call_openai_native(self.llm, sql_prompt)
            sql = self._extract_response_text(sql_response).strip()
            sql = self._clean_llm_sql_response(sql)
            
            # Validar que el SQL generado sea correcto
            if sql and sql.upper().startswith('SELECT') and 'ORDER BY PATI_ID DESC' in sql.upper():
                print(f"   ‚úÖ SQL de √∫ltimo paciente generado correctamente")
                return sql
            else:
                print(f"   ‚ö†Ô∏è SQL generado incorrecto, usando fallback")
                return "SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME FROM PATI_PATIENTS ORDER BY PATI_ID DESC LIMIT 1"
            
        except Exception as e:
            logger.error(f"Error en SQL de √∫ltimo paciente: {e}")
            return "SELECT PATI_ID, PATI_NAME, PATI_SURNAME_1, PATI_FULL_NAME FROM PATI_PATIENTS ORDER BY PATI_ID DESC LIMIT 1"

    async def _llm_validate_and_optimize_sql(self, query: str, sql: str, stream_callback=None) -> str:
        """Validaci√≥n y optimizaci√≥n completamente con LLM usando m√∫ltiples llamadas din√°micas"""
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - Validando y optimizando SQL con IA din√°mica...")
            
            # PRIMERA LLAMADA: An√°lisis de problemas potenciales
            analysis_prompt = f"""Eres un experto en an√°lisis de SQL m√©dico. Analiza este SQL y identifica problemas potenciales.

CONSULTA ORIGINAL: "{query}"
SQL A VALIDAR: "{sql}"

INSTRUCCIONES:
1. Analiza la sintaxis del SQL
2. Identifica problemas de compatibilidad con SQLite
3. Detecta posibles errores de tablas o columnas
4. Sugiere optimizaciones
5. Considera casos edge y errores comunes
6. Analiza si el SQL responde completamente a la consulta

RESPUESTA: JSON con an√°lisis de problemas"""

            print(f"   üîç PRIMERA LLAMADA: Analizando problemas potenciales...")
            analysis_response = _call_openai_native(self.llm, analysis_prompt)
            analysis_result = self._try_parse_llm_json(analysis_response.content)
            
            if not analysis_result:
                print(f"   ‚ùå No se pudo analizar problemas")
                return sql

            # SEGUNDA LLAMADA: Correcci√≥n basada en an√°lisis
            correction_prompt = f"""Eres un experto en correcci√≥n de SQL m√©dico. Corrige este SQL basado en el an√°lisis previo.

CONSULTA ORIGINAL: "{query}"
SQL ORIGINAL: "{sql}"

AN√ÅLISIS DE PROBLEMAS:
{json.dumps(analysis_result, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Usa el an√°lisis previo para corregir problemas
2. Optimiza para SQLite
3. Corrige errores de sintaxis
4. Maneja casos edge
5. Considera m√∫ltiples formas de representar la misma informaci√≥n
6. Aseg√∫rate de que responda completamente a la consulta

REGLAS DE CORRECCI√ìN:
- Mant√©n la funcionalidad original
- Optimiza para rendimiento
- Maneja errores de manera robusta
- Considera diferentes estructuras de base de datos
- Usa solo tablas y columnas que existen

RESPUESTA: SQL corregido y optimizado"""

            print(f"   üß† SEGUNDA LLAMADA: Corrigiendo SQL con contexto...")
            correction_response = _call_openai_native(self.llm, correction_prompt)
            
            corrected_sql = self._extract_response_text(correction_response).strip()
            corrected_sql = self._clean_llm_sql_response(corrected_sql)
            
            if corrected_sql and not corrected_sql.startswith("Error"):
                sql = corrected_sql
            
            # PASO 3: Validaci√≥n final con esquema robusto
            sql = await self._validate_schema_with_robust_tools(sql, stream_callback)
            
            if stream_callback:
                stream_callback("   ‚úÖ SQL validado y optimizado con IA din√°mica")
            
            return sql
            
        except Exception as e:
            logger.error(f"Error en validaci√≥n y optimizaci√≥n: {e}")
            return sql

    async def _regenerate_complete_sql(self, query: str, incomplete_sql: str, missing_tables: List[str], stream_callback=None) -> str:
        """Regenera SQL completo usando LLM con informaci√≥n de tablas faltantes"""
        try:
            if not self.llm:
                return incomplete_sql
            
            if stream_callback:
                stream_callback("   - Regenerando SQL completo con IA...")
            
            # Obtener esquema disponible
            schema = self.schema_tools.get_schema()
            schema_info = {}
            for table_name, columns in schema.items():
                schema_info[table_name] = [col['name'] for col in columns]
            
            prompt = f"""Eres un experto en SQL que regenera consultas completas.

CONSULTA ORIGINAL: "{query}"

SQL INCOMPLETO:
{incomplete_sql}

TABLAS FALTANTES IDENTIFICADAS:
{', '.join(missing_tables)}

ESQUEMA DISPONIBLE:
{json.dumps(schema_info, indent=2, ensure_ascii=False)}

TAREA: Regenera el SQL para incluir todas las tablas necesarias.

INSTRUCCIONES:
1. Analiza la consulta original para entender qu√© informaci√≥n se necesita
2. Incluye las tablas faltantes identificadas
3. Usa JOINs apropiados para conectar las tablas
4. Mant√©n la l√≥gica original de la consulta
5. Aseg√∫rate de que el SQL sea sint√°cticamente correcto
6. Usa solo tablas y columnas que existen en el esquema

EJEMPLOS DE CONEXI√ìN:
- PATI_PATIENTS.PATI_ID = EPIS_EPISODES.PATI_ID
- EPIS_EPISODES.EPIS_ID = EPIS_DIAGNOSTICS.EPIS_ID
- PATI_PATIENTS.PATI_ID = OBSE_OBSERVATIONS.PATI_ID

RESPUESTA:
Devuelve SOLO el SQL completo y corregido, sin explicaciones."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Regenerando SQL completo"
            )
            
            complete_sql = self._extract_response_text(response).strip()
            complete_sql = self._clean_llm_sql_response(complete_sql)
            
            if complete_sql and not complete_sql.startswith("Error"):
                if stream_callback:
                    stream_callback("   ‚úÖ SQL completo regenerado")
                return complete_sql
            else:
                logger.warning("LLM no pudo regenerar SQL completo")
                return incomplete_sql
                
        except Exception as e:
            logger.error(f"Error regenerando SQL completo: {e}")
            return incomplete_sql

    async def _llm_clean_sql_before_execution(self, sql: str, stream_callback=None) -> str:
        """
        Usa el LLM para limpiar errores de sintaxis SQL de forma gen√©rica antes de ejecutar.
        
        Args:
            sql: SQL a limpiar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL limpio y corregido
        """
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - Limpiando errores de sintaxis SQL con IA...")
            
            prompt = f"""Eres un experto en SQL que corrige errores de sintaxis de forma gen√©rica.

SQL A CORREGIR:
{sql}

TAREA: Corrige cualquier error de sintaxis que encuentres, especialmente:
- Palabras pegadas a keywords SQL (ej: PacientesJOIN ‚Üí Pacientes JOIN)
- Espacios faltantes entre palabras clave
- Errores de formato comunes

INSTRUCCIONES:
1. NO uses patterns espec√≠ficos ni hardcodees keywords
2. Detecta cualquier palabra pegada a una palabra clave SQL de forma gen√©rica
3. A√±ade espacios donde falten
4. Mant√©n la l√≥gica original del SQL
5. Aseg√∫rate de que sea sint√°cticamente v√°lido

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Limpiando errores de sintaxis SQL"
            )
            
            cleaned_sql = self._extract_response_text(response).strip()
            cleaned_sql = self._clean_llm_sql_response(cleaned_sql)
            
            if cleaned_sql and not cleaned_sql.startswith("Error"):
                logger.info(f"üß† LLM limpi√≥ SQL exitosamente")
                if stream_callback:
                    stream_callback("   ‚úÖ Errores de sintaxis corregidos")
                return cleaned_sql
            else:
                logger.warning(f"‚ö†Ô∏è LLM no pudo limpiar SQL, usando original")
                return sql
                
        except Exception as e:
            logger.error(f"Error en _llm_clean_sql_before_execution: {e}")
            return sql

    async def _execute_sql_with_llm_validation(self, query: str, sql: str, start_time: float, sql_params: Optional[List[Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """Ejecuta SQL usando los m√≥dulos centralizados de limpieza y ejecuci√≥n con aprendizaje agresivo"""
        
        logger.info(f"üîç SQL original recibido: {sql[:200]}...")
        
        if stream_callback:
            stream_callback("üîç Optimizando y ejecutando consulta SQL...")
        
        try:
            # PASO 1: Limpiar y sanitizar el SQL
            if stream_callback:
                stream_callback("   - Limpiando y optimizando SQL...")
            
            # --- REFORZADO: limpiar errores de palabras pegadas antes de todo ---
            sql = self._fix_typo_errors(sql)
            cleaned_sql_temp = await self._basic_sql_cleanup(sql)
            
            cleaned_sql = SQLCleaner.sanitize_for_execution(cleaned_sql_temp)
            
            # Aplicar correcciones espec√≠ficas de compatibilidad
            cleaned_sql = await self._fix_sql_compatibility(cleaned_sql, stream_callback)
            
            # NUEVO: An√°lisis flexible con prompts espec√≠ficos seg√∫n el contexto
            cleaned_sql = await self._llm_flexible_sql_analysis(cleaned_sql, query, stream_callback)
            
            # NUEVO: Validar esquema con herramientas robustas
            cleaned_sql = await self._validate_schema_with_robust_tools(cleaned_sql, stream_callback)
            
            # Aplicar correcciones de sintaxis
            cleaned_sql = SQLCleaner.fix_common_syntax_errors(cleaned_sql)
            
            logger.info(f"‚úÖ SQL limpio y listo: {cleaned_sql[:200]}...")
            
            # PASO 2: Validar sintaxis antes de ejecutar
            if stream_callback:
                stream_callback("   - Validando sintaxis SQL...")
                
            executor = SQLExecutor(self.db_path)
            is_valid, syntax_error = executor.test_query_syntax(cleaned_sql)
            
            if not is_valid:
                logger.error(f"‚ùå Error de sintaxis SQL: {syntax_error}")
                
                # SISTEMA DE RECUPERACI√ìN MEJORADO: Aplicar correcciones autom√°ticas basadas en patrones
                if stream_callback:
                    stream_callback("   - Error de sintaxis detectado, aplicando correcciones autom√°ticas...")
                
                # Aplicar correcciones autom√°ticas basadas en patrones de error
                corrected_sql = await self._apply_automatic_error_corrections(cleaned_sql, syntax_error or "Error de sintaxis", stream_callback)
                
                if corrected_sql and corrected_sql != cleaned_sql:
                    logger.info(f"üîÑ SQL corregido autom√°ticamente despu√©s de error")
                    # Ejecutar el SQL corregido
                    return await self._execute_sql_with_llm_validation(query, corrected_sql, start_time, sql_params, stream_callback)
                else:
                    return {
                        'success': False,
                        'message': f'‚ùå Error de sintaxis SQL: {syntax_error}',
                        'data': [],
                        'sql_query': cleaned_sql,
                        'error': syntax_error
                    }
            
            # PASO 3: Verificar y ajustar par√°metros
            sql_params = sql_params or []
            placeholder_count = cleaned_sql.count('?')
            
            # NORMALIZAR PAR√ÅMETROS si contienen nombres
            normalized_params = []
            for param in sql_params:
                if isinstance(param, str) and param:
                    # Normalizar el par√°metro usando nuestra funci√≥n ROBUSTA
                    normalized_param = self._normalize_accents_python(param)
                    normalized_params.append(normalized_param)
                else:
                    normalized_params.append(param)
            
            sql_params = normalized_params
            
            # PASO 4: Ejecutar con el m√≥dulo ejecutor
            if stream_callback:
                stream_callback("   - Ejecutando consulta en la base de datos...")
                
            result = executor.execute_query(cleaned_sql, sql_params)
            
            # PASO 5: Procesar resultado
            if result['success']:
                if stream_callback:
                    stream_callback(f"   ‚úÖ Consulta completada: {result['row_count']} resultados en {result['execution_time']:.2f}s")
                
                return {
                    'success': True,
                    'message': f'‚úÖ Encontrados {result["row_count"]} resultados',
                    'data': result['data'],
                    'sql_query': cleaned_sql,
                    'execution_time': result['execution_time'],
                    'total_time': time.time() - start_time
                }
            else:
                if stream_callback:
                    stream_callback(f"   ‚ùå Error ejecutando SQL: {result['error'][:100]}")
                
                # SISTEMA DE APRENDIZAJE AGRESIVO: Aplicar correcciones basadas en el error espec√≠fico
                corrected_sql = await self._apply_error_based_corrections(cleaned_sql, result['error'], stream_callback)
                
                if corrected_sql and corrected_sql != cleaned_sql:
                    logger.info(f"üîÑ Aplicando correcci√≥n basada en error: {result['error'][:50]}")
                    return await self._execute_sql_with_llm_validation(query, corrected_sql, start_time, sql_params, stream_callback)
                else:
                    return {
                        'success': False,
                        'message': f'‚ùå Error ejecutando consulta: {result["error"]}',
                        'data': [],
                        'sql_query': cleaned_sql,
                        'error': result['error']
                    }
                
        except Exception as e:
            # Manejo de errores generales
            error_msg = str(e)
            logger.error(f"‚ùå Error en _execute_sql_with_learning: {error_msg}")
            
            if stream_callback:
                stream_callback(f"   ‚ùå Error inesperado: {error_msg[:100]}")
            
            return {
                'success': False,
                'message': f'‚ùå Error procesando consulta: {error_msg}',
                'data': [],
                'sql_query': sql,
                'error': error_msg
            }

    async def _apply_automatic_error_corrections(self, sql: str, error_message: str, stream_callback=None) -> str:
        """
        Aplica correcciones autom√°ticas basadas en el mensaje de error.
        Maneja espec√≠ficamente errores de alias no definidos.
        """
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   üîß Aplicando correcciones autom√°ticas...")
            
            # Detectar errores espec√≠ficos
            error_lower = error_message.lower()
            
            # Error de alias no definido
            if "no such column" in error_lower and "." in error_message:
                # Extraer el alias problem√°tico
                import re
                alias_match = re.search(r'(\w+)\.(\w+)', error_message)
                if alias_match:
                    problematic_alias = alias_match.group(1)
                    column_name = alias_match.group(2)
                    
                    if stream_callback:
                        stream_callback(f"   ‚ö†Ô∏è Detectado alias no definido: {problematic_alias}")
                    
                    # Corregir usando LLM
                    prompt = f"""Eres un experto en SQL que corrige errores de alias no definidos.

SQL CON ERROR:
{sql}

ERROR DETECTADO:
{error_message}

PROBLEMA: El alias '{problematic_alias}' no est√° definido en el FROM o JOIN.

TAREA: Corrige el SQL para:
1. Definir correctamente el alias en el FROM/JOIN
2. O eliminar el alias si no es necesario
3. Asegurar que todas las referencias de columnas sean v√°lidas

REGLAS:
- Usa solo tablas que existen en la base de datos
- Aseg√∫rate de que los alias est√©n definidos
- Mant√©n la l√≥gica original de la consulta
- Optimiza para SQLite

RESPUESTA: SOLO el SQL corregido, sin explicaciones."""

                    response = await asyncio.to_thread(
                        _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                        task_description="Corrigiendo alias no definido"
                    )
                    
                    corrected_sql = self._extract_response_text(response).strip()
                    corrected_sql = self._clean_llm_sql_response(corrected_sql)
                    
                    if corrected_sql and not corrected_sql.startswith("Error"):
                        if stream_callback:
                            stream_callback("   ‚úÖ Alias corregido autom√°ticamente")
                        return corrected_sql
            
            # Otros errores - usar LLM gen√©rico
            prompt = f"""Eres un experto en SQL que corrige errores de sintaxis.

SQL CON ERROR:
{sql}

ERROR DETECTADO:
{error_message}

TAREA: Corrige el SQL para eliminar el error espec√≠fico.

REGLAS:
- Mant√©n la l√≥gica original de la consulta
- Usa solo tablas y columnas que existen
- Optimiza para SQLite
- Aseg√∫rate de que la sintaxis sea correcta

RESPUESTA: SOLO el SQL corregido, sin explicaciones."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Corrigiendo error SQL"
            )
            
            corrected_sql = self._extract_response_text(response).strip()
            corrected_sql = self._clean_llm_sql_response(corrected_sql)
            
            if corrected_sql and not corrected_sql.startswith("Error"):
                if stream_callback:
                    stream_callback("   ‚úÖ Error corregido autom√°ticamente")
                return corrected_sql
            else:
                if stream_callback:
                    stream_callback("   ‚ö†Ô∏è No se pudo corregir autom√°ticamente")
                return sql
                
        except Exception as e:
            logger.error(f"Error en correcci√≥n autom√°tica: {e}")
            return sql
        
    async def _apply_error_based_corrections(self, sql: str, error_message: str, stream_callback=None) -> str:
        """
        Aplica correcciones espec√≠ficas usando LLM con prompts espec√≠ficos.
        SIN PATRONES HARDCODEADOS - todo via LLM.
        """
        try:
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Correcci√≥n espec√≠fica no disponible (sin LLM)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Aplicando correcciones espec√≠ficas con IA...")
            
            # Prompt espec√≠fico para correcci√≥n basada en error
            correction_prompt = f"""Eres un experto en SQL que corrige errores espec√≠ficos.

SQL CON ERROR:
{sql}

MENSAJE DE ERROR ESPEC√çFICO:
{error_message}

TAREA:
Analiza este error espec√≠fico y corrige SOLO el problema mencionado.

INSTRUCCIONES:
1. Enf√≥cate √öNICAMENTE en el error espec√≠fico mencionado
2. Corrige SOLO el problema exacto
3. NO a√±adas l√≥gica adicional
4. Mant√©n la intenci√≥n original del SQL
5. Usa columnas y tablas que realmente existan

ESQUEMA DISPONIBLE:
{self.schema_tools.get_schema()}

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones."""

            try:
                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": correction_prompt}]
                )
                
                corrected_sql = self._extract_response_text(response).strip()
                corrected_sql = self._clean_llm_sql_response(corrected_sql)
                
                if corrected_sql and corrected_sql != sql and not corrected_sql.startswith("Error"):
                    logger.info(f"üß† LLM corrigi√≥ error espec√≠fico: {error_message[:50]}...")
                    logger.info(f"   SQL original: {sql[:100]}...")
                    logger.info(f"   SQL corregido: {corrected_sql[:100]}...")
                    
                    if stream_callback:
                        stream_callback("   - Correcci√≥n espec√≠fica aplicada con IA")
                    
                    return corrected_sql
                else:
                    if stream_callback:
                        stream_callback("   - No se pudo aplicar correcci√≥n espec√≠fica")
                    return sql
                    
            except Exception as e:
                logger.warning(f"Error usando LLM para correcci√≥n espec√≠fica: {e}")
                if stream_callback:
                    stream_callback(f"   - Error en correcci√≥n espec√≠fica: {str(e)[:50]}...")
                return sql
            
        except Exception as e:
            logger.error(f"Error en _apply_error_based_corrections: {e}")
            return sql

    async def _llm_interpret_medical_results(self, query: str, data: List[Dict[str, Any]], stream_callback=None) -> str:
        """Interpretaci√≥n m√©dica usando MedGemma cuando est√° disponible, o LLM como fallback"""
        try:
            if not data:
                return "No hay datos para interpretar."
            
            # USAR MEDGEMMA SI EST√Å DISPONIBLE
            if self.medgemma_agent:
                if stream_callback:
                    stream_callback("   üß† Usando MedGemma para an√°lisis cl√≠nico avanzado...")
                
                try:
                    # Preparar datos para MedGemma
                    medical_data = {
                        'query': query,
                        'results': data[:10],  # Limitar a 10 registros
                        'context': 'Resultados de consulta SQL m√©dica'
                    }
                    
                    # Analizar con MedGemma
                    medgemma_result = await self.medgemma_agent.analyze_clinical_data(
                        json.dumps(medical_data, indent=2, ensure_ascii=False),
                        stream_callback
                    )
                    
                    if medgemma_result and medgemma_result.get('success'):
                        interpretation = medgemma_result.get('analysis', '')
                        if interpretation:
                            if stream_callback:
                                stream_callback("   ‚úÖ An√°lisis cl√≠nico con MedGemma completado")
                            return interpretation
                    
                    # Si MedGemma falla, continuar con LLM
                    if stream_callback:
                        stream_callback("   ‚ö†Ô∏è MedGemma no disponible, usando LLM...")
                        
                except Exception as e:
                    if stream_callback:
                        stream_callback(f"   ‚ö†Ô∏è Error con MedGemma: {e}, usando LLM...")
            
            # FALLBACK A LLM
            if not self.llm:
                return f"Se encontraron {len(data)} resultados m√©dicos."
            
            prompt = f"""Eres un m√©dico experto que interpreta resultados de bases de datos m√©dicas.

CONSULTA ORIGINAL: "{query}"
DATOS ENCONTRADOS ({len(data)} registros):
{json.dumps(data[:10], indent=2, ensure_ascii=False)}

TAREA: Proporciona una interpretaci√≥n m√©dica clara y √∫til usando solo tu conocimiento m√©dico, sin patrones predefinidos.

INSTRUCCIONES ESPEC√çFICAS:
- Analiza los datos desde una perspectiva m√©dica
- Identifica informaci√≥n cl√≠nicamente relevante
- Destaca hallazgos importantes
- Proporciona contexto m√©dico cuando sea apropiado
- Sugiere interpretaciones √∫tiles

PARA RANKINGS DE MEDICAMENTOS:
- Lista los medicamentos en orden de mayor a menor prescripci√≥n
- Menciona el n√∫mero exacto de prescripciones para cada medicamento
- Si hay empates, ind√≠calo claramente
- Proporciona contexto cl√≠nico sobre los medicamentos m√°s prescritos
- Sugiere posibles razones para el patr√≥n de prescripci√≥n observado

RESPUESTA: Interpretaci√≥n m√©dica clara y profesional en espa√±ol."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Interpretando resultados m√©dicos"
            )
            
            interpretation = self._extract_response_text(response)
            
            if stream_callback:
                stream_callback("   ‚úÖ Interpretaci√≥n m√©dica completada")
            
            return interpretation if interpretation else f"Se encontraron {len(data)} resultados m√©dicos."
            
        except Exception as e:
            logger.error(f"Error en interpretaci√≥n m√©dica: {e}")
            return f"Se encontraron {len(data)} resultados m√©dicos."

    def _get_schema_summary_for_llm(self, schema: Dict[str, Any]) -> str:
        """Genera resumen del esquema para el LLM"""
        try:
            summary = []
            for table_name, columns in schema.items():
                if table_name.startswith('sqlite_'):
                    continue
                column_names = [col['name'] for col in columns]
                summary.append(f"{table_name}: {', '.join(column_names)}")
            return "\n".join(summary)
        except Exception as e:
            logger.error(f"Error generando resumen del esquema: {e}")
            return "Error generando resumen del esquema"

    def _extract_response_text(self, response) -> str:
        """Extrae el texto de la respuesta del LLM"""
        if hasattr(response, 'content'):
            return response.content
        return str(response)

    def _try_parse_llm_json(self, content: str) -> Optional[Dict[str, Any]]:
        """Intenta parsear JSON de respuesta del LLM de forma robusta y tolerante a errores."""
        import re
        import ast
        try:
            content = content.strip()
            
            # ESTRATEGIA 1: Limpiar markdown y buscar primer bloque JSON
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            if content.startswith('```'):
                content = content[3:]
            
            # ESTRATEGIA 2: Buscar primer bloque {...} completo
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group(0))
                except Exception:
                    # Intentar con ast.literal_eval si hay comillas simples
                    try:
                        return ast.literal_eval(json_match.group(0))
                    except Exception:
                        pass
            
            # ESTRATEGIA 3: Intentar parsear directamente
            try:
                return json.loads(content)
            except Exception:
                pass
            
            # ESTRATEGIA 4: Limpiar comillas simples/dobles y reintentar
            content_fixed = content.replace("'", '"')
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content_fixed, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group(0))
                except Exception:
                    pass
                try:
                    return json.loads(content_fixed)
                except Exception:
                    pass
            
            # ESTRATEGIA 5: Buscar m√∫ltiples objetos JSON y usar el m√°s completo
            json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content)
            if json_objects:
                # Intentar con cada objeto JSON encontrado, empezando por el m√°s largo
                json_objects.sort(key=len, reverse=True)
                for json_obj in json_objects:
                    try:
                        return json.loads(json_obj)
                    except Exception:
                        continue
            
            # ESTRATEGIA 6: Reparar JSON incompleto
            try:
                # Si termina con coma, quitarla y a√±adir llave de cierre
                if content.strip().endswith(','):
                    content = content.rstrip(',') + '}'
                    return json.loads(content)
                
                # Si no termina con }, a√±adir llave de cierre
                if not content.strip().endswith('}'):
                    content = content.strip() + '}'
                    return json.loads(content)
                
                # Si empieza con { pero no termina con }, intentar cerrar
                if content.strip().startswith('{') and not content.strip().endswith('}'):
                    # Buscar el √∫ltimo } v√°lido y a√±adir llaves de cierre faltantes
                    last_brace = content.rfind('}')
                    if last_brace > 0:
                        content = content[:last_brace+1]
                        return json.loads(content)
                    else:
                        content = content.strip() + '}'
                        return json.loads(content)
                        
            except Exception:
                pass
            
            # ESTRATEGIA 7: Reparaci√≥n agresiva - intentar cerrar objetos anidados
            try:
                # Contar llaves abiertas y cerradas
                open_braces = content.count('{')
                close_braces = content.count('}')
                
                if open_braces > close_braces:
                    # A√±adir llaves de cierre faltantes
                    missing_braces = open_braces - close_braces
                    content = content.strip() + '}' * missing_braces
                    return json.loads(content)
                    
            except Exception:
                pass
            
            # ESTRATEGIA 8: Extraer solo el primer objeto JSON v√°lido
            try:
                # Buscar el primer { y el √∫ltimo } correspondiente
                start = content.find('{')
                if start >= 0:
                    brace_count = 0
                    end = start
                    for i, char in enumerate(content[start:], start):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                end = i + 1
                                break
                    
                    if end > start:
                        json_part = content[start:end]
                        return json.loads(json_part)
                        
            except Exception:
                pass
            
            # ESTRATEGIA 9: √öltimo intento - limpiar y reparar
            try:
                # Eliminar caracteres problem√°ticos
                content_clean = re.sub(r'[^\x20-\x7E]', '', content)
                content_clean = content_clean.replace('\n', ' ').replace('\r', ' ')
                content_clean = re.sub(r'\s+', ' ', content_clean)
                
                # Buscar JSON en el contenido limpio
                json_match = re.search(r'\{.*?\}', content_clean, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group(0))
                    
            except Exception:
                pass
            
            # ESTRATEGIA 10: Reparaci√≥n de JSON con comillas malformadas
            try:
                # Buscar patrones de comillas problem√°ticas
                content_fixed = content
                # Corregir comillas simples dentro de strings
                content_fixed = re.sub(r"'([^']*)'", r'"\1"', content_fixed)
                # Corregir comillas dobles sin escapar
                content_fixed = re.sub(r'"([^"]*)"([^"]*)"', r'"\1\2"', content_fixed)
                
                return json.loads(content_fixed)
            except Exception:
                pass
            
            # ESTRATEGIA 11: Extracci√≥n de JSON desde respuestas mixtas
            try:
                # Buscar el primer { y el √∫ltimo } v√°lido
                start_idx = content.find('{')
                end_idx = content.rfind('}')
                
                if start_idx >= 0 and end_idx > start_idx:
                    json_part = content[start_idx:end_idx + 1]
                    # Intentar reparar el JSON extra√≠do
                    json_part = re.sub(r',\s*}', '}', json_part)  # Quitar comas finales
                    json_part = re.sub(r',\s*]', ']', json_part)  # Quitar comas finales en arrays
                    return json.loads(json_part)
            except Exception:
                pass
            
            # ESTRATEGIA 12: Reparaci√≥n agresiva de estructura JSON
            try:
                # Intentar cerrar objetos JSON incompletos
                if content.count('{') > content.count('}'):
                    # A√±adir llaves de cierre faltantes
                    missing_braces = content.count('{') - content.count('}')
                    content_fixed = content + '}' * missing_braces
                    return json.loads(content_fixed)
                
                if content.count('[') > content.count(']'):
                    # A√±adir corchetes de cierre faltantes
                    missing_brackets = content.count('[') - content.count(']')
                    content_fixed = content + ']' * missing_brackets
                    return json.loads(content_fixed)
            except Exception:
                pass
            
            # ESTRATEGIA 13: √öltimo intento - crear JSON m√≠nimo
            try:
                # Si parece ser una respuesta de error, crear JSON de error
                if 'error' in content.lower() or 'failed' in content.lower():
                    return {
                        'error': True,
                        'message': content[:200],
                        'raw_content': content
                    }
                
                # Si parece ser una respuesta de √©xito, crear JSON de √©xito
                if 'success' in content.lower() or 'ok' in content.lower():
                    return {
                        'success': True,
                        'message': content[:200],
                        'raw_content': content
                    }
            except Exception:
                pass
            
            # ESTRATEGIA 14: Reparaci√≥n de JSON con arrays incompletos
            try:
                # Buscar arrays que no est√°n cerrados
                if content.count('[') > content.count(']'):
                    missing_brackets = content.count('[') - content.count(']')
                    content_fixed = content + ']' * missing_brackets
                    return json.loads(content_fixed)
            except Exception:
                pass
            
            # ESTRATEGIA 15: Extracci√≥n de JSON desde respuestas con texto adicional
            try:
                # Buscar el JSON m√°s largo en la respuesta
                json_patterns = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content)
                if json_patterns:
                    # Usar el JSON m√°s largo (probablemente el m√°s completo)
                    longest_json = max(json_patterns, key=len)
                    return json.loads(longest_json)
            except Exception:
                pass
            
            # ESTRATEGIA 16: Reparaci√≥n de JSON con valores NULL malformados
            try:
                # Corregir "NULL" strings a null
                content_fixed = content.replace('"NULL"', 'null')
                content_fixed = content_fixed.replace("'NULL'", 'null')
                content_fixed = content_fixed.replace('NULL', 'null')
                return json.loads(content_fixed)
            except Exception:
                pass
            
            # Si todo falla, loggear y devolver None
            logger.error(f"Error parseando JSON robusto: {content[:200]}...")
            return None
            
        except Exception as e:
            logger.error(f"Error cr√≠tico parseando JSON: {e}")
            return None

    def _clean_llm_sql_response(self, sql_response: str) -> str:
        """
        Limpia la respuesta del LLM usando el LLM para eliminar autom√°ticamente texto no-SQL.
        Sin listas hardcodeadas - todo via LLM.
        """
        try:
            if not sql_response or not self.llm:
                return sql_response
            
            # Si ya parece SQL puro, devolver sin cambios
            if sql_response.strip().upper().startswith('SELECT') or sql_response.strip().upper().startswith('WITH'):
                return sql_response
            
            # Usar LLM para extraer solo el SQL
            prompt = f"""Eres un experto en SQL que extrae solo c√≥digo SQL de respuestas mixtas.

RESPUESTA DEL LLM:
{sql_response}

TAREA:
Extrae SOLO el c√≥digo SQL de esta respuesta, eliminando:
- Explicaciones en espa√±ol
- Comentarios
- Texto explicativo
- Markdown (```sql, ```)
- Cualquier texto que no sea SQL v√°lido

REGLAS CR√çTICAS:
1. Devuelve SOLO el SQL puro
2. NO incluyas explicaciones
3. NO incluyas comentarios
4. Aseg√∫rate de que sea SQL v√°lido para SQLite
5. Si no hay SQL v√°lido, devuelve "SELECT 1 as error_no_sql;"

EJEMPLO:
Entrada: "Aqu√≠ est√° el SQL para contar pacientes: SELECT COUNT(*) FROM patients;"
Salida: "SELECT COUNT(*) FROM patients;"

Responde SOLO con el SQL extra√≠do:"""

            # Usar llamada s√≠ncrona en lugar de async
            response = _call_openai_native(self.llm, [{"role": "user", "content": prompt}])
            
            cleaned_sql = self._extract_response_text(response).strip()
            
            # Verificar que realmente es SQL
            if cleaned_sql and (cleaned_sql.upper().startswith('SELECT') or 
                               cleaned_sql.upper().startswith('WITH') or
                               cleaned_sql.upper().startswith('INSERT') or
                               cleaned_sql.upper().startswith('UPDATE') or
                               cleaned_sql.upper().startswith('DELETE')):
                return cleaned_sql
            else:
                # Fallback: intentar extraer SQL manualmente
                import re
                # Buscar patrones SQL comunes
                sql_patterns = [
                    r'SELECT\s+.*?;',  # SELECT statements
                    r'WITH\s+.*?;',    # CTE statements
                    r'INSERT\s+.*?;',  # INSERT statements
                    r'UPDATE\s+.*?;',  # UPDATE statements
                    r'DELETE\s+.*?;',  # DELETE statements
                ]
                
                for pattern in sql_patterns:
                    match = re.search(pattern, sql_response, re.IGNORECASE | re.DOTALL)
                    if match:
                        return match.group(0)
                
                # Si no se encuentra SQL v√°lido, devolver error
                return "SELECT 1 as error_no_valid_sql;"
                
        except Exception as e:
            logger.error(f"Error limpiando respuesta SQL: {e}")
            # Fallback b√°sico
            import re
            # Buscar SQL b√°sico
            sql_match = re.search(r'SELECT\s+.*?;', sql_response, re.IGNORECASE | re.DOTALL)
            if sql_match:
                return sql_match.group(0)
            return "SELECT 1 as error_cleaning_failed;"

    def _extract_sql_basic(self, text: str) -> str:
        """
        Extracci√≥n b√°sica de SQL sin LLM (fallback).
        Busca patrones SQL comunes en el texto.
        """
        try:
            if not text:
                return text
            
            # Buscar SQL que empiece con palabras clave comunes
            sql_patterns = [
                r'SELECT\s+.*?(?:;|$)',
                r'WITH\s+.*?(?:;|$)',
                r'INSERT\s+.*?(?:;|$)',
                r'UPDATE\s+.*?(?:;|$)',
                r'DELETE\s+.*?(?:;|$)'
            ]
            
            for pattern in sql_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
                if matches:
                    # Tomar el primer match que parezca SQL v√°lido
                    for match in matches:
                        if len(match.strip()) > 10:  # Filtrar fragmentos muy cortos
                            return match.strip()
            
            # Si no se encuentra SQL, devolver texto original
            return text
            
        except Exception as e:
            logger.error(f"Error en _extract_sql_basic: {e}")
            return text

    def _create_error_response(self, error: str, sql: str = "") -> Dict[str, Any]:
        return {'success': False, 'message': f"Error: {error}", 'data': [], 'sql_query': sql}
    
    async def _use_generic_sql_tools(self, query: str, stream_callback=None) -> str:
        """
        Usa el LLM para generar SQL de forma din√°mica y segura
        """
        try:
            if not self.llm:
                return "SELECT COUNT(*) FROM PATI_PATIENTS"
            
            if stream_callback:
                stream_callback("   üîß Generando SQL din√°mico con LLM...")
            
            # Obtener esquema de la base de datos
            schema_info = self._get_real_schema_info()
            
            # Prompt espec√≠fico para SQL m√©dico din√°mico
            prompt = f"""Eres un experto en SQL para bases de datos m√©dicas. Genera SQL v√°lido y seguro.

CONSULTA: "{query}"

ESQUEMA DE LA BASE DE DATOS:
{schema_info}

REGLAS CR√çTICAS:
1. Usa SOLO tablas y columnas que existen en el esquema
2. Para diagn√≥sticos m√©dicos busca en campos de texto libre (DIAG_OBSERVATION, DIAG_DESCRIPTION)
3. Para conteos usa COUNT(*) desde la tabla principal
4. Para b√∫squedas m√©dicas usa LIKE '%termino%' para b√∫squedas flexibles
5. Define TODOS los alias en el FROM/JOIN antes de usarlos
6. Usa JOINs apropiados para conectar tablas
7. Optimiza para SQLite

ESTRATEGIA M√âDICA:
- Para diabetes: Buscar en DIAG_OBSERVATION con m√∫ltiples variantes:
  LIKE '%diabetes%' OR LIKE '%diabetes mellitus%' OR LIKE '%DM2%' OR LIKE '%DM1%' 
  OR LIKE '%diabetes tipo 2%' OR LIKE '%diabetes tipo 1%' OR LIKE '%diabetes gestacional%'
- Para medicaci√≥n: Usar PATI_USUAL_MEDICATION.PAUM_OBSERVATIONS (NO MEDICATION_NAME)
- Para conteos: Usar COUNT(*) desde PATI_PATIENTS
- Para pacientes: Usar PATI_NAME, PATI_SURNAME_1
- Para diagn√≥sticos: Usar EPIS_DIAGNOSTICS con DIAG_OBSERVATION

EJEMPLOS DE CONEXI√ìN:
- PATI_PATIENTS.PATI_ID = EPIS_EPISODES.PATI_ID
- EPIS_EPISODES.EPIS_ID = EPIS_DIAGNOSTICS.EPIS_ID

RESPUESTA: SOLO el SQL v√°lido, sin explicaciones."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL din√°mico"
            )
            
            sql = self._extract_response_text(response).strip()
            sql = self._clean_llm_sql_response(sql)
            
            if sql and not sql.startswith("Error"):
                if stream_callback:
                    stream_callback("   ‚úÖ SQL din√°mico generado con LLM")
                return sql
            else:
                # Fallback b√°sico
                if stream_callback:
                    stream_callback("   ‚ö†Ô∏è Fallback a SQL b√°sico")
                return "SELECT COUNT(*) FROM PATI_PATIENTS"
                
        except Exception as e:
            logger.error(f"Error usando herramientas gen√©ricas: {e}")
            if stream_callback:
                stream_callback(f"   ‚ùå Error en herramientas gen√©ricas: {e}")
            return "SELECT COUNT(*) FROM PATI_PATIENTS"

    def _fix_typo_errors(self, sql: str) -> str:
        """
        Corrige errores tipogr√°ficos espec√≠ficos en SQL.
        
        Args:
            sql: SQL con posibles errores tipogr√°ficos
            
        Returns:
            str: SQL con errores tipogr√°ficos corregidos
        """
        if not sql:
            return sql
        
        # Correcciones espec√≠ficas para errores tipogr√°ficos comunes
        corrections = [
            # Espacios faltantes despu√©s de alias de tabla
            (r'(\w+)WHERE', r'\1 WHERE'),
            (r'(\w+)FROM', r'\1 FROM'),
            (r'(\w+)JOIN', r'\1 JOIN'),
            (r'(\w+)ON', r'\1 ON'),
            (r'(\w+)AND', r'\1 AND'),
            (r'(\w+)OR', r'\1 OR'),
            (r'(\w+)ORDER', r'\1 ORDER'),
            (r'(\w+)GROUP', r'\1 GROUP'),
            (r'(\w+)HAVING', r'\1 HAVING'),
            (r'(\w+)LIMIT', r'\1 LIMIT'),
            
            # Espacios faltantes despu√©s de columnas
            (r'(\w+\.\w+)FROM', r'\1 FROM'),
            (r'(\w+\.\w+)WHERE', r'\1 WHERE'),
            (r'(\w+\.\w+)ORDER', r'\1 ORDER'),
            (r'(\w+\.\w+)GROUP', r'\1 GROUP'),
            
            # Espacios faltantes despu√©s de asteriscos
            (r'\*FROM', r'* FROM'),
            (r'\*WHERE', r'* WHERE'),
            (r'\*ORDER', r'* ORDER'),
            
            # Espacios faltantes despu√©s de par√©ntesis
            (r'\)WHERE', r') WHERE'),
            (r'\)FROM', r') FROM'),
            (r'\)JOIN', r') JOIN'),
            (r'\)AND', r') AND'),
            (r'\)OR', r') OR'),
            
            # Espacios faltantes antes de par√©ntesis
            (r'WHERE\(', r'WHERE ('),
            (r'FROM\(', r'FROM ('),
            (r'JOIN\(', r'JOIN ('),
            
            # Correcciones espec√≠ficas para palabras pegadas
            (r'SELECT\*', r'SELECT *'),
            (r'SELECT\w+\.\*', r'SELECT *'),
            (r'FROM\w+', r'FROM '),
            (r'WHERE\w+', r'WHERE '),
            (r'JOIN\w+', r'JOIN '),
            (r'ON\w+', r'ON '),
            (r'AND\w+', r'AND '),
            (r'OR\w+', r'OR '),
            (r'ORDER\w+', r'ORDER '),
            (r'GROUP\w+', r'GROUP '),
            (r'LIMIT\w+', r'LIMIT '),
        ]
        
        corrected_sql = sql
        for pattern, replacement in corrections:
            corrected_sql = re.sub(pattern, replacement, corrected_sql, flags=re.IGNORECASE)
        
        # Normalizar espacios m√∫ltiples
        corrected_sql = re.sub(r'\s+', ' ', corrected_sql).strip()
        
        return corrected_sql

    async def _basic_sql_cleanup(self, sql: str, stream_callback=None) -> str:
        """
        Limpieza robusta de SQL usando LLM para detectar y corregir errores de forma inteligente.
        
        Args:
            sql: SQL a limpiar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL limpio y corregido
        """
        try:
            if not sql:
                return sql
            
            # Si no hay LLM, usar limpieza b√°sica
            if not self.llm:
                return self._basic_sql_cleanup_fallback(sql)
            
            if stream_callback:
                stream_callback("   - Limpieza robusta de SQL con IA...")
            
            prompt = f"""Eres un experto en SQL que detecta y corrige errores de sintaxis de forma inteligente.

SQL A LIMPIAR:
{sql}

TAREA: Analiza el SQL y corrige cualquier error de sintaxis que encuentres.

TIPOS DE ERRORES A DETECTAR:
- Palabras pegadas a keywords SQL (ej: PacientesJOIN, Diagn√≥sticosWHERE)
- Espacios faltantes entre palabras clave
- Caracteres de control o caracteres problem√°ticos
- Comentarios SQL mal formateados
- Errores de formato comunes
- Palabras clave SQL mal escritas

INSTRUCCIONES:
1. Detecta errores de forma inteligente, no uses patterns predefinidos
2. Corrige espacios faltantes entre palabras clave y tablas/columnas
3. Elimina caracteres problem√°ticos
4. Normaliza el formato del SQL
5. Mant√©n la l√≥gica original del SQL
6. Aseg√∫rate de que sea sint√°cticamente v√°lido

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones ni comentarios."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Limpieza robusta de SQL"
            )
            
            cleaned_sql = self._extract_response_text(response).strip()
            cleaned_sql = self._clean_llm_sql_response(cleaned_sql)
            
            if cleaned_sql and not cleaned_sql.startswith("Error"):
                logger.info(f"üß† LLM realiz√≥ limpieza robusta del SQL")
                if stream_callback:
                    stream_callback("   ‚úÖ Limpieza robusta completada")
                return cleaned_sql
            else:
                logger.warning(f"‚ö†Ô∏è LLM no pudo limpiar SQL, usando fallback")
                return self._basic_sql_cleanup_fallback(sql)
                
        except Exception as e:
            logger.error(f"Error en _basic_sql_cleanup: {e}")
            return self._basic_sql_cleanup_fallback(sql)

    def _basic_sql_cleanup_fallback(self, sql: str) -> str:
        """
        Fallback b√°sico para limpieza de SQL cuando no hay LLM disponible.
        
        Args:
            sql: SQL a limpiar
            
        Returns:
            str: SQL b√°sicamente limpio
        """
        try:
            if not sql:
                return sql
            
            # 1. Limpieza b√°sica
            sql = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', sql)  # Caracteres de control
            sql = re.sub(r'--.*$', '', sql, flags=re.MULTILINE)  # Comentarios SQL
            sql = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)  # Comentarios multil√≠nea
            
            # 2. Corregir errores tipogr√°ficos espec√≠ficos
            sql = self._fix_typo_errors(sql)
            
            # 3. Normalizar espacios
            sql = re.sub(r'\s+', ' ', sql).strip()
            
            # 4. Asegurar punto y coma al final
            if not sql.endswith(';'):
                sql += ';'
            
            return sql
            
        except Exception as e:
            logger.error(f"Error en _basic_sql_cleanup_fallback: {e}")
            return sql

    async def _llm_validate_and_correct_tables(self, sql: str, stream_callback=None) -> str:
        """
        Valida y corrige tablas usando LLM con acceso al esquema real.
        Le da al LLM las herramientas para verificar qu√© tablas existen realmente.
        """
        try:
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Validaci√≥n b√°sica de tablas (sin LLM)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Validando tablas con IA y esquema real...")
            
            # Usar el m√©todo correcto de SQLAgentTools
            return await self.schema_tools.llm_validate_and_correct_tables(sql, stream_callback)
            
        except Exception as e:
            logger.error(f"Error en _llm_validate_and_correct_tables: {e}")
            return sql

    async def _llm_validate_and_correct_columns(self, sql: str, stream_callback=None) -> str:
        """
        Valida y corrige columnas usando LLM con acceso al esquema real.
        Le da al LLM las herramientas para verificar qu√© columnas existen realmente.
        """
        try:
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Validaci√≥n b√°sica de columnas (sin LLM)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Validando columnas con IA y esquema real...")
            
            # Extraer tabla del SQL
            table_match = re.search(r'INSERT INTO (\w+)', sql, re.IGNORECASE)
            if not table_match:
                return sql
            
            table_name = table_match.group(1)
            
            # Obtener esquema espec√≠fico de la tabla
            table_schema = self._get_table_schema_info(table_name)
            
            prompt = f"""Eres un experto en validaci√≥n de columnas SQL en bases de datos m√©dicas.

SQL A VALIDAR:
{sql}

ESQUEMA REAL DE LA TABLA {table_name}:
{table_schema}

TAREA ADAPTATIVA: Valida y corrige las columnas del SQL.

INSTRUCCIONES:
1. Analiza el SQL INSERT
2. Identifica las columnas que se est√°n insertando
3. Verifica que TODAS las columnas existan en el esquema real
4. Si alguna columna NO existe, elim√≠nala del INSERT
5. Mant√©n solo las columnas que S√ç existen en la tabla
6. Adapta el SQL seg√∫n las columnas disponibles

REGLAS DE VALIDACI√ìN:
- SOLO usa columnas que existan en el esquema real
- Si una columna no existe, elim√≠nala completamente
- Mant√©n la estructura del INSERT v√°lida
- No agregues columnas que no est√©n en el esquema
- Adapta el mapeo seg√∫n las columnas disponibles

VALIDACI√ìN ADAPTATIVA:
- Analiza el esquema de {table_name}
- Identifica las columnas disponibles
- Corrige el SQL seg√∫n las columnas reales
- Mant√©n solo columnas que existan

RESPUESTA JSON:
{{
    "sql_corrected": "SQL corregido",
    "columns_validated": ["columna1", "columna2"],
    "corrections_applied": ["correcci√≥n1", "correcci√≥n2"],
    "table_used": "{table_name}",
    "validation_confidence": 0.95
}}

IMPORTANTE: Solo responde con el JSON."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Validando columnas con IA"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('sql_corrected'):
                corrections = result.get('corrections_applied', [])
                if stream_callback and corrections:
                    stream_callback(f"   ‚úÖ Columnas validadas")
                    for correction in corrections:
                        stream_callback(f"      - {correction}")
                return result['sql_corrected']
            else:
                return sql
            
        except Exception as e:
            logger.error(f"Error en _llm_validate_and_correct_columns: {e}")
            return sql

    def _normalize_accents_python(self, text: str) -> str:
        """
        Normaliza vocales acentuadas en Python (m√°s eficiente que en SQL).
        Versi√≥n ROBUSTA que maneja todos los casos edge.
        
        Args:
            text: Texto a normalizar
            
        Returns:
            str: Texto con vocales acentuadas normalizadas
        """
        if not text:
            return ""
        
        # Reemplazos completos de acentos y caracteres especiales
        replacements = {
            # Vocales acentuadas may√∫sculas
            '√Å': 'A', '√â': 'E', '√ç': 'I', '√ì': 'O', '√ö': 'U', '√ú': 'U',
            # Vocales acentuadas min√∫sculas
            '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u', '√º': 'u',
            # √ë
            '√ë': 'N', '√±': 'n',
            # Caracteres especiales que pueden aparecer en nombres
            '√Ä': 'A', '√à': 'E', '√å': 'I', '√í': 'O', '√ô': 'U',
            '√†': 'a', '√®': 'e', '√¨': 'i', '√≤': 'o', '√π': 'u',
            '√Ç': 'A', '√ä': 'E', '√é': 'I', '√î': 'O', '√õ': 'U',
            '√¢': 'a', '√™': 'e', '√Æ': 'i', '√¥': 'o', '√ª': 'u',
            '√É': 'A', '√ï': 'O',
            '√£': 'a', '√µ': 'o',
            # Eliminar caracteres problem√°ticos
            '\t': ' ', '\n': ' ', '\r': ' ',
        }
        
        normalized = text
        for accented, normal in replacements.items():
            normalized = normalized.replace(accented, normal)
        
        # Normalizar espacios m√∫ltiples
        normalized = ' '.join(normalized.split())
        
        # Convertir a may√∫sculas para consistencia
        return normalized.upper()

    async def _fix_sql_compatibility(self, sql: str, stream_callback=None) -> str:
        """
        Corrige problemas de compatibilidad del SQL para SQLite usando LLM.
        SIN PATRONES HARDCODEADOS - todo via LLM.
        """
        try:
            if not sql:
                return sql
                
            # Si no hay LLM, usar fallback b√°sico
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Ajustando compatibilidad SQL con m√©todo b√°sico...")
                return sql
                
            if stream_callback:
                stream_callback("   - Optimizando SQL para compatibilidad con SQLite...")
            
            # Usar LLM para correcci√≥n inteligente de compatibilidad
            compatibility_prompt = f"""Eres un experto en bases de datos que convierte SQL de MySQL/PostgreSQL a SQLite.

TAREA: Convierte este SQL para que sea 100% compatible con SQLite, manteniendo la l√≥gica original.

SQL A CONVERTIR:
{sql}

REGLAS DE CONVERSI√ìN PARA SQLITE:

1. **FECHAS Y TIEMPO:**
   - DATE_SUB(CURDATE(), INTERVAL n YEAR) ‚Üí date('now', '-n years')
   - DATE_SUB(CURDATE(), INTERVAL n MONTH) ‚Üí date('now', '-n months')
   - DATE_SUB(CURDATE(), INTERVAL n DAY) ‚Üí date('now', '-n days')
   - CURDATE() ‚Üí date('now')
   - NOW() ‚Üí datetime('now')
   - GETDATE() ‚Üí datetime('now')
   - YEAR(column) ‚Üí strftime('%Y', column)
   - MONTH(column) ‚Üí strftime('%m', column)
   - DAY(column) ‚Üí strftime('%d', column)
   - DATEDIFF(date1, date2) ‚Üí julianday(date1) - julianday(date2)

2. **L√çMITES:**
   - SELECT TOP n ‚Üí SELECT ... LIMIT n
   - LIMIT n OFFSET m ‚Üí LIMIT n OFFSET m (ya compatible)

3. **FUNCIONES DE CADENA:**
   - CONCAT(a, b) ‚Üí (a || b)
   - LENGTH() ‚Üí length() (ya compatible)
   - SUBSTRING() ‚Üí substr()

4. **FUNCIONES MATEM√ÅTICAS:**
   - POW(a, b) ‚Üí POWER(a, b)
   - RAND() ‚Üí RANDOM()

5. **TIPOS DE DATOS:**
   - AUTO_INCREMENT ‚Üí AUTOINCREMENT
   - TINYINT, SMALLINT, MEDIUMINT, BIGINT ‚Üí INTEGER
   - TEXT, LONGTEXT ‚Üí TEXT
   - DECIMAL(n,m) ‚Üí REAL o NUMERIC

6. **OTRAS FUNCIONES:**
   - IFNULL(a, b) ‚Üí COALESCE(a, b)
   - IF(condition, true_val, false_val) ‚Üí CASE WHEN condition THEN true_val ELSE false_val END

IMPORTANTE:
- Mant√©n la l√≥gica exacta del SQL original
- Aseg√∫rate de que la sintaxis sea v√°lida para SQLite
- No cambies nombres de tablas o columnas
- Preserva todos los WHERE, JOIN, GROUP BY, ORDER BY, etc.
- Si el SQL ya es compatible, devu√©lvelo sin cambios

RESPUESTA:
Devuelve SOLO el SQL corregido, sin explicaciones adicionales."""

            try:
                if stream_callback:
                    stream_callback("   - Analizando SQL para compatibilidad con SQLite...")
                    
                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": compatibility_prompt}]
                )
                
                corrected_sql = self._extract_response_text(response).strip()
                corrected_sql = self._clean_llm_sql_response(corrected_sql)
                
                # Validar que el LLM devolvi√≥ SQL v√°lido
                if corrected_sql and not corrected_sql.startswith("Error") and len(corrected_sql) > 10:
                    # Log de cambios si fueron significativos
                    if corrected_sql != sql:
                        logger.info(f"üß† LLM corrigi√≥ compatibilidad SQL para SQLite")
                        logger.info(f"   Original: {sql[:100]}...")
                        logger.info(f"   Corregido: {corrected_sql[:100]}...")
                        
                        if stream_callback:
                            stream_callback("   - Optimizadas funciones para compatibilidad con SQLite")
                    else:
                        if stream_callback:
                            stream_callback("   - SQL ya compatible con SQLite, sin cambios necesarios")
                    
                    return corrected_sql
                else:
                    logger.warning(f"‚ö†Ô∏è LLM devolvi√≥ respuesta inv√°lida, usando original")
                    if stream_callback:
                        stream_callback("   - Usando SQL original")
                    return sql
                    
            except Exception as e:
                logger.error(f"Error usando LLM para compatibilidad: {e}")
                if stream_callback:
                    stream_callback(f"   - Error optimizando SQL: {str(e)[:50]}... Usando original")
                return sql
                
        except Exception as e:
            logger.error(f"Error en _fix_sql_compatibility: {e}")
            if stream_callback:
                stream_callback("   - Error en correcci√≥n de compatibilidad")
            return sql  # Devolver original si falla completamente

    async def _validate_schema_with_robust_tools(self, sql: str, stream_callback=None) -> str:
        """
        Valida el esquema usando herramientas robustas para verificar columnas y tablas reales.
        GARANTIZA que el LLM devuelva SOLO SQL sin explicaciones.
        """
        try:
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Validaci√≥n b√°sica (sin LLM)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Validando esquema con herramientas robustas...")
            
            # Obtener esquema real de la base de datos
            schema_info = self._get_real_schema_info()
            
            # PROMPT ESTRICTO que garantiza solo SQL
            validation_prompt = f"""Eres un experto en SQL que corrige consultas contra esquemas reales.

SQL A VALIDAR:
{sql}

ESQUEMA REAL DE LA BASE DE DATOS:
{schema_info}

TAREA CR√çTICA:
1. Verifica que TODAS las tablas mencionadas en el SQL existan en el esquema real
2. Verifica que TODAS las columnas mencionadas existan en sus respectivas tablas
3. Si encuentras tablas o columnas que NO existen, corr√≠gelas usando las alternativas reales
4. Mant√©n la l√≥gica original del SQL
5. NO inventes columnas que no existen

REGLAS IMPORTANTES:
- Si una tabla no existe, busca una tabla similar en el esquema
- Si una columna no existe, busca una columna similar en la misma tabla
- Para pacientes, usa PATI_PATIENTS con columnas como PATI_ID, PATI_FULL_NAME
- Para diagn√≥sticos, usa EPIS_DIAGNOSTICS con columnas como DIAG_ID, CDTE_ID
- Para observaciones, usa OBSE_OBSERVATIONS con columnas como OBSE_ID, OBSE_VALUE

IMPORTANTE: Devuelve √öNICAMENTE el SQL corregido, SIN explicaciones, SIN comentarios, SIN texto adicional.
Si el SQL est√° correcto, devuelve el SQL original sin cambios.

EJEMPLO DE RESPUESTA CORRECTA:
SELECT p.PATI_ID, p.PATI_FULL_NAME FROM PATI_PATIENTS p WHERE p.PATI_ACTIVE = 1;

RESPUESTA (SOLO SQL):"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                task_description="Validando esquema con herramientas robustas"
            )
            
            validated_sql = self._extract_response_text(response).strip()
            
            # LIMPIEZA AGRESIVA para eliminar cualquier texto que no sea SQL
            validated_sql = self._clean_sql_response_aggressive(validated_sql)
            
            if validated_sql and not validated_sql.startswith("Error"):
                # Verificar que realmente es SQL v√°lido
                if self._is_valid_sql_response(validated_sql):
                    logger.info(f"üß† SQL validado con esquema real")
                    if stream_callback:
                        stream_callback("   ‚úÖ Esquema validado con herramientas robustas")
                    return validated_sql
                else:
                    logger.warning(f"‚ö†Ô∏è LLM devolvi√≥ texto que no es SQL v√°lido")
                    return sql
            else:
                logger.warning(f"‚ö†Ô∏è No se pudo validar con herramientas, usando original")
                return sql
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n con herramientas: {e}")
            return sql

    def _clean_sql_response_aggressive(self, response: str) -> str:
        """
        Limpieza agresiva para eliminar cualquier texto que no sea SQL puro.
        """
        if not response:
            return response
        
        # Eliminar bloques de c√≥digo markdown
        response = re.sub(r'^```[a-zA-Z]*\n', '', response)
        response = re.sub(r'\n```$', '', response)
        response = re.sub(r'^```', '', response)
        response = re.sub(r'```$', '', response)
        
        # Eliminar comentarios SQL
        response = re.sub(r'--.*$', '', response, flags=re.MULTILINE)
        response = re.sub(r'/\*.*?\*/', '', response, flags=re.DOTALL)
        
        # Eliminar explicaciones comunes del LLM
        explanations = [
            "Aqu√≠ est√° el SQL corregido:",
            "El SQL corregido es:",
            "SQL v√°lido:",
            "Consulta corregida:",
            "Aqu√≠ tienes el SQL:",
            "El SQL ser√≠a:",
            "SQL resultante:",
            "Consulta SQL:",
            "SQL optimizado:",
            "SQL final:"
        ]
        
        for explanation in explanations:
            response = response.replace(explanation, "")
        
        # Buscar el primer SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, ALTER
        sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER', 'WITH']
        for keyword in sql_keywords:
            pos = response.upper().find(keyword)
            if pos != -1:
                response = response[pos:]
                break
        
        # Buscar el √∫ltimo punto y coma
        last_semicolon = response.rfind(';')
        if last_semicolon != -1:
            response = response[:last_semicolon + 1]
        
        # Limpiar espacios extra
        response = re.sub(r'\s+', ' ', response).strip()
        
        return response

    def _is_valid_sql_response(self, sql: str) -> bool:
        """
        Verifica si la respuesta es SQL v√°lido.
        """
        if not sql:
            return False
        
        # Verificar que contenga palabras clave SQL
        sql_keywords = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'DROP', 'ALTER', 'WITH']
        has_sql_keyword = any(keyword in sql.upper() for keyword in sql_keywords)
        
        # Verificar que no contenga texto explicativo
        explanatory_words = ['explicaci√≥n', 'explicaci√≥n', 'aqu√≠', 'corregido', 'v√°lido', 'resultado', 'final']
        has_explanation = any(word in sql.lower() for word in explanatory_words)
        
        # Verificar que no sea solo texto sin SQL
        if len(sql) < 10:
            return False
        
        return has_sql_keyword and not has_explanation

    def _get_real_schema_info(self) -> str:
        """
        Obtiene informaci√≥n real del esquema de la base de datos usando LLM para categorizaci√≥n.
        SIN HARDCODEO - todo via LLM.
        """
        try:
            # Conectar a la base de datos y obtener esquema real
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Obtener todas las tablas
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]
            
            # Obtener informaci√≥n detallada de columnas para cada tabla
            schema_info = []
            for table in tables:
                if table.startswith('sqlite_') or table.startswith('_'):
                    continue
                    
                # Obtener columnas detalladas de cada tabla
                cursor.execute(f"PRAGMA table_info('{table}');")
                columns_info = cursor.fetchall()
                
                schema_info.append(f"üìã TABLA: {table}")
                schema_info.append("   COLUMNAS:")
                
                for col_info in columns_info:
                    col_name = col_info[1]
                    col_type = col_info[2]
                    not_null = "NOT NULL" if col_info[3] else ""
                    pk = "PRIMARY KEY" if col_info[5] else ""
                    default = f"DEFAULT {col_info[4]}" if col_info[4] else ""
                    
                    constraints = " ".join(filter(None, [not_null, pk, default])).strip()
                    if constraints:
                        schema_info.append(f"     - {col_name} ({col_type}) {constraints}")
                    else:
                        schema_info.append(f"     - {col_name} ({col_type})")
                
                schema_info.append("")
            
            conn.close()
            return "\n".join(schema_info)
            
        except Exception as e:
            logger.error(f"Error obteniendo esquema real: {e}")
            return "Error obteniendo esquema"

    async def _llm_categorize_tables_intelligent(self, tables: List[str], stream_callback=None) -> Dict[str, List[str]]:
        """
        Categoriza tablas usando LLM de forma inteligente - SIN HARDCODEO.
        
        Args:
            tables: Lista de nombres de tablas
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Dict[str, List[str]]: Categor√≠as y tablas correspondientes
        """
        try:
            if not self.llm:
                # Fallback b√°sico sin LLM
                return {'TABLAS': tables}
            
            if stream_callback:
                stream_callback("   - Categorizando tablas con IA inteligente...")
            
            # Obtener informaci√≥n de columnas para contexto
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            table_info = {}
            for table in tables:
                if table.startswith('sqlite_') or table.startswith('_'):
                    continue
                try:
                    cursor.execute(f"PRAGMA table_info('{table}');")
                    columns = [row[1] for row in cursor.fetchall()]
                    table_info[table] = columns
                except Exception as e:
                    logger.warning(f"No se pudo obtener informaci√≥n de tabla {table}: {e}")
            
            conn.close()
            
            # PROMPT ESPEC√çFICO PARA CATEGORIZACI√ìN INTELIGENTE - SIN HARDCODEO
            categorization_prompt = f"""Eres un experto en an√°lisis de esquemas de bases de datos m√©dicas.

TABLAS DISPONIBLES:
{json.dumps(table_info, indent=2, ensure_ascii=False)}

TAREA ESPEC√çFICA: Analiza cada tabla y categor√≠zala seg√∫n su funci√≥n en un sistema m√©dico.

INSTRUCCIONES DE CATEGORIZACI√ìN:
1. Analiza los nombres de las tablas y sus columnas
2. Identifica patrones en los nombres y estructura
3. Determina la funci√≥n principal de cada tabla
4. Categoriza bas√°ndote en el contenido sem√°ntico, NO en patrones de nombres
5. Considera m√∫ltiples categor√≠as si una tabla puede servir para varios prop√≥sitos

CRITERIOS DE AN√ÅLISIS:
- Tablas con informaci√≥n de pacientes (datos personales, demogr√°ficos)
- Tablas con episodios m√©dicos (visitas, hospitalizaciones)
- Tablas con diagn√≥sticos y condiciones m√©dicas
- Tablas con medicamentos y tratamientos
- Tablas con procedimientos m√©dicos
- Tablas con citas y programaci√≥n
- Tablas con observaciones y resultados de laboratorio
- Tablas con c√≥digos y par√°metros del sistema
- Tablas con informaci√≥n administrativa
- Tablas con datos de especialidades espec√≠ficas (oncolog√≠a, cardiolog√≠a, etc.)

RESPUESTA JSON:
{{
    "categorias": {{
        "PACIENTES": ["tabla1", "tabla2"],
        "EPISODIOS": ["tabla3", "tabla4"],
        "DIAGN√ìSTICOS": ["tabla5", "tabla6"],
        "MEDICAMENTOS": ["tabla7", "tabla8"],
        "PROCEDIMIENTOS": ["tabla9", "tabla10"],
        "OBSERVACIONES": ["tabla11", "tabla12"],
        "CITAS": ["tabla13", "tabla14"],
        "C√ìDIGOS": ["tabla15", "tabla16"],
        "ADMINISTRATIVO": ["tabla17", "tabla18"],
        "ESPECIALIDADES": ["tabla19", "tabla20"],
        "OTROS": ["tabla21", "tabla22"]
    }},
    "razonamiento": "explicaci√≥n de la categorizaci√≥n",
    "total_tablas": {len(tables)}
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": categorization_prompt}],
                task_description="Categorizando tablas con IA inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and 'categorias' in result:
                categorias = result['categorias']
                razonamiento = result.get('razonamiento', 'Sin explicaci√≥n')
                
                if stream_callback:
                    stream_callback(f"   - Categorizaci√≥n completada: {len(categorias)} categor√≠as")
                    stream_callback(f"   - Razonamiento: {razonamiento[:50]}...")
                
                return categorias
            else:
                logger.warning("‚ö†Ô∏è LLM no pudo categorizar tablas, usando categor√≠a √∫nica")
                return {'TABLAS': tables}
                
        except Exception as e:
            logger.error(f"Error categorizando tablas: {e}")
            return {'TABLAS': tables}

    async def _llm_select_relevant_tables_intelligent(self, query: str, medical_concepts: List[str], stream_callback=None) -> List[str]:
        """
        Selecciona tablas relevantes usando LLM de forma inteligente - SIN HARDCODEO.
        
        Args:
            query: Consulta original del usuario
            medical_concepts: Conceptos m√©dicos detectados
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            List[str]: Tablas relevantes seleccionadas
        """
        try:
            if not self.llm:
                # Fallback b√°sico sin LLM
                schema = self.schema_tools.get_schema()
                return list(schema.keys())[:3]
            
            if stream_callback:
                stream_callback("   - Seleccionando tablas relevantes con IA inteligente...")
            
            # Obtener esquema completo
            schema = self.schema_tools.get_schema()
            schema_summary = self._get_schema_summary_for_llm(schema)
            
            # Categorizar tablas primero
            tables = list(schema.keys())
            categorias = await self._llm_categorize_tables_intelligent(tables, stream_callback)
            
            # PROMPT ESPEC√çFICO PARA SELECCI√ìN INTELIGENTE - SIN HARDCODEO
            selection_prompt = f"""Eres un experto en bases de datos m√©dicas que selecciona las tablas m√°s relevantes.

CONSULTA DEL USUARIO: "{query}"

CONCEPTOS M√âDICOS DETECTADOS: {medical_concepts}

CATEGOR√çAS DE TABLAS DISPONIBLES:
{json.dumps(categorias, indent=2, ensure_ascii=False)}

ESQUEMA COMPLETO:
{schema_summary}

TAREA ESPEC√çFICA: Selecciona las tablas m√°s relevantes para responder a esta consulta.

ESTRATEGIA DE SELECCI√ìN:
1. Analiza la consulta para entender qu√© informaci√≥n se necesita
2. Identifica qu√© categor√≠as de tablas son relevantes
3. Selecciona tablas espec√≠ficas dentro de esas categor√≠as
4. Considera relaciones entre tablas
5. Prioriza tablas que contengan la informaci√≥n m√°s espec√≠fica
6. Incluye tablas de soporte si son necesarias para JOINs

CRITERIOS DE SELECCI√ìN:
- Relevancia directa con la consulta
- Capacidad de proporcionar la informaci√≥n solicitada
- Posibilidad de JOINs efectivos
- Complejidad vs. simplicidad
- Rendimiento esperado

INSTRUCCIONES:
- Selecciona m√°ximo 5 tablas para evitar consultas muy complejas
- Prioriza tablas que contengan la informaci√≥n principal
- Incluye tablas de soporte solo si son necesarias
- Considera el rendimiento de la consulta

RESPUESTA JSON:
{{
    "tablas_seleccionadas": ["tabla1", "tabla2", "tabla3"],
    "categorias_relevantes": ["categoria1", "categoria2"],
    "razonamiento": "explicaci√≥n de la selecci√≥n",
    "estrategia_joins": "descripci√≥n de c√≥mo conectar las tablas"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": selection_prompt}],
                task_description="Seleccionando tablas relevantes con IA inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and 'tablas_seleccionadas' in result:
                tablas_seleccionadas = result['tablas_seleccionadas']
                categorias_relevantes = result.get('categorias_relevantes', [])
                razonamiento = result.get('razonamiento', 'Sin explicaci√≥n')
                
                # Validar que las tablas existan
                valid_tables = [t for t in tablas_seleccionadas if t in schema]
                
                if stream_callback:
                    stream_callback(f"   - Tablas seleccionadas: {', '.join(valid_tables[:3])}...")
                    stream_callback(f"   - Categor√≠as relevantes: {', '.join(categorias_relevantes)}")
                
                return valid_tables[:5]  # M√°ximo 5 tablas
            else:
                logger.warning("‚ö†Ô∏è LLM no pudo seleccionar tablas, usando fallback")
                return list(schema.keys())[:3]
                
        except Exception as e:
            logger.error(f"Error seleccionando tablas: {e}")
            schema = self.schema_tools.get_schema()
            return list(schema.keys())[:3]

    # M√©todo de compatibilidad para mantener funcionalidad existente
    async def _llm_map_fhir_to_sql_intelligent(self, fhir_data: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        M√©todo de compatibilidad que redirige al nuevo sistema adaptativo.
        Mantiene compatibilidad hacia atr√°s mientras se migra completamente.
        """
        return await self._llm_map_fhir_to_sql_adaptive(fhir_data, stream_callback, None)

    async def _llm_map_fhir_to_sql_adaptive(self, fhir_data: Dict[str, Any], stream_callback=None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        üß† ARQUITECTURA ADAPTATIVA: Mapeo din√°mico que aprende y se adapta autom√°ticamente.
        El LLM descubre el esquema, aprende de cada operaci√≥n y valida contextualmente.
        
        Args:
            fhir_data: Datos FHIR a mapear
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Dict[str, Any]: Informaci√≥n de mapeo adaptativo
        """
        try:
            if not self.llm:
                # Fallback b√°sico sin LLM
                return {
                    'table': 'PATI_PATIENTS',
                    'columns': ['PATI_NAME', 'PATI_SURNAME_1'],
                    'values': [fhir_data.get('name', ''), fhir_data.get('surname', '')]
                }
            
            if stream_callback:
                stream_callback("üß† ARQUITECTURA ADAPTATIVA OPTIMIZADA: Consolidaci√≥n + Cach√©...")
            
            # PASO 1: Mapeo din√°mico usando LLM consolidado
            mapping_result = await self._llm_consolidated_discovery_and_mapping(fhir_data, stream_callback, context)
            
            # PASO 2: Validaci√≥n din√°mica
            final_result = await self._llm_adaptive_cleanup(mapping_result, stream_callback)
            
            # PASO 3: FORZAR VALIDACI√ìN DE IDs (CR√çTICO)
            if final_result and final_result.get('values') and final_result.get('columns'):
                corrected_values = await self._llm_validate_and_correct_fictitious_ids_adaptive(
                    final_result['values'], 
                    final_result['columns'], 
                    stream_callback
                )
                if corrected_values:
                    final_result['values'] = corrected_values
                    if stream_callback:
                        stream_callback("   ‚úÖ Validaci√≥n de IDs forzada completada")
            
            if stream_callback:
                stream_callback(f"üß† Mapeo adaptativo completado: {final_result.get('resource_type', 'Unknown')} ‚Üí {final_result.get('table', 'Unknown')}")
                stream_callback(f"   - Campos adaptados: {len(final_result.get('columns', []))}")
            
            return final_result
                
        except Exception as e:
            logger.error(f"Error en mapeo adaptativo: {e}")
            
            # FALLBACK INTELIGENTE CON LLM: Usar LLM para seleccionar tabla correcta
            if stream_callback:
                stream_callback(f"   üîß Aplicando fallback inteligente con LLM...")
            
            return await self._llm_intelligent_fallback_mapping(fhir_data, stream_callback)

    async def _llm_intelligent_fallback_mapping(self, fhir_data: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        FALLBACK INTELIGENTE CON LLM: Usa LLM para seleccionar tabla y mapear campos cuando el m√©todo principal falla.
        """
        try:
            if not self.llm:
                # Fallback b√°sico sin LLM
                return {
                    'table': 'PATI_PATIENTS',
                    'columns': ['PATI_NAME', 'PATI_SURNAME_1'],
                    'values': [fhir_data.get('name', ''), fhir_data.get('surname', '')]
                    }
            
            if stream_callback:
                stream_callback("   üß† Fallback inteligente: Analizando con LLM...")
            
            # PROMPT INTELIGENTE PARA DESCUBRIMIENTO DIN√ÅMICO
            fallback_prompt = f"""Eres un experto en an√°lisis din√°mico de esquemas de bases de datos m√©dicas. Analiza el esquema disponible y descubre autom√°ticamente la tabla m√°s apropiada.

DATOS FHIR A MAPEAR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA COMPLETO DE LA BASE DE DATOS:
{self._get_real_schema_info()}

TAREA INTELIGENTE: Analiza el esquema din√°micamente y descubre la tabla m√°s apropiada.

ESTRATEGIA DE DESCUBRIMIENTO DIN√ÅMICO:
1. Analiza el tipo de recurso FHIR (Patient, Condition, Observation, etc.)
2. Examina todas las tablas disponibles en el esquema
3. Identifica patrones en los nombres de las tablas (PATI_*, EPIS_*, OBSE_*, MEDI_*, etc.)
4. Analiza las columnas de cada tabla para entender su prop√≥sito
5. Busca tablas que contengan campos relevantes para el tipo de recurso
6. Considera el contexto m√©dico y sem√°ntico
7. Selecciona la tabla m√°s apropiada bas√°ndose en el an√°lisis din√°mico

AN√ÅLISIS DIN√ÅMICO REQUERIDO:
- Examina los prefijos de las tablas (PATI, EPIS, OBSE, MEDI, etc.)
- Analiza las columnas de cada tabla para entender su funci√≥n
- Busca patrones sem√°nticos (patient, diagnosis, observation, medication, etc.)
- Considera las relaciones impl√≠citas entre tablas
- Identifica la tabla que mejor se adapta al tipo de recurso FHIR

INSTRUCCIONES CR√çTICAS:
- NO uses mapeos hardcodeados, analiza din√°micamente
- Examina el esquema completo para encontrar la tabla correcta
- Considera el contexto m√©dico y sem√°ntico
- SOLO usa columnas que existan en la tabla seleccionada
- NO uses IDs ficticios, deja que se autoincrementen
- Para valores nulos, usa null (no "NULL" como string)
- Extrae valores espec√≠ficos del FHIR, NO objetos completos

RESPUESTA JSON:
{{
    "resource_type": "tipo_de_recurso_detectado",
    "target_table": "tabla_descubierta_din√°micamente",
    "columns": ["columna1", "columna2"],
    "values": ["valor1", null],
    "mapping_strategy": "discovery_dynamic",
    "confidence": 0.9,
    "discovery_analysis": "an√°lisis_del_descubrimiento",
    "table_selection_reasoning": "razonamiento_para_selecci√≥n_de_tabla"
}}

IMPORTANTE: 
- Analiza DIN√ÅMICAMENTE el esquema, NO uses mapeos hardcodeados
- Descubre la tabla bas√°ndote en el an√°lisis del esquema
- Considera el contexto m√©dico y sem√°ntico
- SOLO usa columnas que existan realmente en la tabla seleccionada

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": fallback_prompt}],
                task_description="Fallback inteligente con LLM"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   ‚úÖ Fallback inteligente: {result.get('resource_type', 'Unknown')} ‚Üí {result.get('target_table', 'Unknown')}")
                    stream_callback(f"   üìä Columnas: {len(result.get('columns', []))}")
                
                return result
            else:
                # Si el LLM falla, intentar con un prompt m√°s simple pero a√∫n din√°mico
                if stream_callback:
                    stream_callback(f"   ‚ö†Ô∏è LLM fall√≥, intentando an√°lisis simplificado...")
                
                # PROMPT SIMPLIFICADO PERO DIN√ÅMICO
                simple_prompt = f"""Analiza este recurso FHIR y encuentra la tabla m√°s apropiada en el esquema.

RECURSO FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA:
{self._get_real_schema_info()}

TAREA: Encuentra la tabla m√°s apropiada analizando el esquema din√°micamente.

RESPUESTA JSON:
{{
    "resource_type": "tipo_detectado",
    "target_table": "tabla_encontrada",
    "columns": ["columna1"],
    "values": ["valor1"],
    "mapping_strategy": "simple_dynamic",
    "confidence": 0.6
}}

Responde SOLO con el JSON:"""

                response = await asyncio.to_thread(
                    _call_openai_native, self.llm, [{"role": "user", "content": simple_prompt}],
                    task_description="An√°lisis simplificado"
                )
                
                content = self._extract_response_text(response)
                result = self._try_parse_llm_json(content)
                
                if result:
                    if stream_callback:
                        stream_callback(f"   ‚úÖ An√°lisis simplificado: {result.get('resource_type', 'Unknown')} ‚Üí {result.get('target_table', 'Unknown')}")
                    return result
                else:
                    # √öltimo recurso: an√°lisis b√°sico sin LLM
                    if stream_callback:
                        stream_callback(f"   ‚ö†Ô∏è Usando an√°lisis b√°sico sin LLM...")
                    
                    # An√°lisis b√°sico basado en el tipo de recurso
                    resource_type = fhir_data.get('resourceType', '')
                    
                    # Buscar tabla por patrones en el esquema
                    schema_info = self._get_real_schema_info()
                    if 'PATI_PATIENTS' in schema_info and resource_type == 'Patient':
                        selected_table = 'PATI_PATIENTS'
                    elif 'EPIS_DIAGNOSTICS' in schema_info and resource_type == 'Condition':
                        selected_table = 'EPIS_DIAGNOSTICS'
                    elif 'MEDI_MEDICATIONS' in schema_info and resource_type == 'MedicationRequest':
                        selected_table = 'MEDI_MEDICATIONS'
                    elif 'OBSE_OBSERVATIONS' in schema_info and resource_type == 'Observation':
                        selected_table = 'OBSE_OBSERVATIONS'
                    elif 'EPIS_EPISODES' in schema_info and resource_type == 'Encounter':
                        selected_table = 'EPIS_EPISODES'
                    else:
                        selected_table = 'PATI_PATIENTS'  # Fallback gen√©rico
                    
                    return {
                        'table': selected_table,
                        'resource_type': resource_type,
                        'columns': ['PATI_NAME', 'PATI_SURNAME_1'],
                        'values': [fhir_data.get('name', ''), fhir_data.get('surname', '')],
                        'mapping_strategy': 'basic_analysis',
                        'confidence': 0.3
                    }
                
        except Exception as e:
            logger.error(f"Error en fallback inteligente: {e}")
            return {
                'table': 'PATI_PATIENTS',
                'columns': ['PATI_NAME', 'PATI_SURNAME_1'],
                'values': [fhir_data.get('name', ''), fhir_data.get('surname', '')],
                'mapping_strategy': 'fallback_error',
                'confidence': 0.3
            }

    async def _llm_discover_schema_adaptive(self, fhir_data: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 1: Descubrimiento din√°mico del esquema usando LLM.
        El LLM explora la base de datos y descubre patrones autom√°ticamente.
        """
        try:
            if not self.llm:
                return {'tables': [], 'patterns': []}
            
            if stream_callback:
                stream_callback("   - Descubriendo esquema din√°micamente...")
            
            # Obtener informaci√≥n real de la base de datos
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Explorar todas las tablas din√°micamente
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            all_tables = [row[0] for row in cursor.fetchall()]
            
            # Analizar estructura de cada tabla
            table_analysis = {}
            for table in all_tables:
                if table.startswith('sqlite_') or table.startswith('_'):
                    continue
                
                cursor.execute(f"PRAGMA table_info('{table}');")
                columns = cursor.fetchall()
                
                # Analizar patrones en columnas
                column_patterns = []
                for col in columns:
                    col_name = col[1]
                    col_type = col[2]
                    is_pk = col[5]
                    
                    # Detectar patrones autom√°ticamente
                    if 'ID' in col_name.upper():
                        column_patterns.append('identifier')
                    elif 'NAME' in col_name.upper() or 'FULL' in col_name.upper():
                        column_patterns.append('name')
                    elif 'DATE' in col_name.upper():
                        column_patterns.append('date')
                    elif 'OBSERVATION' in col_name.upper():
                        column_patterns.append('observation')
                    elif 'DIAG' in col_name.upper():
                        column_patterns.append('diagnosis')
                
                table_analysis[table] = {
                    'columns': [col[1] for col in columns],
                    'patterns': column_patterns,
                    'primary_key': next((col[1] for col in columns if col[5]), None)
                }
            
            conn.close()
            
            # PROMPT ADAPTATIVO: Descubrimiento din√°mico
            discovery_prompt = f"""Eres un experto en descubrimiento din√°mico de esquemas de bases de datos m√©dicas.

DATOS FHIR A ANALIZAR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA DESCUBIERTO DIN√ÅMICAMENTE:
{json.dumps(table_analysis, indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Analiza el esquema descubierto y identifica patrones autom√°ticamente.

ESTRATEGIA DE DESCUBRIMIENTO:
1. Analiza los nombres de las tablas para identificar su funci√≥n
2. Examina los patrones de columnas para entender la estructura
3. Identifica relaciones impl√≠citas entre tablas
4. Detecta campos de identificaci√≥n, fechas, observaciones
5. Mapea conceptos m√©dicos a estructuras de datos

MAPEO ESPEC√çFICO DE TABLAS:
- PATI_PATIENTS ‚Üí Datos de pacientes
- EPIS_EPISODES ‚Üí Episodios m√©dicos
- EPIS_DIAGNOSTICS ‚Üí Diagn√≥sticos y condiciones
- OBSE_OBSERVATIONS ‚Üí Observaciones m√©dicas
- MEDI_MEDICATIONS ‚Üí Medicamentos
- CODR_TABULAR_DIAGNOSTICS ‚Üí C√≥digos de diagn√≥stico

INSTRUCCIONES:
- Identifica las tablas disponibles en el esquema
- Mapea cada tipo de recurso FHIR a la tabla correspondiente
- Considera el contexto m√©dico espec√≠fico
- Sugiere mapeos basados en el contenido sem√°ntico

RESPUESTA JSON:
{{
    "discovered_tables": {{
        "patient_tables": ["PATI_PATIENTS"],
        "diagnosis_tables": ["EPIS_DIAGNOSTICS"],
        "observation_tables": ["OBSE_OBSERVATIONS"],
        "medication_tables": ["MEDI_MEDICATIONS"],
        "episode_tables": ["EPIS_EPISODES"]
    }},
    "patterns_identified": ["patr√≥n1", "patr√≥n2"],
    "suggested_mappings": {{
        "Patient": "PATI_PATIENTS",
        "Observation": "OBSE_OBSERVATIONS",
        "Condition": "EPIS_DIAGNOSTICS",
        "Encounter": "EPIS_EPISODES",
        "Medication": "MEDI_MEDICATIONS"
    }},
    "confidence_level": "high|medium|low"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": discovery_prompt}],
                task_description="Descubriendo esquema din√°micamente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   - Esquema descubierto: {len(result.get('discovered_tables', {}))} categor√≠as")
                
                return {
                    'discovered_tables': result.get('discovered_tables', {}),
                    'patterns': result.get('patterns_identified', []),
                    'suggested_mappings': result.get('suggested_mappings', {}),
                    'confidence': result.get('confidence_level', 'medium'),
                    'raw_analysis': table_analysis
                }
            else:
                return {'tables': [], 'patterns': []}
                
        except Exception as e:
            logger.error(f"Error en descubrimiento de esquema: {e}")
            return {'tables': [], 'patterns': []}

    async def _llm_analyze_context_adaptive(self, fhir_data: Dict[str, Any], schema_discovery: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 2: An√°lisis contextual de los datos FHIR.
        El LLM analiza el contexto m√©dico y determina la mejor estrategia.
        """
        try:
            if not self.llm:
                return {'context': 'general', 'strategy': 'basic'}
            
            if stream_callback:
                stream_callback("   - Analizando contexto m√©dico adaptativo...")
            
            # PROMPT ADAPTATIVO: An√°lisis contextual
            context_prompt = f"""Eres un experto en an√°lisis contextual de datos m√©dicos FHIR.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA DESCUBIERTO:
{json.dumps(schema_discovery, indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Analiza el contexto m√©dico y determina la mejor estrategia de mapeo.

AN√ÅLISIS CONTEXTUAL:
1. Identifica el tipo de informaci√≥n m√©dica presente
2. Determina la urgencia y complejidad de los datos
3. Analiza las relaciones entre diferentes elementos
4. Considera el flujo de trabajo m√©dico
5. Eval√∫a la precisi√≥n requerida

ESTRATEGIAS ADAPTATIVAS:
- Si son datos de paciente: Priorizar tablas de pacientes
- Si son observaciones: Usar tablas de observaciones
- Si son diagn√≥sticos: Mapear a tablas de diagn√≥sticos
- Si son medicamentos: Usar tablas de medicamentos
- Si son episodios: Mapear a tablas de episodios

INSTRUCCIONES:
- Analiza el contenido sem√°ntico completo
- Considera el contexto m√©dico espec√≠fico
- Determina la estrategia m√°s apropiada
- Eval√∫a la confianza en la decisi√≥n

RESPUESTA JSON:
{{
    "medical_context": "patient|diagnosis|observation|medication|episode",
    "complexity_level": "simple|medium|complex",
    "priority_strategy": "accuracy|speed|completeness",
    "suggested_approach": "direct_mapping|flexible_mapping|hybrid_mapping",
    "confidence_score": 0.85,
    "contextual_factors": ["factor1", "factor2"],
    "medical_entities": ["entidad1", "entidad2"]
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": context_prompt}],
                task_description="Analizando contexto m√©dico adaptativo"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   - Contexto: {result.get('medical_context', 'Unknown')}")
                    stream_callback(f"   - Estrategia: {result.get('suggested_approach', 'Unknown')}")
                
                return result
            else:
                return {'context': 'general', 'strategy': 'basic'}
                
        except Exception as e:
            logger.error(f"Error en an√°lisis contextual: {e}")
            return {'context': 'general', 'strategy': 'basic'}

    async def _llm_adaptive_mapping(self, fhir_data: Dict[str, Any], context_analysis: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 3: Mapeo inteligente basado en aprendizaje previo.
        El LLM aprende de cada operaci√≥n y mejora autom√°ticamente.
        """
        try:
            if not self.llm:
                return {
                    'table': 'PATI_PATIENTS',
                    'columns': ['PATI_NAME'],
                    'values': [fhir_data.get('name', '')]
                }
            
            if stream_callback:
                stream_callback("   - Mapeo adaptativo inteligente...")
            
            # Usar LLM para determinar din√°micamente la tabla correcta
            resource_type = fhir_data.get('resourceType', '')
            
            # PROMPT ADAPTATIVO: Selecci√≥n din√°mica de tabla
            table_selection_prompt = f"""Eres un experto en selecci√≥n de tablas para mapeo FHIR‚ÜíSQL.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

TIPO DE RECURSO: {resource_type}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

TAREA ADAPTATIVA: Selecciona la tabla m√°s apropiada para este tipo de recurso FHIR.

INSTRUCCIONES:
1. Analiza el tipo de recurso FHIR
2. Revisa el esquema disponible
3. Selecciona la tabla que mejor se adapte al contenido
4. Considera el contexto m√©dico
5. Usa solo tablas que existan realmente en el esquema

REGLAS DE SELECCI√ìN:
- Patient ‚Üí buscar tabla de pacientes
- Condition ‚Üí buscar tabla de condiciones/diagn√≥sticos
- Observation ‚Üí buscar tabla de observaciones
- Encounter ‚Üí buscar tabla de episodios
- Medication ‚Üí buscar tabla de medicamentos
- MedicationRequest ‚Üí buscar tabla de medicamentos

RESPUESTA JSON:
{{
    "selected_table": "nombre_tabla_seleccionada",
    "reasoning": "explicaci√≥n_de_la_selecci√≥n",
    "confidence": 0.95
}}

IMPORTANTE: Solo usa tablas que existan en el esquema real.

Responde SOLO con el JSON:"""

            # Obtener tabla seleccionada por LLM
            if self.llm:
                try:
                    response = await asyncio.to_thread(
                        _call_openai_native, self.llm, [{"role": "user", "content": table_selection_prompt}],
                        task_description="Seleccionando tabla din√°micamente"
                    )
                    
                    content = self._extract_response_text(response)
                    table_result = self._try_parse_llm_json(content)
                    
                    if table_result and table_result.get('selected_table'):
                        target_table = table_result['selected_table']
                        if stream_callback:
                            stream_callback(f"   - Tabla seleccionada din√°micamente: {target_table}")
                    else:
                        target_table = 'PATI_PATIENTS'  # Fallback
                        if stream_callback:
                            stream_callback(f"   - Usando tabla por defecto: {target_table}")
                except Exception as e:
                    logger.error(f"Error seleccionando tabla: {e}")
                    target_table = 'PATI_PATIENTS'  # Fallback
            else:
                target_table = 'PATI_PATIENTS'  # Fallback sin LLM
            
            # Obtener esquema espec√≠fico de la tabla seleccionada
            table_schema = self._get_table_schema_info(target_table)
            
            # PROMPT ADAPTATIVO: Mapeo inteligente
            mapping_prompt = f"""Eres un experto en mapeo adaptativo FHIR‚ÜíSQL que aprende de cada operaci√≥n.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

AN√ÅLISIS CONTEXTUAL:
{json.dumps(context_analysis, indent=2, ensure_ascii=False)}

TABLA OBJETIVO: {target_table}
ESQUEMA ESPEC√çFICO DE LA TABLA:
{table_schema}

TAREA ADAPTATIVA: Mapea los datos FHIR usando aprendizaje previo y contexto.

REGLAS OBLIGATORIAS (NO NEGOCIABLES):
1. SOLO usa la tabla {target_table}
2. NUNCA uses IDs ficticios, deja que se autoincrementen
3. Usa tu criterio para detectar IDs problem√°ticos
4. Usa NULL para valores nulos, NO "None"
5. SOLO usa columnas que existan en el esquema de la tabla
6. NO uses columnas que no existan
7. NUNCA uses IDs ficticios en valores
8. SOLO usa columnas que aparezcan en el esquema de {target_table}

MAPEO ADAPTATIVO:
- Analiza el esquema de {target_table}
- Identifica las columnas disponibles
- Mapea solo campos que existan realmente
- NO incluyas campos de ID en INSERT
- Usa valores reales o NULL
- Adapta el mapeo seg√∫n las columnas disponibles

INSTRUCCIONES:
- Identifica el tipo de recurso FHIR
- Usa SOLO la tabla {target_table}
- Mapea solo campos que existan en el esquema de la tabla
- NO incluyas campos de ID en INSERT
- Usa valores reales o NULL
- NO uses columnas que no existan
- Usa tu criterio para detectar IDs problem√°ticos
- Adapta el mapeo seg√∫n las columnas disponibles en {target_table}

RESPUESTA JSON:
{{
    "table": "{target_table}",
    "columns": ["columna1", "columna2"],
    "values": ["valor1", "valor2"],
    "resource_type": "{resource_type}",
    "mapping_strategy": "adaptive_mapping",
    "confidence": 0.95
}}

IMPORTANTE: SOLO usa columnas que existan en el esquema de {target_table} y usa tu criterio para detectar IDs problem√°ticos.

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": mapping_prompt}],
                task_description="Mapeo adaptativo inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   - Mapeo adaptativo: {result.get('table', 'Unknown')}")
                    stream_callback(f"   - Estrategia: {result.get('mapping_strategy', 'Unknown')}")
                
                return result
            else:
                return {
                    'table': 'PATI_PATIENTS',
                    'columns': ['PATI_NAME'],
                    'values': [fhir_data.get('name', '')]
                }
                
        except Exception as e:
            logger.error(f"Error en mapeo adaptativo: {e}")
            return {
                'table': 'PATI_PATIENTS',
                'columns': ['PATI_NAME'],
                'values': [fhir_data.get('name', '')]
            }

    async def _llm_contextual_validation(self, fhir_data: Dict[str, Any], adaptive_mapping: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 4: Validaci√≥n contextual sin reglas fijas.
        El LLM valida bas√°ndose en el contexto espec√≠fico.
        """
        try:
            if not self.llm:
                return {'needs_correction': False}
            
            if stream_callback:
                stream_callback("   - Validaci√≥n contextual adaptativa...")
            
            # PROMPT ADAPTATIVO: Validaci√≥n contextual
            validation_prompt = f"""Eres un experto en validaci√≥n contextual de mapeos FHIR‚ÜíSQL.

DATOS FHIR ORIGINALES:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

MAPEO ADAPTATIVO ACTUAL:
{json.dumps(adaptive_mapping, indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Valida el mapeo bas√°ndote en el contexto espec√≠fico.

VALIDACI√ìN CONTEXTUAL:
1. Analiza la coherencia sem√°ntica del mapeo
2. Verifica que la tabla sea apropiada para el tipo de datos
3. Valida que los campos mapeados existan realmente
4. Considera el contexto m√©dico espec√≠fico
5. Eval√∫a la precisi√≥n del mapeo

ESTRATEGIA DE VALIDACI√ìN:
- NO uses reglas fijas, adapta seg√∫n el contexto
- Considera la complejidad de los datos
- Eval√∫a la confianza del mapeo
- Identifica posibles mejoras
- Sugiere correcciones si es necesario

INSTRUCCIONES:
- Valida bas√°ndote en el contexto espec√≠fico
- Considera la complejidad identificada
- Eval√∫a la precisi√≥n del mapeo
- Sugiere mejoras si es necesario

RESPUESTA JSON:
{{
    "needs_correction": true|false,
    "correction_type": "table|columns|values|strategy",
    "suggested_improvements": ["mejora1", "mejora2"],
    "confidence_in_validation": 0.85,
    "contextual_factors": ["factor1", "factor2"]
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                task_description="Validaci√≥n contextual adaptativa"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    if result.get('needs_correction', False):
                        stream_callback(f"   - Correcci√≥n necesaria: {result.get('correction_type', 'Unknown')}")
                    else:
                        stream_callback("   - Validaci√≥n contextual exitosa")
                
                return result
            else:
                return {'needs_correction': False}
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n contextual: {e}")
            return {'needs_correction': False}

    async def _llm_apply_adaptive_corrections(self, fhir_data: Dict[str, Any], current_mapping: Dict[str, Any], validation_result: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 5: Aplicar correcciones adaptativas.
        El LLM aplica correcciones bas√°ndose en el contexto.
        """
        try:
            if not self.llm:
                return current_mapping
            
            if stream_callback:
                stream_callback("   - Aplicando correcciones adaptativas...")
            
            # PROMPT ADAPTATIVO: Correcciones
            correction_prompt = f"""Eres un experto en correcciones adaptativas de mapeos FHIR‚ÜíSQL.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

MAPEO ACTUAL:
{json.dumps(current_mapping, indent=2, ensure_ascii=False)}

RESULTADO DE VALIDACI√ìN:
{json.dumps(validation_result, indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Aplica correcciones bas√°ndote en el contexto espec√≠fico.

ESTRATEGIA DE CORRECCI√ìN:
1. Analiza el tipo de correcci√≥n necesaria
2. Aplica mejoras basadas en el contexto
3. Considera la complejidad de los datos
4. Optimiza para precisi√≥n y rendimiento
5. Mant√©n la coherencia sem√°ntica

INSTRUCCIONES:
- Aplica correcciones espec√≠ficas al contexto
- Considera las sugerencias de mejora
- Mant√©n la l√≥gica original cuando sea posible
- Optimiza para el tipo de datos espec√≠fico

RESPUESTA JSON:
{{
    "table": "tabla_corregida",
    "columns": ["columna1", "columna2"],
    "values": ["valor1", "valor2"],
    "resource_type": "tipo_corregido",
    "corrections_applied": ["correcci√≥n1", "correcci√≥n2"],
    "confidence": 0.9
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": correction_prompt}],
                task_description="Aplicando correcciones adaptativas"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   - Correcciones aplicadas: {len(result.get('corrections_applied', []))}")
                
                return result
            else:
                return current_mapping
                
        except Exception as e:
            logger.error(f"Error aplicando correcciones adaptativas: {e}")
            return current_mapping

    async def _llm_adaptive_cleanup(self, mapping_result: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        PASO 6: Limpieza final adaptativa.
        El LLM limpia y optimiza el resultado final.
        """
        try:
            if not self.llm:
                return mapping_result
            
            if stream_callback:
                stream_callback("   - Limpieza final adaptativa...")
            
            # Obtener esquema espec√≠fico de la tabla para validaci√≥n
            table_name = mapping_result.get('table', 'PATI_PATIENTS')
            table_schema = self._get_table_schema_info(table_name)
            
            # PROMPT ADAPTATIVO: Limpieza final
            cleanup_prompt = f"""Eres un experto en limpieza adaptativa de mapeos FHIR‚ÜíSQL.

RESULTADO DEL MAPEO:
{json.dumps(mapping_result, indent=2, ensure_ascii=False)}

TABLA OBJETIVO: {table_name}
ESQUEMA ESPEC√çFICO DE LA TABLA:
{table_schema}

TAREA ADAPTATIVA: Limpia y optimiza el resultado final.

LIMPIEZA ADAPTATIVA CR√çTICA:
1. ELIMINA TODOS los IDs ficticios, deja que se autoincrementen
2. Usa tu criterio para detectar IDs problem√°ticos
3. Convierte tipos de datos apropiadamente
4. Maneja valores nulos correctamente (NULL, no "None")
5. Optimiza para rendimiento
6. Asegura coherencia sem√°ntica
7. SOLO usa columnas que existan en el esquema de la tabla

REGLAS DE LIMPIEZA OBLIGATORIAS:
- Usa tu criterio para detectar y eliminar IDs problem√°ticos
- Convierte a NULL o valor real seg√∫n corresponda
- Convierte "None" ‚Üí NULL
- Convierte "null" ‚Üí NULL
- Usa fechas en formato SQLite (YYYY-MM-DD)
- SOLO usa columnas que existan en el esquema de {table_name}
- NO uses columnas que no existan (como PATI_IDENTIFIER, PATI_PHONE, PATI_ADDRESS)

INSTRUCCIONES:
- Limpia TODOS los valores problem√°ticos
- Optimiza para la base de datos espec√≠fica
- Mant√©n la coherencia sem√°ntica
- Asegura que el resultado sea ejecutable
- Usa tu criterio para detectar IDs problem√°ticos
- SOLO usa columnas que existan en el esquema de {table_name}

RESPUESTA JSON:
{{
    "table": "{table_name}",
    "columns": ["columna1", "columna2"],
    "values": ["valor1", "valor2"],
    "resource_type": "tipo_final",
    "cleanup_applied": ["limpieza1", "limpieza2"],
    "final_confidence": 0.95
}}

IMPORTANTE: USA TU CRITERIO PARA DETECTAR IDs PROBLEM√ÅTICOS Y SOLO USA COLUMNAS QUE EXISTAN.

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": cleanup_prompt}],
                task_description="Limpieza final adaptativa"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                if stream_callback:
                    stream_callback(f"   - Limpieza final adaptativa completada")
                
                return result
            else:
                return mapping_result
                
        except Exception as e:
            logger.error(f"Error en limpieza adaptativa: {e}")
            return mapping_result

    async def _llm_validate_and_correct_ids_adaptive(self, columns: List[str], values: List[Any], stream_callback=None) -> List[Any]:
        """
        VALIDACI√ìN ADAPTATIVA: Usa LLM para detectar y corregir IDs ficticios.
        Sin patterns r√≠gidos - todo via LLM.
        """
        try:
            if not self.llm:
                return values
            
            if stream_callback:
                stream_callback("   - Validando IDs con IA adaptativa...")
            
            # PROMPT ADAPTATIVO: Validaci√≥n de IDs
            validation_prompt = f"""Eres un experto en validaci√≥n de IDs en bases de datos m√©dicas.

COLUMNAS Y VALORES A VALIDAR:
{json.dumps(list(zip(columns, values)), indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Analiza cada valor y detecta si es un ID ficticio o problem√°tico.

CRITERIOS DE VALIDACI√ìN:
1. Identifica IDs ficticios o problem√°ticos usando tu criterio
2. Detecta IDs que no son reales
3. Identifica valores que deber√≠an ser NULL
4. Corrige valores problem√°ticos autom√°ticamente

ESTRATEGIA ADAPTATIVA:
- Analiza el contexto de cada columna
- Considera el tipo de datos esperado
- Identifica patrones de IDs problem√°ticos usando tu criterio
- Sugiere correcciones apropiadas

INSTRUCCIONES:
- Analiza cada par columna-valor
- Identifica IDs problem√°ticos usando tu criterio
- Sugiere valores corregidos
- Mant√©n valores v√°lidos sin cambios

RESPUESTA JSON:
{{
    "corrected_values": ["valor1", "valor2", "valor3"],
    "corrections_applied": ["correcci√≥n1", "correcci√≥n2"],
    "validation_confidence": 0.95
}}

IMPORTANTE: Si un valor es un ID problem√°tico, reempl√°zalo con NULL.

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                task_description="Validando IDs con IA adaptativa"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and 'corrected_values' in result:
                corrected_values = result['corrected_values']
                corrections = result.get('corrections_applied', [])
                confidence = result.get('validation_confidence', 0.0)
                
                # VALIDACI√ìN ADAPTATIVA: Limpieza b√°sica sin recursi√≥n
                final_values = []
                for value in corrected_values:
                    if value == "NULL" or value == "null" or value == "None":
                        final_values.append(None)
                    elif isinstance(value, str) and value.lower() in ["null", "none"]:
                        final_values.append(None)
                    else:
                        final_values.append(value)
                
                if stream_callback:
                    stream_callback(f"   - Validaci√≥n completada: {len(corrections)} correcciones")
                    stream_callback(f"   - Confianza: {confidence}")
                
                return final_values
            else:
                return values
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n de IDs adaptativa: {e}")
            return values

    async def _llm_validate_and_correct_table_adaptive(self, current_table: str, resource_type: str, stream_callback=None) -> str:
        """
        VALIDACI√ìN ADAPTATIVA: Usa LLM para validar y corregir tabla.
        Sin patterns r√≠gidos - todo via LLM.
        """
        try:
            if not self.llm:
                return current_table
            
            if stream_callback:
                stream_callback("   - Validando tabla con IA adaptativa...")
            
            # PROMPT ADAPTATIVO: Validaci√≥n de tabla
            validation_prompt = f"""Eres un experto en validaci√≥n de tablas en bases de datos m√©dicas.

TABLA ACTUAL: {current_table}
TIPO DE RECURSO: {resource_type}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

TAREA ADAPTATIVA: Valida si la tabla es apropiada para el tipo de recurso.

CRITERIOS DE VALIDACI√ìN:
1. Verifica que la tabla existe en el esquema
2. Analiza si es apropiada para el tipo de recurso
3. Sugiere tabla alternativa si es necesario
4. Considera el contexto m√©dico

ESTRATEGIA ADAPTATIVA:
- Analiza la funci√≥n de cada tabla
- Considera el tipo de datos del recurso
- Identifica la tabla m√°s apropiada
- Sugiere correcciones si es necesario

INSTRUCCIONES:
- Verifica que la tabla existe
- Analiza si es apropiada para el recurso
- Sugiere tabla alternativa si es necesario
- Mant√©n la tabla si es correcta

RESPUESTA JSON:
{{
    "corrected_table": "tabla_corregida",
    "needs_correction": true|false,
    "reasoning": "explicaci√≥n de la correcci√≥n",
    "confidence": 0.95
}}

IMPORTANTE: Solo sugiere tablas que existan realmente en el esquema.

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                task_description="Validando tabla con IA adaptativa"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                corrected_table = result.get('corrected_table', current_table)
                needs_correction = result.get('needs_correction', False)
                reasoning = result.get('reasoning', 'Sin explicaci√≥n')
                confidence = result.get('confidence', 0.0)
                
                if stream_callback:
                    if needs_correction:
                        stream_callback(f"   - Tabla corregida: {current_table} ‚Üí {corrected_table}")
                        stream_callback(f"   - Raz√≥n: {reasoning}")
                    else:
                        stream_callback("   - Tabla validada correctamente")
                    stream_callback(f"   - Confianza: {confidence}")
                
                return corrected_table
            else:
                return current_table
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n de tabla adaptativa: {e}")
            return current_table

    async def _llm_final_cleanup_adaptive(self, mapping_result: Dict[str, Any], stream_callback=None) -> Dict[str, Any]:
        """
        LIMPIEZA FINAL ADAPTATIVA: Usa LLM para limpieza final completa.
        Sin patterns r√≠gidos - todo via LLM.
        """
        try:
            if not self.llm:
                return mapping_result
            
            if stream_callback:
                stream_callback("   - Limpieza final adaptativa...")
            
            # PROMPT ADAPTATIVO: Limpieza final
            cleanup_prompt = f"""Eres un experto en limpieza final de mapeos FHIR‚ÜíSQL.

RESULTADO DEL MAPEO:
{json.dumps(mapping_result, indent=2, ensure_ascii=False)}

TAREA ADAPTATIVA: Realiza limpieza final completa del mapeo.

LIMPIEZA FINAL ADAPTATIVA:
1. Elimina TODOS los IDs ficticios y UUIDs problem√°ticos
2. Convierte tipos de datos apropiadamente
3. Maneja valores nulos correctamente
4. Optimiza para rendimiento
5. Asegura coherencia sem√°ntica

ESTRATEGIA ADAPTATIVA:
- Analiza cada valor individualmente
- Identifica patrones problem√°ticos
- Aplica correcciones inteligentes
- Mant√©n valores v√°lidos
- Optimiza para la base de datos espec√≠fica

INSTRUCCIONES:
- Analiza cada columna y valor
- Identifica y corrige problemas
- Optimiza para SQLite
- Asegura que el resultado sea ejecutable
- Mant√©n la coherencia sem√°ntica
- Para valores nulos, usa null (no "NULL" como string)

RESPUESTA JSON:
{{
    "table": "tabla_final",
    "columns": ["columna1", "columna2"],
    "values": ["valor1", null],
    "resource_type": "tipo_final",
    "cleanup_applied": ["limpieza1", "limpieza2"],
    "final_confidence": 0.95
}}

IMPORTANTE: 
- Elimina TODOS los IDs ficticios y valores problem√°ticos
- Para valores nulos, usa null (no "NULL" como string)
- NO uses "NULL" como string, usa null

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": cleanup_prompt}],
                task_description="Limpieza final adaptativa"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                # VALIDACI√ìN ADICIONAL: Convertir "NULL" strings a None
                values = result.get('values', [])
                columns = result.get('columns', [])
                
                if values and columns:
                    # Limpieza b√°sica sin recursi√≥n
                    corrected_values = []
                    for i, value in enumerate(values):
                        if value == "NULL" or value == "null" or value == "None":
                            corrected_values.append(None)
                        elif isinstance(value, str) and value.lower() in ["null", "none"]:
                            corrected_values.append(None)
                        else:
                            corrected_values.append(value)
                    result['values'] = corrected_values
                
                cleanup_applied = result.get('cleanup_applied', [])
                final_confidence = result.get('final_confidence', 0.0)
                
                if stream_callback:
                    stream_callback(f"   - Limpieza final: {len(cleanup_applied)} optimizaciones")
                    stream_callback(f"   - Confianza final: {final_confidence}")
                
                return result
            else:
                return mapping_result
                
        except Exception as e:
            logger.error(f"Error en limpieza final adaptativa: {e}")
            return mapping_result

    async def _detect_and_fix_missing_joins(self, sql: str, stream_callback=None) -> str:
        """
        Detecta y corrige JOINs faltantes usando la nueva funci√≥n flexible.
        ARQUITECTURA ADAPTATIVA: Usa prompts espec√≠ficos seg√∫n el contexto.
        """
        try:
            if not self.llm:
                if stream_callback:
                    stream_callback("   - Verificaci√≥n b√°sica de JOINs (sin LLM)...")
                return sql
            
            if stream_callback:
                stream_callback("   - Detectando JOINs faltantes con IA...")
            
            # Usar la nueva funci√≥n flexible con contexto vac√≠o
            return await self._llm_flexible_sql_analysis(sql, "", stream_callback)
                
        except Exception as e:
            logger.error(f"Error en _detect_and_fix_missing_joins: {e}")
            return sql



    def _extract_medical_codes_from_codr_table(self, medical_terms: List[str]) -> List[str]:
        """
        Extrae c√≥digos CDTE_ID asociados con t√©rminos m√©dicos de la tabla CODR_TABULAR_DIAGNOSTICS.
        
        Args:
            medical_terms: Lista de t√©rminos m√©dicos a buscar (ej: ['diabetes', 'hipertensi√≥n'])
            
        Returns:
            List[str]: Lista de c√≥digos CDTE_ID que corresponden a los t√©rminos m√©dicos
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Verificar si la tabla tiene datos
            cursor.execute("SELECT COUNT(*) FROM CODR_TABULAR_DIAGNOSTICS WHERE COTA_DESCRIPTION_ES IS NOT NULL")
            count = cursor.fetchone()[0]
            
            if count == 0:
                logger.warning("‚ö†Ô∏è La tabla CODR_TABULAR_DIAGNOSTICS est√° vac√≠a o no tiene descripciones")
                conn.close()
                return []
            
            medical_codes = []
            
            for term in medical_terms:
                cursor.execute("""
                    SELECT COTA_ID, COTA_DESCRIPTION_ES 
                    FROM CODR_TABULAR_DIAGNOSTICS 
                    WHERE UPPER(COTA_DESCRIPTION_ES) LIKE UPPER(?)
                """, (f'%{term}%',))
                
                results = cursor.fetchall()
                for code, description in results:
                    if code not in medical_codes:
                        medical_codes.append(str(code))
                        logger.info(f"üîç C√≥digo m√©dico encontrado: {code} - {description}")
            
            conn.close()
            
            logger.info(f"‚úÖ Se encontraron {len(medical_codes)} c√≥digos para t√©rminos: {medical_terms}")
            return medical_codes
            
        except Exception as e:
            logger.error(f"Error extrayendo c√≥digos m√©dicos: {e}")
            return []

    async def _llm_detect_medical_terms_and_codes(self, query: str, stream_callback=None) -> Dict[str, Any]:
        """
        Usa LLM para detectar autom√°ticamente t√©rminos m√©dicos y extraer c√≥digos correspondientes.
        ARQUITECTURA SOSTENIBLE: 100% basada en LLM, sin hardcodeo.
        
        Args:
            query: Consulta original del usuario
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Dict[str, Any]: Informaci√≥n sobre t√©rminos m√©dicos y c√≥digos encontrados
        """
        try:
            if not self.llm:
                # Fallback b√°sico sin LLM
                return {
                    'medical_terms': [],
                    'medical_codes': [],
                    'search_strategy': 'free_text'
                }
            
            if stream_callback:
                stream_callback("   - Detectando t√©rminos m√©dicos con IA avanzada...")
            
            # PROMPT ESPEC√çFICO PARA DETECCI√ìN M√âDICA - SIN HARDCODEO
            detection_prompt = f"""Eres un experto en terminolog√≠a m√©dica y c√≥digos de diagn√≥stico.

CONSULTA DEL USUARIO: "{query}"

TAREA ESPEC√çFICA: Analiza la consulta y extrae t√©rminos m√©dicos relevantes que podr√≠an tener c√≥digos oficiales en la base de datos.

INSTRUCCIONES DETALLADAS:
1. Identifica condiciones m√©dicas, diagn√≥sticos, enfermedades mencionadas
2. Incluye sin√≥nimos y variaciones comunes (ej: diabetes ‚Üí diab√©tico, diab√©tica, DM)
3. Considera abreviaciones m√©dicas (DM = diabetes mellitus, HTA = hipertensi√≥n arterial)
4. Incluye t√©rminos en espa√±ol e ingl√©s si aplica
5. Detecta t√©rminos relacionados y comorbilidades
6. Identifica la condici√≥n principal y secundarias

ESTRATEGIA DE DETECCI√ìN:
- Buscar t√©rminos m√©dicos espec√≠ficos
- Identificar condiciones cr√≥nicas y agudas
- Detectar s√≠ntomas y signos
- Reconocer medicamentos y tratamientos
- Identificar especialidades m√©dicas mencionadas

RESPUESTA JSON ESTRUCTURADA:
{{
    "medical_terms": ["t√©rmino1", "t√©rmino2", "t√©rmino3"],
    "primary_condition": "condici√≥n principal identificada",
    "secondary_conditions": ["condici√≥n2", "condici√≥n3"],
    "symptoms": ["s√≠ntoma1", "s√≠ntoma2"],
    "medications": ["medicamento1", "medicamento2"],
    "search_strategy": "official_codes|free_text|hybrid",
    "confidence_level": "high|medium|low",
    "specialties_involved": ["especialidad1", "especialidad2"]
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": detection_prompt}],
                task_description="Detectando t√©rminos m√©dicos con IA avanzada"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and 'medical_terms' in result:
                medical_terms = result['medical_terms']
                primary_condition = result.get('primary_condition', '')
                search_strategy = result.get('search_strategy', 'free_text')
                confidence_level = result.get('confidence_level', 'medium')
                
                # NUEVO: Extraer c√≥digos oficiales usando LLM espec√≠fico
                medical_codes = await self._llm_extract_medical_codes_intelligent(medical_terms, stream_callback)
                
                if stream_callback:
                    if medical_codes:
                        stream_callback(f"   - Encontrados {len(medical_codes)} c√≥digos oficiales para {primary_condition}")
                    else:
                        stream_callback(f"   - No se encontraron c√≥digos oficiales, usando b√∫squeda libre")
                
                return {
                    'medical_terms': medical_terms,
                    'medical_codes': medical_codes,
                    'primary_condition': primary_condition,
                    'search_strategy': search_strategy,
                    'confidence_level': confidence_level,
                    'secondary_conditions': result.get('secondary_conditions', []),
                    'symptoms': result.get('symptoms', []),
                    'medications': result.get('medications', []),
                    'specialties_involved': result.get('specialties_involved', [])
                }
            else:
                logger.warning("‚ö†Ô∏è LLM no pudo detectar t√©rminos m√©dicos, usando b√∫squeda libre")
                return {
                    'medical_terms': [],
                    'medical_codes': [],
                    'search_strategy': 'free_text',
                    'confidence_level': 'low'
                }
                
        except Exception as e:
            logger.error(f"Error detectando t√©rminos m√©dicos: {e}")
            return {
                'medical_terms': [],
                'medical_codes': [],
                'search_strategy': 'free_text',
                'confidence_level': 'low'
            }

    async def _llm_extract_medical_codes_intelligent(self, medical_terms: List[str], stream_callback=None) -> List[str]:
        """
        Extrae c√≥digos m√©dicos usando LLM espec√≠fico - SIN HARDCODEO.
        ARQUITECTURA SOSTENIBLE: Todo via LLM.
        
        Args:
            medical_terms: T√©rminos m√©dicos detectados
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            List[str]: C√≥digos m√©dicos encontrados
        """
        try:
            if not self.llm or not medical_terms:
                return []
            
            if stream_callback:
                stream_callback("   - Extrayendo c√≥digos m√©dicos con IA espec√≠fica...")
            
            # PROMPT ESPEC√çFICO PARA EXTRACCI√ìN DE C√ìDIGOS - SIN HARDCODEO
            code_extraction_prompt = f"""Eres un experto en c√≥digos de diagn√≥stico m√©dico y terminolog√≠a cl√≠nica.

T√âRMINOS M√âDICOS DETECTADOS: {medical_terms}

TAREA ESPEC√çFICA: Analiza estos t√©rminos m√©dicos y genera c√≥digos de diagn√≥stico que podr√≠an existir en la base de datos.

ESTRATEGIA DE EXTRACCI√ìN:
1. Identifica c√≥digos ICD-10, CIE-10, o c√≥digos locales que podr√≠an corresponder
2. Considera variaciones y sin√≥nimos de los t√©rminos
3. Incluye c√≥digos relacionados y subcategor√≠as
4. Genera c√≥digos num√©ricos y alfanum√©ricos
5. Considera c√≥digos de diferentes sistemas de clasificaci√≥n

EJEMPLOS DE CORRESPONDENCIA:
- diabetes ‚Üí ['E11', 'E10', 'E13', '250']
- hipertensi√≥n ‚Üí ['I10', 'I11', 'I12', '401']
- c√°ncer ‚Üí ['C00-C97', '140-208']
- asma ‚Üí ['J45', 'J46', '493']

INSTRUCCIONES:
- Genera c√≥digos que podr√≠an existir en la base de datos
- Incluye c√≥digos principales y secundarios
- Considera c√≥digos de diferentes especialidades
- Mant√©n formato consistente

RESPUESTA JSON:
{{
    "primary_codes": ["c√≥digo1", "c√≥digo2"],
    "secondary_codes": ["c√≥digo3", "c√≥digo4"],
    "related_codes": ["c√≥digo5", "c√≥digo6"],
    "code_system": "ICD-10|CIE-10|local",
    "confidence": "high|medium|low"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": code_extraction_prompt}],
                task_description="Extrayendo c√≥digos m√©dicos con IA espec√≠fica"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                # Combinar todos los c√≥digos
                all_codes = []
                all_codes.extend(result.get('primary_codes', []))
                all_codes.extend(result.get('secondary_codes', []))
                all_codes.extend(result.get('related_codes', []))
                
                # Verificar qu√© c√≥digos realmente existen en la base de datos
                existing_codes = await self._llm_verify_codes_in_database(all_codes, stream_callback)
                
                if stream_callback:
                    stream_callback(f"   - Verificados {len(existing_codes)} c√≥digos en la base de datos")
                
                return existing_codes
            else:
                logger.warning("‚ö†Ô∏è LLM no pudo extraer c√≥digos m√©dicos")
                return []
                
        except Exception as e:
            logger.error(f"Error extrayendo c√≥digos m√©dicos: {e}")
            return []

    async def _llm_verify_codes_in_database(self, codes: List[str], stream_callback=None) -> List[str]:
        """
        Verifica qu√© c√≥digos realmente existen en la base de datos usando LLM.
        ARQUITECTURA SOSTENIBLE: Sin hardcodeo.
        
        Args:
            codes: C√≥digos a verificar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            List[str]: C√≥digos que existen en la base de datos
        """
        try:
            if not self.llm or not codes:
                return []
            
            # Obtener informaci√≥n real de la base de datos
            db_info = await self._llm_get_database_schema_info(stream_callback)
            
            # PROMPT ESPEC√çFICO PARA VERIFICACI√ìN - SIN HARDCODEO
            verification_prompt = f"""Eres un experto en bases de datos m√©dicas que verifica la existencia de c√≥digos.

C√ìDIGOS A VERIFICAR: {codes}

INFORMACI√ìN DE LA BASE DE DATOS:
{db_info}

TAREA ESPEC√çFICA: Analiza qu√© c√≥digos podr√≠an existir realmente en esta base de datos.

ESTRATEGIA DE VERIFICACI√ìN:
1. Analiza la estructura de la base de datos
2. Identifica patrones de c√≥digos existentes
3. Considera el formato y rango de c√≥digos
4. Eval√∫a la probabilidad de existencia
5. Prioriza c√≥digos m√°s probables

INSTRUCCIONES:
- Si la tabla de c√≥digos est√° vac√≠a, devuelve lista vac√≠a
- Si hay patrones de c√≥digos, identifica los m√°s probables
- Considera el contexto m√©dico de la base de datos
- Eval√∫a la coherencia con el esquema

RESPUESTA JSON:
{{
    "existing_codes": ["c√≥digo1", "c√≥digo2"],
    "probability": "high|medium|low",
    "reasoning": "explicaci√≥n de la verificaci√≥n"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": verification_prompt}],
                task_description="Verificando c√≥digos en la base de datos"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                existing_codes = result.get('existing_codes', [])
                probability = result.get('probability', 'low')
                
                if stream_callback:
                    stream_callback(f"   - Probabilidad de c√≥digos: {probability}")
                
                return existing_codes
            else:
                return []
                
        except Exception as e:
            logger.error(f"Error verificando c√≥digos: {e}")
            return []

    async def _llm_get_database_schema_info(self, stream_callback=None) -> str:
        """
        Obtiene informaci√≥n del esquema de la base de datos usando LLM.
        ARQUITECTURA SOSTENIBLE: Sin hardcodeo.
        
        Args:
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: Informaci√≥n del esquema formateada
        """
        try:
            # Obtener informaci√≥n real de la base de datos
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Verificar tabla de c√≥digos
            cursor.execute("SELECT COUNT(*) FROM CODR_TABULAR_DIAGNOSTICS WHERE COTA_DESCRIPTION_ES IS NOT NULL")
            codigos_count = cursor.fetchone()[0]
            
            # Obtener ejemplos de diagn√≥sticos
            cursor.execute("SELECT DIAG_OBSERVATION FROM EPIS_DIAGNOSTICS WHERE DIAG_OBSERVATION IS NOT NULL LIMIT 10")
            diagnosticos_ejemplos = [row[0] for row in cursor.fetchall()]
            
            # Obtener estructura de tablas
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tablas = [row[0] for row in cursor.fetchall()]
            
            conn.close()
            
            # PROMPT ESPEC√çFICO PARA AN√ÅLISIS DE ESQUEMA - SIN HARDCODEO
            schema_prompt = f"""Eres un experto en an√°lisis de esquemas de bases de datos m√©dicas.

INFORMACI√ìN DE LA BASE DE DATOS:
- Tabla CODR_TABULAR_DIAGNOSTICS: {codigos_count} registros con descripciones
- Tablas disponibles: {tablas}
- Ejemplos de diagn√≥sticos: {diagnosticos_ejemplos}

TAREA ESPEC√çFICA: Analiza esta informaci√≥n y proporciona un resumen estructurado del esquema.

AN√ÅLISIS REQUERIDO:
1. Estado de la tabla de c√≥digos oficiales
2. Tipos de diagn√≥sticos disponibles
3. Patrones en los datos
4. Capacidades de b√∫squeda
5. Limitaciones identificadas

RESPUESTA ESTRUCTURADA:
{{
    "codigos_status": "available|empty|limited",
    "diagnosticos_count": {len(diagnosticos_ejemplos)},
    "search_capabilities": ["b√∫squeda1", "b√∫squeda2"],
    "limitations": ["limitaci√≥n1", "limitaci√≥n2"],
    "recommended_strategy": "official_codes|free_text|hybrid"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": schema_prompt}],
                task_description="Analizando esquema de la base de datos"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                return json.dumps(result, indent=2, ensure_ascii=False)
            else:
                return f"Tabla de c√≥digos: {codigos_count} registros, Diagn√≥sticos: {len(diagnosticos_ejemplos)} ejemplos"
                
        except Exception as e:
            logger.error(f"Error obteniendo informaci√≥n del esquema: {e}")
            return "Error obteniendo informaci√≥n del esquema"

    async def _process_medical_query_specialized(self, query: str, stream_callback=None) -> Optional[Dict[str, Any]]:
        """
        Procesa consultas m√©dicas de manera especializada usando m√∫ltiples llamadas a LLM espec√≠ficas.
        ARQUITECTURA SOSTENIBLE: 100% LLM, sin patterns hardcodeados.
        
        Args:
            query: Consulta original del usuario
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Optional[Dict[str, Any]]: Resultado si es consulta m√©dica, None si no
        """
        try:
            # LLAMADA 1: Detectar si es consulta m√©dica usando LLM espec√≠fico
            is_medical = await self._llm_detect_medical_query(query, stream_callback)
            
            if not is_medical:
                return None
            
            if stream_callback:
                stream_callback("ü©∫ Detectada consulta m√©dica, usando an√°lisis especializado...")
            
            # LLAMADA 2: Detectar t√©rminos m√©dicos y c√≥digos
            medical_info = await self._llm_detect_medical_terms_and_codes(query, stream_callback)
            
            # LLAMADA 3: Generar SQL espec√≠fico para diagn√≥sticos m√©dicos
            generated_sql = await self._llm_generate_medical_diagnosis_sql(query, medical_info, stream_callback)
            
            if generated_sql and not generated_sql.startswith("Error"):
                # LLAMADA 4: Ejecutar con validaci√≥n robusta
                result = await self._execute_sql_with_llm_validation(query, generated_sql, time.time(), [], stream_callback)
                
                # LLAMADA 5: Interpretaci√≥n m√©dica de resultados
                if result.get('success'):
                    if stream_callback:
                        stream_callback("ü©∫ Interpretando resultados m√©dicos...")
                    
                    interpretation = await self._llm_interpret_medical_results(query, result.get('data', []), stream_callback)
                    result['explanation'] = interpretation
                
                return result
            
            return None
            
        except Exception as e:
            logger.error(f"Error procesando consulta m√©dica especializada: {e}")
            return None

    async def _llm_detect_medical_query(self, query: str, stream_callback=None) -> bool:
        """
        LLAMADA ESPEC√çFICA 1: Detecta si una consulta es m√©dica usando LLM.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            query: Consulta a analizar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            bool: True si es consulta m√©dica, False si no
        """
        try:
            if not self.llm:
                return False
            
            if stream_callback:
                stream_callback("   - Detectando si es consulta m√©dica con IA...")
            
            # PROMPT ESPEC√çFICO PARA DETECCI√ìN M√âDICA - SIN HARDCODEO
            medical_detection_prompt = f"""Eres un experto en clasificaci√≥n de consultas m√©dicas.

CONSULTA: "{query}"

TAREA ESPEC√çFICA: Determina si esta consulta es de naturaleza m√©dica o cl√≠nica.

CRITERIOS DE CLASIFICACI√ìN M√âDICA:
- Preguntas sobre pacientes, diagn√≥sticos, enfermedades
- Consultas sobre s√≠ntomas, condiciones m√©dicas
- B√∫squedas de informaci√≥n cl√≠nica
- Preguntas sobre tratamientos, medicamentos
- Consultas sobre especialidades m√©dicas
- Preguntas sobre datos de salud

CRITERIOS NO M√âDICOS:
- Consultas administrativas generales
- Preguntas sobre el sistema o base de datos
- Consultas t√©cnicas no relacionadas con salud
- Preguntas sobre configuraci√≥n o mantenimiento

INSTRUCCIONES:
1. Analiza el contenido sem√°ntico de la consulta
2. Identifica si menciona conceptos m√©dicos, pacientes, diagn√≥sticos
3. Considera el contexto y la intenci√≥n de la consulta
4. Eval√∫a si requiere conocimiento m√©dico para responder

RESPUESTA JSON:
{{
    "is_medical": true|false,
    "confidence": "high|medium|low",
    "medical_elements": ["elemento1", "elemento2"],
    "reasoning": "explicaci√≥n de la clasificaci√≥n"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": medical_detection_prompt}],
                task_description="Detectando consulta m√©dica"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                is_medical = result.get('is_medical', False)
                confidence = result.get('confidence', 'low')
                
                if stream_callback:
                    stream_callback(f"   - Clasificaci√≥n m√©dica: {is_medical} (confianza: {confidence})")
                
                return is_medical
            else:
                return False
                
        except Exception as e:
            logger.error(f"Error detectando consulta m√©dica: {e}")
            return False

    async def _llm_handle_patient_search(self, query: str, stream_callback=None) -> Optional[Dict[str, Any]]:
        """
        LLAMADA ESPEC√çFICA 2: Maneja b√∫squedas de pacientes usando LLM.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            query: Consulta sobre pacientes
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Optional[Dict[str, Any]]: Resultado de b√∫squeda de pacientes
        """
        try:
            if not self.llm:
                return None
            
            if stream_callback:
                stream_callback("   - Analizando b√∫squeda de pacientes con IA...")
            
            # PROMPT SIMPLE PARA DETECCI√ìN DE PACIENTES
            patient_search_prompt = f"""¬øEs esta consulta sobre pacientes?

CONSULTA: "{query}"

Responde JSON:
{{
    "is_patient_query": true|false,
    "confidence": "high|medium|low"
}}"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": patient_search_prompt}],
                task_description="Analizando b√∫squeda de pacientes"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                is_patient_query = result.get('is_patient_query', False)
                confidence = result.get('confidence', 'low')
                
                if stream_callback:
                    stream_callback(f"   - Es consulta de pacientes: {is_patient_query} (confianza: {confidence})")
                
                if is_patient_query:
                    # LLAMADA ESPEC√çFICA 3: Generar SQL para b√∫squeda de pacientes
                    sql = await self._llm_generate_patient_search_sql(query, result, stream_callback)
                    
                    if sql:
                        # Ejecutar la b√∫squeda
                        search_result = await self._execute_sql_with_llm_validation(query, sql, time.time(), [], stream_callback)
                        
                        # LLAMADA ESPEC√çFICA 4: Interpretar resultados de pacientes
                        if search_result.get('success'):
                            interpretation = await self._llm_interpret_patient_results(query, search_result.get('data', []), stream_callback)
                            search_result['explanation'] = interpretation
                        
                        return search_result
            
            return None
            
            return None
            
        except Exception as e:
            logger.error(f"Error en b√∫squeda de pacientes: {e}")
            return None

    async def _llm_generate_patient_search_sql(self, query: str, search_info: Dict[str, Any], stream_callback=None) -> str:
        """
        LLAMADA ESPEC√çFICA 3: Genera SQL para b√∫squeda de pacientes usando LLM.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            query: Consulta original
            search_info: Informaci√≥n de b√∫squeda
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL para b√∫squeda de pacientes
        """
        try:
            if not self.llm:
                return ""
            
            if stream_callback:
                stream_callback("   - Generando SQL para b√∫squeda de pacientes...")
            
            # Obtener contexto din√°mico de la base de datos
            try:
                from utils.schema_discovery import get_dynamic_sql_context, SchemaDiscovery
                discovery = SchemaDiscovery(self.db_path)
                if discovery.connect():
                    try:
                        db_context = discovery.generate_sql_prompt_context(['PATI_PATIENTS', 'PARA_GENDERS'])
                        # Descubrir valores de columnas autom√°ticamente
                        column_values = discovery.discover_all_column_values('PARA_GENDERS')
                        if column_values:
                            db_context += "\n\nVALORES DE COLUMNAS DESCUBIERTOS:\n"
                            for col_name, values in column_values.items():
                                if values.values:
                                    db_context += f"- PARA_GENDERS.{col_name}: {', '.join(map(str, values.values))}\n"
                    finally:
                        discovery.close()
                else:
                    db_context = "TABLAS DISPONIBLES:\n- PATI_PATIENTS: PATI_ID, PATI_FULL_NAME, PATI_BIRTH_DATE, GEND_ID, PATI_ACTIVE\n- PARA_GENDERS: GEND_ID, GEND_DESCRIPTION_ES"
            except Exception as e:
                logger.warning(f"No se pudo obtener contexto din√°mico: {e}")
                db_context = "TABLAS DISPONIBLES:\n- PATI_PATIENTS: PATI_ID, PATI_FULL_NAME, PATI_BIRTH_DATE, GEND_ID, PATI_ACTIVE\n- PARA_GENDERS: GEND_ID, GEND_DESCRIPTION_ES"
            
            # PROMPT DIN√ÅMICO PARA SQL DE PACIENTES
            patient_sql_prompt = f"""Genera SQL para b√∫squeda de pacientes.

CONSULTA: "{query}"

{db_context}

REGLAS:
- Usa PATI_PATIENTS para datos b√°sicos
- Para g√©nero, usa JOIN con PARA_GENDERS
- Para edad, usa PATI_BIRTH_DATE con strftime
- NO uses tablas de diagn√≥sticos
- Mant√©n el SQL simple

Responde SOLO con SQL:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": patient_sql_prompt}],
                task_description="Generando SQL para b√∫squeda de pacientes"
            )
            
            sql = self._extract_response_text(response).strip()
            sql = self._clean_llm_sql_response(sql)
            
            # Si el LLM no gener√≥ SQL v√°lido, usar herramientas gen√©ricas
            if not sql or sql.startswith("Error") or "SELECT" not in sql.upper():
                sql = await self._use_generic_sql_tools(query, stream_callback)
            
            # Validaci√≥n simple del SQL generado
            if sql and not sql.startswith("Error"):
                # Validar que no tenga JOINs problem√°ticos
                if "EPIS_DIAGNOSTICS" in sql.upper():
                    if stream_callback:
                        stream_callback("   ‚ö†Ô∏è Detectando JOIN problem√°tico, corrigiendo...")
                    corrected_sql = await self._llm_correct_patient_search_sql(query, sql, stream_callback)
                    if corrected_sql:
                        sql = corrected_sql
                
                if stream_callback:
                    stream_callback("   ‚úÖ SQL para pacientes generado")
                return sql
            else:
                return ""
                
        except Exception as e:
            logger.error(f"Error generando SQL para pacientes: {e}")
            return ""

    async def _llm_correct_patient_search_sql(self, query: str, sql: str, stream_callback=None) -> str:
        """
        LLAMADA ESPEC√çFICA PARA CORRECCI√ìN: Corrige SQL de b√∫squeda de pacientes usando LLM.
        Detecta y elimina condiciones m√©dicas innecesarias de manera din√°mica.
        
        Args:
            query: Consulta original
            sql: SQL generado que puede contener condiciones innecesarias
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL corregido sin condiciones m√©dicas innecesarias
        """
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - Corrigiendo SQL con LLM...")
            
            # PROMPT SIMPLE PARA CORRECCI√ìN
            correction_prompt = f"""Corrige este SQL para b√∫squeda de pacientes.

CONSULTA: "{query}"
SQL ACTUAL: {sql}

REGLAS:
- Elimina JOINs con tablas de diagn√≥sticos
- Elimina condiciones EXISTS innecesarias
- Mant√©n solo b√∫squedas b√°sicas de pacientes
- Usa PATI_PATIENTS y PARA_GENDERS si es necesario

Responde SOLO con SQL corregido:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": correction_prompt}],
                task_description="Corrigiendo SQL de b√∫squeda de pacientes"
            )
            
            corrected_sql = self._extract_response_text(response).strip()
            corrected_sql = self._clean_llm_sql_response(corrected_sql)
            
            if corrected_sql and not corrected_sql.startswith("Error"):
                if stream_callback:
                    stream_callback("   ‚úÖ SQL corregido exitosamente")
                return corrected_sql
            else:
                # Si la correcci√≥n falla, devolver el SQL original
                return sql
                
        except Exception as e:
            logger.error(f"Error corrigiendo SQL de pacientes: {e}")
            return sql

    async def _llm_interpret_patient_results(self, query: str, data: List[Dict[str, Any]], stream_callback=None) -> str:
        """
        LLAMADA ESPEC√çFICA 4: Interpreta resultados de b√∫squeda de pacientes usando LLM.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            query: Consulta original
            data: Datos encontrados
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: Interpretaci√≥n de los resultados
        """
        try:
            if not self.llm:
                return f"Se encontraron {len(data)} resultados de pacientes."
            
            if stream_callback:
                stream_callback("   - Interpretando resultados de pacientes...")
            
            # PROMPT ESPEC√çFICO PARA INTERPRETACI√ìN DE PACIENTES - SIN HARDCODEO
            patient_interpretation_prompt = f"""Eres un experto en interpretaci√≥n de resultados de b√∫squeda de pacientes.

CONSULTA ORIGINAL: "{query}"

DATOS ENCONTRADOS ({len(data)} registros):
{json.dumps(data[:5], indent=2, ensure_ascii=False)}

TAREA ESPEC√çFICA: Proporciona una interpretaci√≥n clara y √∫til de los resultados de b√∫squeda de pacientes.

TIPOS DE INTERPRETACI√ìN:
1. Paciente encontrado con informaci√≥n completa
2. Paciente encontrado sin episodios m√©dicos
3. Paciente no encontrado
4. M√∫ltiples pacientes encontrados
5. Pacientes con diagn√≥sticos espec√≠ficos

INSTRUCCIONES:
- Analiza si el paciente fue encontrado
- Identifica si tiene episodios m√©dicos o diagn√≥sticos
- Destaca informaci√≥n relevante (fechas, diagn√≥sticos)
- Proporciona contexto m√©dico cuando sea apropiado
- Sugiere pr√≥ximos pasos si es necesario

RESPUESTA: Interpretaci√≥n clara y profesional en espa√±ol."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": patient_interpretation_prompt}],
                task_description="Interpretando resultados de pacientes"
            )
            
            interpretation = self._extract_response_text(response)
            
            if stream_callback:
                stream_callback("   ‚úÖ Interpretaci√≥n de pacientes completada")
            
            return interpretation if interpretation else f"Se encontraron {len(data)} resultados de pacientes."
            
        except Exception as e:
            logger.error(f"Error interpretando resultados de pacientes: {e}")
            return f"Se encontraron {len(data)} resultados de pacientes."

    async def _llm_generate_medical_diagnosis_sql(self, query: str, medical_info: Dict[str, Any], stream_callback=None) -> str:
        """
        LLAMADA ESPEC√çFICA 5: Genera SQL para diagn√≥sticos m√©dicos usando LLM.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            query: Consulta original del usuario
            medical_info: Informaci√≥n sobre t√©rminos m√©dicos y c√≥digos detectados
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL optimizado para b√∫squeda de diagn√≥sticos
        """
        try:
            if not self.llm:
                # Fallback sin LLM
                return self._create_generic_diagnosis_sql(medical_info)
            
            if stream_callback:
                stream_callback("   - Generando SQL inteligente para diagn√≥sticos m√©dicos...")
            
            medical_terms = medical_info.get('medical_terms', [])
            medical_codes = medical_info.get('medical_codes', [])
            primary_condition = medical_info.get('primary_condition', '')
            search_strategy = medical_info.get('search_strategy', 'free_text')
            confidence_level = medical_info.get('confidence_level', 'medium')
            
            # PROMPT ESPEC√çFICO PARA GENERACI√ìN DE SQL M√âDICO - SIN HARDCODEO
            sql_generation_prompt = f"""Eres un experto en SQL para bases de datos m√©dicas especializado en diagn√≥sticos.

CONSULTA ORIGINAL: "{query}"

INFORMACI√ìN M√âDICA DETECTADA:
- T√©rminos m√©dicos: {medical_terms}
- C√≥digos oficiales: {medical_codes if medical_codes else "No disponibles"}
- Condici√≥n principal: {primary_condition}
- Estrategia de b√∫squeda: {search_strategy}
- Nivel de confianza: {confidence_level}

ESQUEMA DE TABLAS RELEVANTES:
- EPIS_DIAGNOSTICS: Contiene diagn√≥sticos (CDTE_ID, DIAG_OBSERVATION, EPIS_PATI_ID)
- CODR_TABULAR_DIAGNOSTICS: Tabla de c√≥digos oficiales (COTA_ID, COTA_DESCRIPTION_ES)
- PATI_PATIENTS: Informaci√≥n de pacientes (PATI_ID, PATI_FULL_NAME)

ESTRATEGIAS DE B√öSQUEDA INTELIGENTE:

1. SI HAY C√ìDIGOS OFICIALES ({len(medical_codes)} encontrados):
   - Usar JOIN con CODR_TABULAR_DIAGNOSTICS
   - Filtrar por CDTE_ID IN (c√≥digos_m√©dicos)
   - Incluir descripci√≥n oficial del diagn√≥stico

2. SI NO HAY C√ìDIGOS OFICIALES:
   - Buscar en DIAG_OBSERVATION con t√©rminos m√©dicos detectados
   - Usar b√∫squeda flexible con LIKE para cada t√©rmino
   - Considerar variaciones y sin√≥nimos

3. DETECTAR TIPO DE CONSULTA:
   - Si pregunta "¬øcu√°ntos?" o "n√∫mero de" ‚Üí Usar COUNT(DISTINCT PATI_ID)
   - Si pregunta "mostrar" o "listar" ‚Üí Usar SELECT con informaci√≥n detallada
   - Si pregunta "pacientes con" ‚Üí Usar SELECT con nombres

4. OPTIMIZACIONES:
   - Ordenar por EPIS_ID DESC (m√°s recientes primero)
   - Limitar a 50 resultados si no es conteo
   - Incluir informaci√≥n del paciente cuando sea relevante
   - Usar √≠ndices eficientes

GENERA SQL OPTIMIZADO que:
- Use la estrategia m√°s apropiada seg√∫n los c√≥digos disponibles
- Sea compatible con SQLite
- Incluya informaci√≥n relevante del paciente
- Sea eficiente y preciso
- Maneje correctamente los t√©rminos m√©dicos detectados
- Use COUNT cuando se pida un conteo num√©rico

IMPORTANTE: Responde SOLO con el c√≥digo SQL, sin explicaciones, comentarios ni texto adicional.
El SQL debe ser v√°lido para SQLite y ejecutable directamente."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": sql_generation_prompt}],
                task_description="Generando SQL inteligente para diagn√≥sticos m√©dicos"
            )
            
            generated_sql = self._extract_response_text(response).strip()
            generated_sql = self._clean_llm_sql_response(generated_sql)
            
            if generated_sql and not generated_sql.startswith("Error"):
                if stream_callback:
                    stream_callback("   ‚úÖ SQL inteligente para diagn√≥sticos generado")
                return generated_sql
            else:
                # Fallback a m√©todo manual
                return self._create_generic_diagnosis_sql(medical_info)
                
        except Exception as e:
            logger.error(f"Error generando SQL para diagn√≥sticos: {e}")
            return self._create_generic_diagnosis_sql(medical_info)

    def _create_generic_diagnosis_sql(self, medical_info: Dict[str, Any]) -> str:
        """
        Crea SQL gen√©rico para buscar diagn√≥sticos m√©dicos.
        FALLBACK: Solo cuando LLM no est√° disponible.
        
        Args:
            medical_info: Informaci√≥n sobre t√©rminos m√©dicos y c√≥digos detectados
            
        Returns:
            str: SQL optimizado para b√∫squeda de diagn√≥sticos
        """
        medical_codes = medical_info.get('medical_codes', [])
        medical_terms = medical_info.get('medical_terms', [])
        
        if medical_codes:
            # Usar c√≥digos oficiales - m√°s preciso
            codes_list = ','.join(medical_codes)
            sql = f"""
            SELECT 
                e.EPIS_ID,
                e.EPIS_PATI_ID,
                e.CDTE_ID,
                e.DIAG_OBSERVATION,
                c.COTA_DESCRIPTION_ES as DIAGNOSIS_DESCRIPTION,
                p.PATI_FULL_NAME
            FROM EPIS_DIAGNOSTICS e
            INNER JOIN CODR_TABULAR_DIAGNOSTICS c ON e.CDTE_ID = c.COTA_ID
            LEFT JOIN PATI_PATIENTS p ON e.EPIS_PATI_ID = p.PATI_ID
            WHERE e.CDTE_ID IN ({codes_list})
            ORDER BY e.EPIS_ID DESC
            LIMIT 50
            """
            logger.info(f"üîç Usando {len(medical_codes)} c√≥digos oficiales")
            return sql
        elif medical_terms:
            # B√∫squeda libre con t√©rminos m√©dicos
            conditions = []
            for term in medical_terms:
                conditions.append(f"UPPER(e.DIAG_OBSERVATION) LIKE UPPER('%{term}%')")
            
            where_clause = " OR ".join(conditions)
            sql = f"""
            SELECT 
                e.EPIS_ID,
                e.EPIS_PATI_ID,
                e.CDTE_ID,
                e.DIAG_OBSERVATION,
                p.PATI_FULL_NAME
            FROM EPIS_DIAGNOSTICS e
            LEFT JOIN PATI_PATIENTS p ON e.EPIS_PATI_ID = p.PATI_ID
            WHERE {where_clause}
            ORDER BY e.EPIS_ID DESC
            LIMIT 50
            """
            logger.info(f"üîç Usando b√∫squeda libre con t√©rminos: {medical_terms}")
            return sql
        else:
            # Fallback: b√∫squeda general
            sql = """
            SELECT 
                e.EPIS_ID,
                e.EPIS_PATI_ID,
                e.CDTE_ID,
                e.DIAG_OBSERVATION,
                p.PATI_FULL_NAME
            FROM EPIS_DIAGNOSTICS e
            LEFT JOIN PATI_PATIENTS p ON e.EPIS_PATI_ID = p.PATI_ID
            ORDER BY e.EPIS_ID DESC
            LIMIT 50
            """
            logger.info("üîç Usando b√∫squeda general de diagn√≥sticos")
            return sql

    async def process_data_manipulation(self, operation: str, data: Dict[str, Any], context: Optional[Dict[str, Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """
        Procesa operaciones de manipulaci√≥n de datos (INSERT, UPDATE, DELETE)
        Compatible con FHIRAgent - M√©todo de compatibilidad
        """
        try:
            print(f"üîÑ Procesando operaci√≥n de datos: {operation}")
            print(f"   üì• Datos recibidos: {json.dumps(data, indent=2, ensure_ascii=False)}")
            print(f"   üìã Contexto: {context}")
            
            # Extraer informaci√≥n del contexto
            intent = context.get('intent', 'general') if context else 'general'
            conn = context.get('conn') if context else None
            
            # Generar SQL para la operaci√≥n usando LLM
            if operation.upper() == 'INSERT':
                sql_result = await self._generate_insert_sql_intelligent(data, context, stream_callback)
                sql = sql_result['sql']
                values = sql_result.get('values', [])
                table_used = sql_result.get('table', 'desconocida')
            elif operation.upper() == 'UPDATE':
                sql_result = await self._generate_update_sql_intelligent(data, context, stream_callback)
                sql = sql_result['sql']
                values = sql_result.get('values', [])
                table_used = sql_result.get('table', 'desconocida')
            elif operation.upper() == 'DELETE':
                sql_result = await self._generate_delete_sql_intelligent(data, context, stream_callback)
                sql = sql_result['sql']
                values = sql_result.get('values', [])
                table_used = sql_result.get('table', 'desconocida')
            else:
                return {
                    'success': False,
                    'error': f'Operaci√≥n no soportada: {operation}',
                    'data': []
                }
            
            print(f"   üíæ SQL generado: {sql[:100]}...")
            if values:
                print(f"   üìä Valores: {values}")
            
            # Mostrar informaci√≥n detallada de la operaci√≥n
            print(f"   üìã OPERACI√ìN: {operation.upper()}")
            print(f"   üóÉÔ∏è TABLA: {table_used}")
            
            # Extraer informaci√≥n de columnas del SQL
            if operation.upper() == 'INSERT':
                # Buscar columnas en INSERT
                import re
                column_match = re.search(r'INSERT INTO \w+ \((.*?)\) VALUES', sql, re.IGNORECASE)
                if column_match:
                    columns = [col.strip() for col in column_match.group(1).split(',')]
                    print(f"   üìä COLUMNAS A INSERTAR: {', '.join(columns)}")
                    
                    # Mostrar valores correspondientes
                    if values:
                        for i, (col, val) in enumerate(zip(columns, values)):
                            print(f"      - {col}: {val}")
                    else:
                        # Extraer valores del SQL si no est√°n en la lista de valores
                        values_match = re.search(r'VALUES \((.*?)\)', sql, re.IGNORECASE)
                        if values_match:
                            sql_values = [v.strip().strip("'") for v in values_match.group(1).split(',')]
                            for i, (col, val) in enumerate(zip(columns, sql_values)):
                                # Manejar valores NULL correctamente
                                if val.upper() == 'NULL' or val == 'None':
                                    print(f"      - {col}: NULL")
                                else:
                                    print(f"      - {col}: {val}")
            
            elif operation.upper() == 'UPDATE':
                # Buscar columnas en UPDATE
                import re
                set_match = re.search(r'SET (.*?) WHERE', sql, re.IGNORECASE)
                if set_match:
                    set_clause = set_match.group(1)
                    # Extraer pares columna=valor
                    updates = [pair.strip() for pair in set_clause.split(',')]
                    print(f"   üìä COLUMNAS A ACTUALIZAR:")
                    for update in updates:
                        if '=' in update:
                            col, val = update.split('=', 1)
                            print(f"      - {col.strip()}: {val.strip()}")
            
            elif operation.upper() == 'DELETE':
                # Buscar condici√≥n WHERE en DELETE
                import re
                where_match = re.search(r'WHERE (.*?)(?:;|$)', sql, re.IGNORECASE)
                if where_match:
                    where_clause = where_match.group(1)
                    print(f"   üîç CONDICI√ìN WHERE: {where_clause}")
            
            # Ejecutar SQL usando la conexi√≥n proporcionada o crear una nueva
            inserted_id = None
            if conn:
                # Usar conexi√≥n existente (para transacciones)
                try:
                    cursor = conn.cursor()
                    if values and '?' in sql:
                        cursor.execute(sql, values)
                    else:
                        cursor.execute(sql)
                    
                    # Obtener el ID del registro insertado si es posible
                    if operation.upper() == 'INSERT':
                        try:
                            # Usar lastrowid (m√°s confiable y directo)
                            inserted_id = cursor.lastrowid
                            if inserted_id:
                                print(f"   ‚úÖ ID del registro insertado (lastrowid): {inserted_id}")
                            else:
                                print(f"   ‚ö†Ô∏è lastrowid no disponible, usando m√©todo adaptativo...")
                                # Fallback al m√©todo adaptativo si lastrowid no funciona
                                inserted_id = await self._get_real_inserted_id_adaptive(table_used, data, stream_callback)
                                if inserted_id:
                                    print(f"   ‚úÖ ID del registro insertado (adaptativo): {inserted_id}")
                                else:
                                    print(f"   ‚ö†Ô∏è No se pudo obtener el ID del registro insertado")
                        except Exception as e:
                            print(f"   ‚ö†Ô∏è Error obteniendo ID: {e}")
                            inserted_id = None
                    
                    # No hacer commit aqu√≠, dejar que el llamador maneje la transacci√≥n
                    result = {
                        'success': True,
                        'data': [],
                        'sql_used': sql,
                        'table_used': table_used,
                        'inserted_id': inserted_id
                    }
                except Exception as e:
                    result = {
                        'success': False,
                        'error': str(e),
                        'sql_used': sql,
                        'table_used': table_used,
                        'inserted_id': None
                    }
            else:
                # Usar SQL executor normal
                if values and '?' in sql:
                    result = self.sql_executor.execute_query(sql, values)
                else:
                    # SQL ya tiene valores espec√≠ficos
                    result = self.sql_executor.execute_query(sql)
                
                # Para INSERT, intentar obtener el ID del √∫ltimo registro insertado
                if operation.upper() == 'INSERT' and result.get('success'):
                    try:
                        # Intentar obtener lastrowid del resultado
                        inserted_id = result.get('lastrowid')
                        if inserted_id:
                                    print(f"   ‚úÖ ID del registro insertado (lastrowid): {inserted_id}")
                        else:
                            print(f"   ‚ö†Ô∏è lastrowid no disponible, usando m√©todo adaptativo...")
                            # Fallback al m√©todo adaptativo
                            inserted_id = await self._get_real_inserted_id_adaptive(table_used, data, stream_callback)
                            if inserted_id:
                                print(f"   ‚úÖ ID del registro insertado (adaptativo): {inserted_id}")
                            else:
                                print(f"   ‚ö†Ô∏è No se pudo obtener el ID del registro insertado")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Error obteniendo ID: {e}")
                        inserted_id = None
                
                result['inserted_id'] = inserted_id

            # Formatear los datos para mejor visualizaci√≥n
            formatted_data = await self._format_sql_results_for_display(result.get('data', []), f"Operaci√≥n {operation}")
            
            return {
                'success': result['success'],
                'data': result.get('data', []),
                'formatted_data': formatted_data,
                'error': result.get('error', ''),
                'operation': operation,
                'sql_used': sql,
                'table_used': result.get('table_used', table_used),
                'inserted_id': result.get('inserted_id'),
                'message': f"Operaci√≥n {operation} completada" if result['success'] else result.get('error', 'Error desconocido')
            }
            
        except Exception as e:
            # Formatear datos vac√≠os para error
            formatted_data = await self._format_sql_results_for_display([], f"Operaci√≥n {operation}")
            
            return {
                'success': False,
                'error': f'Error en manipulaci√≥n de datos: {str(e)}',
                'data': [],
                'formatted_data': formatted_data,
                'operation': operation,
                'table_used': 'desconocida',
                'inserted_id': None,
                'message': f'Error en manipulaci√≥n de datos: {str(e)}'
            }

    async def _generate_insert_sql_intelligent(self, data: Dict[str, Any], context: Optional[Dict[str, Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """Genera SQL INSERT inteligente usando LLM para mapeo din√°mico FHIR‚ÜíSQL"""
        try:
            # DEBUG: Mostrar datos de entrada
            print(f"üîç DEBUG _generate_insert_sql_intelligent:")
            print(f"   üì• Datos de entrada: {json.dumps(data, indent=2, ensure_ascii=False)}")
            print(f"   üìã Contexto: {context}")
            
            # DETECTAR SI SON DATOS FHIR O YA MAPEADOS
            is_fhir_data = 'resourceType' in data
            
            if is_fhir_data:
                # USAR MAPEO FHIR‚ÜíSQL INTELIGENTE CON LLM
                print(f"   üîÑ Detectados datos FHIR, usando mapeo LLM flexible...")
                
                # Importar el mapper FHIR‚ÜíSQL
                from agents.fhir_sql_llm_mapper import FHIRSQLLLMMapper
                
                # Crear instancia del mapper
                mapper = FHIRSQLLLMMapper(
                    llm=self.llm,
                    schema_getter=self._get_table_columns
                )
                
                # Obtener esquema completo de la base de datos
                db_schema = {}
                try:
                    # Obtener todas las tablas de la base de datos
                    import sqlite3
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                    all_tables = [row[0] for row in cursor.fetchall()]
                    conn.close()
                    
                    # print(f"   üìã Tablas encontradas en la BD: {all_tables}")  # ELIMINADO para no mostrar todas las tablas
                    
                    # Obtener columnas de cada tabla (solo debug de tabla seleccionada)
                    for table in all_tables:
                        try:
                            columns = await self._get_table_columns(table)
                            db_schema[table] = columns
                            # print(f"      - {table}: {len(columns)} columnas")  # ELIMINADO para no mostrar todas las columnas
                        except Exception as e:
                            print(f"      ‚ö†Ô∏è Error obteniendo columnas de {table}: {e}")
                            db_schema[table] = []
                            
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Error obteniendo esquema completo: {e}")
                    # Fallback con tablas b√°sicas
                    fallback_tables = ['PATI_PATIENTS', 'EPIS_DIAGNOSTICS', 'PATI_USUAL_MEDICATION']
                    for table in fallback_tables:
                        try:
                            columns = await self._get_table_columns(table)
                            db_schema[table] = columns
                        except:
                            db_schema[table] = []
                
                # Realizar mapeo inteligente
                mapping_result = await mapper.map_fhir_to_sql(data, db_schema, context)
                
                # El mapper siempre devuelve un resultado v√°lido
                target_table = mapping_result['table']
                mapped_data = mapping_result['mapped_data']
                resource_type = data.get('resourceType', 'Unknown')
                
                print(f"   ‚úÖ Mapeo LLM exitoso:")
                print(f"      üìã Tabla: {target_table}")
                print(f"      üîÑ Tipo de recurso: {resource_type}")
                print(f"      üìä Campos mapeados: {len(mapped_data)}")
                print(f"      üìù Resumen: {mapping_result['mapping_summary']}")
                print(f"      üêû DEBUG VALORES A INSERTAR: {mapped_data}")
                for k, v in mapped_data.items():
                    if v is None or v == '' or v == 'none' or v == 'None':
                        print(f"      ‚ö†Ô∏è CAMPO VAC√çO O NONE: {k} = {v}")
                
                # Si no hay datos mapeados, usar fallback
                if not mapped_data:
                    print(f"   ‚ö†Ô∏è No se mapearon campos, usando fallback b√°sico...")
                    target_table = context.get('table_hint', 'PATI_PATIENTS') if context else 'PATI_PATIENTS'
                    mapped_data = {
                        'PATI_ID': context.get('patient_id') if context else None,
                        'DIAG_OBSERVATION': json.dumps(data, ensure_ascii=False)
                    }
                    # Filtrar valores None
                    mapped_data = {k: v for k, v in mapped_data.items() if v is not None}
                    
                    resource_type = data.get('resourceType', 'Unknown')
                    target_table = context.get('table_hint', 'PATI_PATIENTS') if context else 'PATI_PATIENTS'
                    mapped_data = {
                        'PATI_ID': context.get('patient_id') if context else None,
                        'DIAG_OBSERVATION': json.dumps(data, ensure_ascii=False)
                    }
                    # Filtrar valores None
                    mapped_data = {k: v for k, v in mapped_data.items() if v is not None}
                
            else:
                # Datos ya mapeados, usar tabla del contexto
                target_table = context.get('table_hint', 'PATI_PATIENTS') if context else 'PATI_PATIENTS'
                mapped_data = data
                resource_type = 'Unknown'
            
            # Generar SQL INSERT
            columns = list(mapped_data.keys())
            values = list(mapped_data.values())
            placeholders = ', '.join(['?' for _ in values])
            column_names = ', '.join(columns)
            
            sql = f"INSERT INTO {target_table} ({column_names}) VALUES ({placeholders})"
            
            print(f"   üóÉÔ∏è Tabla seleccionada: {target_table}")
            print(f"   üìä Columnas: {columns}")
            print(f"   üíæ Valores: {values}")
            for i, v in enumerate(values):
                if v is None or v == '' or v == 'none' or v == 'None':
                    print(f"      ‚ö†Ô∏è VALOR VAC√çO O NONE EN COLUMNA: {columns[i]} = {v}")
            print(f"   üìù SQL generado: {sql}")
            
            return {
                'sql': sql,
                'values': values,
                'table': target_table,
                'resource_type': resource_type,
                'mapped_data': mapped_data
            }
                    
        except Exception as e:
            logger.error(f"Error generando SQL INSERT: {e}")
            # Fallback simple
            table_name = context.get('table_hint', 'PATI_PATIENTS') if context else 'PATI_PATIENTS'
            columns = list(data.keys())
            values = list(data.values())
            placeholders = ', '.join(['?' for _ in values])
            column_names = ', '.join(columns)
            
            sql = f"INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})"
        
            return {
                'sql': sql,
                'values': values,
                'table': table_name,
                'resource_type': 'Unknown',
                'mapped_data': data
            }

    async def _generate_update_sql_intelligent(self, data: Dict[str, Any], context: Optional[Dict[str, Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """Genera SQL UPDATE inteligente usando LLM"""
        try:
            if not self.llm:
                default_table = 'PATI_PATIENTS'
                fallback_sql = await self._llm_generate_fallback_sql_adaptive('UPDATE', data, default_table, None)
                return {
                    'sql': fallback_sql,
                    'values': [],
                    'table': default_table
                }

            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en SQL UPDATE m√©dico. Genera SQL UPDATE basado en estos datos:

DATOS A ACTUALIZAR:
{json.dumps(data, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Identifica la tabla apropiada para la actualizaci√≥n
2. Usa el campo 'id' como condici√≥n WHERE
3. Mapea los campos FHIR a columnas SQL
4. Genera SQL UPDATE completo con valores espec√≠ficos

RESPUESTA JSON:
{{
    "sql": "UPDATE tabla SET columna1 = 'valor1' WHERE id = 'valor_id';",
    "table": "nombre_tabla",
    "values": []
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL UPDATE inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('sql'):
                return {
                    'sql': result['sql'],
                    'values': result.get('values', []),
                    'table': result.get('table', 'desconocida')
                }
            else:
                default_table = await self._llm_select_default_table_adaptive('Unknown', data, None)
                fallback_sql = await self._llm_generate_fallback_sql_adaptive('UPDATE', data, default_table, None)
                return {
                    'sql': fallback_sql,
                    'values': [],
                    'table': default_table
                }
                
        except Exception as e:
            logger.error(f"Error generando SQL UPDATE: {e}")
            default_table = await self._llm_select_default_table_adaptive('Unknown', data, None)
            fallback_sql = await self._llm_generate_fallback_sql_adaptive('UPDATE', data, default_table, None)
            return {
                'sql': fallback_sql,
                'values': [],
                'table': default_table
            }

    async def _generate_delete_sql_intelligent(self, data: Dict[str, Any], context: Optional[Dict[str, Any]] = None, stream_callback=None) -> Dict[str, Any]:
        """Genera SQL DELETE inteligente usando LLM"""
        try:
            if not self.llm:
                default_table = 'PATI_PATIENTS'
                fallback_sql = await self._llm_generate_fallback_sql_adaptive('DELETE', data, default_table, None)
                return {
                    'sql': fallback_sql,
                    'values': [],
                    'table': default_table
                }

            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en SQL DELETE m√©dico. Genera SQL DELETE basado en estos datos:

DATOS PARA ELIMINAR:
{json.dumps(data, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Identifica la tabla apropiada para la eliminaci√≥n
2. Usa el campo 'id' como condici√≥n WHERE
3. Genera SQL DELETE completo

RESPUESTA JSON:
{{
    "sql": "DELETE FROM tabla WHERE id = 'valor_id';",
    "table": "nombre_tabla",
    "values": []
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL DELETE inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('sql'):
                return {
                    'sql': result['sql'],
                    'values': result.get('values', []),
                    'table': result.get('table', 'desconocida')
                }
            else:
                default_table = await self._llm_select_default_table_adaptive('Unknown', data, None)
                fallback_sql = await self._llm_generate_fallback_sql_adaptive('DELETE', data, default_table, None)
                return {
                    'sql': fallback_sql,
                    'values': [],
                    'table': default_table
                }
                
        except Exception as e:
            logger.error(f"Error generando SQL DELETE: {e}")
            default_table = await self._llm_select_default_table_adaptive('Unknown', data, None)
            fallback_sql = await self._llm_generate_fallback_sql_adaptive('DELETE', data, default_table, None)
            return {
                'sql': fallback_sql,
                'values': [],
                'table': default_table
            }

    async def _format_sql_results_for_display(self, data: List[Dict[str, Any]], query: str) -> str:
        """Formatea resultados SQL para mostrar al usuario"""
        try:
            if not data:
                return "No se encontraron resultados."
            
            # Formato b√°sico
            result_lines = []
            for i, row in enumerate(data[:10], 1):  # Mostrar m√°ximo 10 filas
                row_str = " | ".join([f"{k}: {v}" for k, v in row.items()])
                result_lines.append(f"{i}. {row_str}")
            
            if len(data) > 10:
                result_lines.append(f"... y {len(data) - 10} registros m√°s")
            
            return "\n".join(result_lines)
            
        except Exception as e:
            logger.error(f"Error formateando resultados: {e}")
            return f"Se encontraron {len(data)} resultados."

    async def _llm_validate_mapping_intelligent(self, fhir_data: Dict[str, Any], tabla_actual: str, tipo_actual: str, valores_actuales: Dict[str, Any], stream_callback=None) -> Optional[Dict[str, Any]]:
        """
        LLAMADA ESPEC√çFICA: Valida y corrige el mapeo FHIR‚ÜíSQL usando LLM inteligente.
        SIN PATTERNS HARDCODEADOS - todo via LLM.
        
        Args:
            fhir_data: Datos FHIR originales
            tabla_actual: Tabla mapeada actualmente
            tipo_actual: Tipo de recurso actual
            valores_actuales: Valores mapeados actualmente
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Optional[Dict[str, Any]]: Correcciones aplicadas o None si no hay cambios
        """
        try:
            if not self.llm:
                return None
            
            if stream_callback:
                stream_callback("   - Validando mapeo con IA inteligente...")
            
            # PROMPT ESPEC√çFICO PARA VALIDACI√ìN DE MAPEO - SIN HARDCODEO
            validation_prompt = f"""Eres un experto en validaci√≥n de mapeo FHIR‚ÜíSQL para bases de datos m√©dicas.

DATOS FHIR ORIGINALES:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

MAPEO ACTUAL:
- Tabla: {tabla_actual}
- Tipo: {tipo_actual}
- Valores: {json.dumps(valores_actuales, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

TAREA ESPEC√çFICA: Analiza el mapeo actual y detecta errores o inconsistencias.

PROBLEMAS COMUNES A DETECTAR:
1. Observaciones mapeadas como pacientes
2. Pacientes mapeados como observaciones
3. Tipos de recurso incorrectos
4. Campos mapeados en tablas incorrectas
5. Valores en columnas inapropiadas

ESTRATEGIA DE VALIDACI√ìN:
1. Analiza el contenido sem√°ntico de los datos FHIR
2. Identifica el tipo de recurso real basado en campos espec√≠ficos
3. Verifica que la tabla sea apropiada para el tipo de recurso
4. Corrige mapeos incorrectos autom√°ticamente
5. Sugiere mejoras en el mapeo

REGLAS DE CORRECCI√ìN:
- Si contiene "valueQuantity", "component" ‚Üí ES OBSERVACI√ìN
- Si contiene "name", "birthDate", "gender" ‚Üí ES PACIENTE
- Si contiene "code", "clinicalStatus" ‚Üí ES DIAGN√ìSTICO
- Si contiene "medicationCodeableConcept" ‚Üí ES MEDICAMENTO
- Si contiene "status", "period" ‚Üí ES EPISODIO

INSTRUCCIONES:
1. Analiza los datos FHIR para determinar el tipo real
2. Verifica si el mapeo actual es correcto
3. Si hay errores, proporciona correcciones
4. Si est√° correcto, confirma el mapeo
5. Considera el contexto m√©dico completo

RESPUESTA JSON:
{{
    "needs_correction": true|false,
    "corrected_table": "tabla_corregida",
    "corrected_type": "tipo_corregido",
    "corrected_values": {{
        "columna1": "valor1",
        "columna2": "valor2"
    }},
    "reasoning": "explicaci√≥n de la correcci√≥n",
    "confidence": "high|medium|low"
}}

IMPORTANTE: 
- Solo corrige si hay errores claros
- Mant√©n la l√≥gica original si el mapeo es correcto
- Usa tablas y columnas que realmente existen
- Considera el contexto m√©dico completo

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
                task_description="Validando mapeo con IA inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('needs_correction', False):
                corrected_table = result.get('corrected_table', tabla_actual)
                corrected_type = result.get('corrected_type', tipo_actual)
                corrected_values = result.get('corrected_values', valores_actuales)
                reasoning = result.get('reasoning', 'Sin explicaci√≥n')
                confidence = result.get('confidence', 'medium')
                
                if stream_callback:
                    stream_callback(f"   - Correcci√≥n aplicada: {tabla_actual} ‚Üí {corrected_table}")
                    stream_callback(f"   - Tipo corregido: {tipo_actual} ‚Üí {corrected_type}")
                    stream_callback(f"   - Confianza: {confidence}")
                
                logger.info(f"üß† LLM corrigi√≥ mapeo: {reasoning}")
                
                return {
                    'corrected_table': corrected_table,
                    'corrected_type': corrected_type,
                    'corrected_values': corrected_values,
                    'reasoning': reasoning,
                    'confidence': confidence
                }
            else:
                if stream_callback:
                    stream_callback("   ‚úÖ Mapeo validado correctamente")
                return None
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n de mapeo: {e}")
            return None

    async def _llm_detect_resource_type_intelligent(self, fhir_data: Dict[str, Any], stream_callback=None) -> str:
        """
        LLAMADA ESPEC√çFICA: Detecta el tipo de recurso FHIR usando LLM inteligente.
        SIN PATRONES HARDCODEADOS - todo via LLM.
        
        Args:
            fhir_data: Datos FHIR a analizar
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: Tipo de recurso detectado
        """
        try:
            if not self.llm:
                return 'Patient'  # Fallback b√°sico
            
            if stream_callback:
                stream_callback("   - Detectando tipo de recurso con IA...")
            
            # PROMPT ESPEC√çFICO PARA DETECCI√ìN DE TIPO - SIN HARDCODEO
            detection_prompt = f"""Eres un experto en identificaci√≥n de tipos de recursos FHIR.

DATOS FHIR A ANALIZAR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

TAREA ESPEC√çFICA: Identifica el tipo de recurso FHIR basado en el contenido sem√°ntico.

TIPOS DE RECURSOS POSIBLES:
- Patient: Datos de pacientes (nombre, fecha nacimiento, g√©nero)
- Condition: Diagn√≥sticos y condiciones m√©dicas
- Medication: Medicamentos y tratamientos
- Observation: Observaciones m√©dicas (signos vitales, resultados)
- Encounter: Episodios de atenci√≥n m√©dica
- EpisodeOfCare: Episodios de cuidado

CRITERIOS DE IDENTIFICACI√ìN:
1. Buscar "resourceType" expl√≠cito primero
2. Analizar campos espec√≠ficos de cada tipo
3. Considerar el contexto m√©dico completo
4. Identificar patrones en los datos

INSTRUCCIONES:
- Analiza todos los campos disponibles
- Considera el contexto m√©dico
- Identifica el tipo m√°s apropiado
- Proporciona confianza en la identificaci√≥n

RESPUESTA JSON:
{{
    "resource_type": "Patient|Condition|Medication|Observation|Encounter|EpisodeOfCare",
    "confidence": "high|medium|low",
    "key_fields": ["campo1", "campo2"],
    "reasoning": "explicaci√≥n de la identificaci√≥n"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": detection_prompt}],
                task_description="Detectando tipo de recurso con IA"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                resource_type = result.get('resource_type', 'Patient')
                confidence = result.get('confidence', 'medium')
                reasoning = result.get('reasoning', 'Sin explicaci√≥n')
                
                if stream_callback:
                    stream_callback(f"   - Tipo detectado: {resource_type} (confianza: {confidence})")
                
                return resource_type
            else:
                return 'Patient'  # Fallback
                
        except Exception as e:
            logger.error(f"Error detectando tipo de recurso: {e}")
            return 'Patient'  # Fallback

    async def _llm_select_table_intelligent(self, resource_type: str, fhir_data: Dict[str, Any], stream_callback=None) -> str:
        """
        Selecciona la tabla SQL apropiada usando SOLO LLM, sin ning√∫n mapeo r√≠gido ni fallback, salvo el √∫ltimo recurso por excepci√≥n.
        """
        try:
            if stream_callback:
                stream_callback("   - Seleccionando tabla SQL con IA...")
            
            selection_prompt = f"""Eres un experto en mapeo de recursos FHIR a tablas SQL m√©dicas.

TIPO DE RECURSO: {resource_type}

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

TAREA: Selecciona la tabla SQL m√°s apropiada para este tipo de recurso.

INSTRUCCIONES:
- Analiza el esquema completo din√°micamente
- Busca patrones en nombres de tablas
- Considera el contexto m√©dico espec√≠fico
- Selecciona la tabla m√°s apropiada
- NO uses mapeos r√≠gidos, analiza din√°micamente

RESPUESTA: Solo el nombre exacto de la tabla m√°s apropiada, sin explicaciones, sin JSON, sin texto adicional."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": selection_prompt}],
                task_description="Seleccionando tabla SQL con IA"
            )
            selected_table = self._extract_response_text(response).strip().strip('"').strip("'")
            if stream_callback:
                stream_callback(f"   - Tabla seleccionada: {selected_table}")
            return selected_table
        except Exception as e:
            logger.error(f"Error seleccionando tabla: {e}")
            return 'PATI_PATIENTS'  # √öltimo recurso


    async def _llm_map_fields_intelligent(self, fhir_data: Dict[str, Any], resource_type: str, target_table: str, stream_callback=None) -> Dict[str, Any]:
        """
        LLAMADA ESPEC√çFICA: Mapea campos FHIR a columnas SQL usando LLM inteligente.
        SIN PATRONES HARDCODEADOS - todo via LLM.
        
        Args:
            fhir_data: Datos FHIR
            resource_type: Tipo de recurso
            target_table: Tabla SQL objetivo
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Dict[str, Any]: Mapeo de campos y valores
        """
        try:
            if not self.llm:
                # Fallback b√°sico adaptativo
                name_fields = await self._llm_detect_common_fields_adaptive(target_table, 'name', None)
                return {
                    'columns': name_fields,
                    'values': [fhir_data.get('name', '')] * len(name_fields)
                }
            
            if stream_callback:
                stream_callback("   - Mapeando campos con IA inteligente...")
            
            # PROMPT ESPEC√çFICO PARA MAPEO DE CAMPOS - SIN HARDCODEO
            mapping_prompt = f"""Eres un experto en mapeo de campos FHIR a columnas SQL m√©dicas.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

TIPO DE RECURSO: {resource_type}
TABLA OBJETIVO: {target_table}

ESQUEMA DE LA TABLA:
{self._get_table_schema_info(target_table)}

TAREA ESPEC√çFICA: Mapea los campos FHIR a columnas SQL espec√≠ficas.

ESTRATEGIA DE MAPEO:
1. Analiza cada campo FHIR
2. Identifica la columna SQL correspondiente
3. Convierte tipos de datos apropiadamente
4. Maneja valores nulos y opcionales
5. Considera campos de auditor√≠a

REGLAS CR√çTICAS:
- NO incluyas campos de ID en INSERT (d√©jalos autoincrementarse)
- Maneja fechas en formato SQLite (YYYY-MM-DD)
- Escapa valores de texto apropiadamente
- Considera valores por defecto cuando sea necesario
- NO uses UUIDs ficticios como "patient-id-unico" o "urn:uuid:..."
- Para valores nulos, usa NULL, NO "None"
- Para IDs, usa valores num√©ricos reales o NULL
- NO generes IDs ficticios, deja que la base de datos los genere
- Para fechas vac√≠as, usa NULL, NO "None"
- Para campos opcionales sin valor, usa NULL

INSTRUCCIONES:
- Mapea solo campos que existen en la tabla
- Convierte tipos de datos correctamente
- Maneja valores nulos apropiadamente
- Considera el contexto m√©dico

RESPUESTA JSON:
{{
    "columns": ["columna1", "columna2"],
    "values": ["valor1", "valor2"],
    "field_mapping": {{
        "campo_fhir1": "columna_sql1",
        "campo_fhir2": "columna_sql2"
    }},
    "data_types": {{
        "columna1": "TEXT|INTEGER|REAL|DATE",
        "columna2": "TEXT|INTEGER|REAL|DATE"
    }}
}}

IMPORTANTE:
- NO uses "None" como valor, usa NULL para valores nulos
- NO uses UUIDs ficticios como "patient-id-unico" o "urn:uuid:..."
- NO uses IDs ficticios, deja que se autoincrementen
- Usa valores reales o NULL cuando corresponda
- Para fechas vac√≠as, usa NULL en lugar de "None"
- Para IDs, NO incluyas campos de ID en INSERT

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": mapping_prompt}],
                task_description="Mapeando campos con IA inteligente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result:
                columns = result.get('columns', [])
                values = result.get('values', [])
                field_mapping = result.get('field_mapping', {})
                
                if stream_callback:
                    stream_callback(f"   - Campos mapeados: {len(columns)} columnas")
                
                return {
                    'columns': columns,
                    'values': values,
                    'field_mapping': field_mapping
                }
            else:
                # Fallback b√°sico adaptativo
                name_fields = await self._llm_detect_common_fields_adaptive(target_table, 'name', None)
                return {
                    'columns': name_fields,
                    'values': [fhir_data.get('name', '')] * len(name_fields)
                }
                
        except Exception as e:
            logger.error(f"Error mapeando campos: {e}")
            name_fields = await self._llm_detect_common_fields_adaptive(target_table, 'name', None)
            return {
                'columns': name_fields,
                'values': [fhir_data.get('name', '')] * len(name_fields)
            }

    def _get_table_schema_info(self, table_name: str) -> str:
        """
        Obtiene informaci√≥n del esquema de una tabla espec√≠fica.
        
        Args:
            table_name: Nombre de la tabla
            
        Returns:
            str: Informaci√≥n del esquema de la tabla
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Obtener informaci√≥n de columnas
            cursor.execute(f"PRAGMA table_info('{table_name}');")
            columns_info = cursor.fetchall()
            
            schema_info = [f"TABLA: {table_name}"]
            schema_info.append("COLUMNAS DISPONIBLES:")
            
            for col_info in columns_info:
                col_name = col_info[1]
                col_type = col_info[2]
                not_null = col_info[3]
                default_value = col_info[4]
                pk = col_info[5]
                
                col_desc = f"  - {col_name}: {col_type}"
                if pk:
                    col_desc += " (PRIMARY KEY)"
                if not_null:
                    col_desc += " (NOT NULL)"
                if default_value:
                    col_desc += f" (DEFAULT: {default_value})"
                
                schema_info.append(col_desc)
            
            # Agregar informaci√≥n espec√≠fica para tablas conocidas
            if table_name.upper() == 'PATI_PATIENTS':
                schema_info.append("")
                schema_info.append("INFORMACI√ìN ESPEC√çFICA PARA PATI_PATIENTS:")
                schema_info.append("  - PATI_ID: ID √∫nico del paciente (PRIMARY KEY)")
                schema_info.append("  - PATI_NAME: Nombre del paciente")
                schema_info.append("  - PATI_SURNAME_1: Primer apellido")
                schema_info.append("  - PATI_SURNAME_2: Segundo apellido (opcional)")
                schema_info.append("  - PATI_FULL_NAME: Nombre completo")
                schema_info.append("  - PATI_BIRTH_DATE: Fecha de nacimiento (YYYY-MM-DD)")
                schema_info.append("  - PATI_ACTIVE: Estado activo (1=activo, 0=inactivo)")
                schema_info.append("  - GEND_ID: ID de g√©nero (1=masculino, 2=femenino, 3=otro)")
                schema_info.append("  - PATI_START_DATE: Fecha de inicio de atenci√≥n")
                schema_info.append("  - MTIME: Timestamp de modificaci√≥n")
                schema_info.append("")
                schema_info.append("COLUMNAS QUE NO EXISTEN (NO USAR):")
                schema_info.append("  - PATI_IDENTIFIER (no existe)")
                schema_info.append("  - PATI_PHONE (no existe)")
                schema_info.append("  - PATI_ADDRESS (no existe)")
            
            conn.close()
            return "\n".join(schema_info)
            
        except Exception as e:
            logger.error(f"Error obteniendo esquema de tabla {table_name}: {e}")
            return f"Error obteniendo esquema de tabla {table_name}"

    async def _llm_detect_id_fields_adaptive(self, table_name: str, stream_callback=None) -> List[str]:
        """Usa LLM para detectar din√°micamente los campos de ID de una tabla"""
        try:
            if not self.llm:
                return ['PATI_ID', 'EPIS_ID', 'DIAG_ID', 'MEDI_ID', 'OBSE_ID']  # Fallback b√°sico
            
            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en an√°lisis de esquemas de base de datos m√©dicos. 

AN√ÅLISIS DE CAMPOS DE ID:
Tabla: {table_name}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Analiza la tabla {table_name}
2. Identifica TODOS los campos que son claves primarias o IDs
3. Incluye campos que terminen en _ID, ID, o que sean claves primarias
4. Considera tambi√©n campos de autoincremento

RESPUESTA JSON:
{{
    "id_fields": ["campo1", "campo2", "campo3"]
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Detectando campos de ID adaptativamente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('id_fields'):
                return result['id_fields']
            else:
                return ['PATI_ID', 'EPIS_ID', 'DIAG_ID', 'MEDI_ID', 'OBSE_ID']  # Fallback
                
        except Exception as e:
            logger.error(f"Error detectando campos de ID: {e}")
            return ['PATI_ID', 'EPIS_ID', 'DIAG_ID', 'MEDI_ID', 'OBSE_ID']  # Fallback

    async def _llm_select_default_table_adaptive(self, resource_type: str, fhir_data: Dict[str, Any], stream_callback=None) -> str:
        """Usa LLM para seleccionar din√°micamente la tabla por defecto"""
        try:
            if not self.llm:
                return 'PATI_PATIENTS'  # Fallback b√°sico
            
            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en mapeo FHIR a SQL m√©dico.

SELECCI√ìN DE TABLA POR DEFECTO:
Tipo de recurso: {resource_type}
Datos FHIR: {json.dumps(fhir_data, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Analiza el tipo de recurso FHIR
2. Identifica la tabla m√°s apropiada para este tipo de datos
3. Considera el contenido de los datos FHIR
4. Selecciona la tabla que mejor se adapte

RESPUESTA JSON:
{{
    "default_table": "nombre_tabla",
    "reasoning": "explicaci√≥n de la selecci√≥n"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Seleccionando tabla por defecto adaptativamente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('default_table'):
                return result['default_table']
            else:
                return 'PATI_PATIENTS'  # Fallback
                
        except Exception as e:
            logger.error(f"Error seleccionando tabla por defecto: {e}")
            return 'PATI_PATIENTS'  # Fallback

    async def _llm_generate_fallback_sql_adaptive(self, operation: str, data: Dict[str, Any], table: str, stream_callback=None) -> str:
        """Usa LLM para generar SQL de fallback adaptativo"""
        try:
            if not self.llm:
                # Fallback b√°sico hardcodeado
                if operation == 'INSERT':
                    return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
                elif operation == 'UPDATE':
                    return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
                elif operation == 'DELETE':
                    return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
                else:
                    return f"SELECT * FROM {table};"
            
            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en SQL m√©dico. Genera SQL de fallback.

OPERACI√ìN: {operation}
TABLA: {table}
DATOS: {json.dumps(data, indent=2, ensure_ascii=False)}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Genera SQL {operation} b√°sico pero funcional
2. Usa solo campos que existan en la tabla
3. Maneja valores nulos correctamente
4. Evita campos de ID en INSERT
5. Usa condiciones WHERE apropiadas

RESPUESTA JSON:
{{
    "sql": "SQL generado aqu√≠",
    "table": "{table}",
    "operation": "{operation}"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL de fallback adaptativo"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('sql'):
                return result['sql']
            else:
                # Fallback b√°sico
                if operation == 'INSERT':
                    return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
                elif operation == 'UPDATE':
                    return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
                elif operation == 'DELETE':
                    return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
                else:
                    return f"SELECT * FROM {table};"
                
        except Exception as e:
            logger.error(f"Error generando SQL de fallback: {e}")
            # Fallback b√°sico
            if operation == 'INSERT':
                return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
            elif operation == 'UPDATE':
                return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
            elif operation == 'DELETE':
                return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
            else:
                return f"SELECT * FROM {table};"

    async def _llm_validate_table_exists_adaptive(self, table_name: str, stream_callback=None) -> bool:
        """Usa LLM para validar si una tabla existe en el esquema"""
        try:
            if not self.llm:
                # Fallback mejorado - verificar en column_metadata
                return table_name in self.column_metadata
            
            if stream_callback:
                stream_callback("   üí° Validando tabla con IA adaptativa...")
            
            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en validaci√≥n de esquemas de base de datos m√©dicos.

VALIDACI√ìN DE TABLA:
Tabla a verificar: {table_name}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Verifica si la tabla {table_name} existe en el esquema
2. Busca coincidencias exactas o similares
3. Considera variaciones de nombres
4. Si la tabla no existe, sugiere la tabla m√°s apropiada

REGLAS ESPEC√çFICAS:
- Para observaciones m√©dicas, usa OBSE_OBSERVATIONS
- Para pacientes, usa PATI_PATIENTS
- Para episodios, usa EPIS_EPISODES
- Para diagn√≥sticos, usa EPIS_DIAGNOSTICS
- Para medicamentos, usa MEDI_MEDICATIONS
- Para citas, usa APPO_APPOINTMENTS

RESPUESTA JSON:
{{
    "table_exists": true/false,
    "exact_match": true/false,
    "suggested_table": "tabla_sugerida_si_no_existe",
    "similar_tables": ["tabla1", "tabla2"]
}}

IMPORTANTE: Solo responde con el JSON."""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Validando existencia de tabla adaptativamente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('table_exists') is not None:
                table_exists = result.get('table_exists', False)
                suggested_table = result.get('suggested_table', '')
                
                if stream_callback:
                    if table_exists:
                        stream_callback(f"   ‚úÖ Tabla {table_name} existe")
                    else:
                        stream_callback(f"   ‚ö†Ô∏è TABLA CORREGIDA: {table_name} ‚Üí {suggested_table}")
                
                return table_exists
            else:
                # Fallback mejorado
                return table_name in self.column_metadata
                
        except Exception as e:
            logger.error(f"Error validando tabla: {e}")
            return table_name in self.column_metadata

    async def _llm_detect_common_fields_adaptive(self, table_name: str, field_type: str, stream_callback=None) -> List[str]:
        """Usa LLM para detectar din√°micamente campos comunes de una tabla"""
        try:
            if not self.llm:
                # Fallback b√°sico
                if field_type == 'name':
                    return ['PATI_NAME']
                elif field_type == 'surname':
                    return ['PATI_SURNAME_1']
                elif field_type == 'id':
                    return ['PATI_ID']
                else:
                    return []
            
            schema_info = self._get_real_schema_info()
            
            prompt = f"""Eres un experto en an√°lisis de esquemas de base de datos m√©dicos.

DETECCI√ìN DE CAMPOS COMUNES:
Tabla: {table_name}
Tipo de campo: {field_type}

ESQUEMA DISPONIBLE:
{schema_info}

INSTRUCCIONES:
1. Analiza la tabla {table_name}
2. Identifica campos que correspondan al tipo: {field_type}
3. Para 'name': busca campos de nombre, nombre completo, etc.
4. Para 'surname': busca campos de apellido
5. Para 'id': busca campos de identificaci√≥n
6. Considera variaciones y sin√≥nimos

RESPUESTA JSON:
{{
    "common_fields": ["campo1", "campo2"],
    "field_type": "{field_type}",
    "table": "{table_name}"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Detectando campos comunes adaptativamente"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('common_fields'):
                return result['common_fields']
            else:
                # Fallback b√°sico
                if field_type == 'name':
                    return ['PATI_NAME']
                elif field_type == 'surname':
                    return ['PATI_SURNAME_1']
                elif field_type == 'id':
                    return ['PATI_ID']
                else:
                    return []
                
        except Exception as e:
            logger.error(f"Error detectando campos comunes: {e}")
            # Fallback b√°sico
            if field_type == 'name':
                return ['PATI_NAME']
            elif field_type == 'surname':
                return ['PATI_SURNAME_1']
            elif field_type == 'id':
                return ['PATI_ID']
            else:
                return []

    async def _llm_generate_dynamic_sql_adaptive(self, operation: str, table: str, data: Dict[str, Any], stream_callback=None) -> str:
        """Usa LLM para generar SQL din√°mico basado en el esquema real"""
        try:
            if not self.llm:
                # Fallback b√°sico
                if operation == 'INSERT':
                    return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
                elif operation == 'UPDATE':
                    return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
                elif operation == 'DELETE':
                    return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
                else:
                    return f"SELECT * FROM {table};"
            
            schema_info = self._get_real_schema_info()
            table_schema = self._get_table_schema_info(table)
            
            prompt = f"""Eres un experto en SQL m√©dico. Genera SQL din√°mico basado en el esquema real.

OPERACI√ìN: {operation}
TABLA: {table}
DATOS: {json.dumps(data, indent=2, ensure_ascii=False)}

ESQUEMA COMPLETO:
{schema_info}

ESQUEMA DE LA TABLA ESPEC√çFICA:
{table_schema}

INSTRUCCIONES:
1. Analiza el esquema real de la tabla {table}
2. Identifica campos apropiados para la operaci√≥n {operation}
3. Mapea los datos disponibles a campos existentes
4. Genera SQL v√°lido y funcional
5. Evita campos de ID en INSERT
6. Maneja valores nulos correctamente

REGLAS CR√çTICAS:
- Usa solo campos que existan en el esquema
- Para INSERT: NO incluyas campos de ID (d√©jalos autoincrementarse)
- Para UPDATE/DELETE: usa campos de ID apropiados en WHERE
- Maneja valores nulos con NULL, NO "None"
- Escapa valores de texto apropiadamente

RESPUESTA JSON:
{{
    "sql": "SQL generado aqu√≠",
    "columns_used": ["columna1", "columna2"],
    "values_used": ["valor1", "valor2"],
    "operation": "{operation}"
}}

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="Generando SQL din√°mico adaptativo"
            )
            
            content = self._extract_response_text(response)
            result = self._try_parse_llm_json(content)
            
            if result and result.get('sql'):
                return result['sql']
            else:
                # Fallback b√°sico
                if operation == 'INSERT':
                    return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
                elif operation == 'UPDATE':
                    return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
                elif operation == 'DELETE':
                    return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
                else:
                    return f"SELECT * FROM {table};"
                
        except Exception as e:
            logger.error(f"Error generando SQL din√°mico: {e}")
            # Fallback b√°sico
            if operation == 'INSERT':
                return f"INSERT INTO {table} (PATI_NAME) VALUES ('{data.get('name', '')}');"
            elif operation == 'UPDATE':
                return f"UPDATE {table} SET PATI_NAME = '{data.get('name', '')}' WHERE PATI_ID = '{data.get('id', '')}';"
            elif operation == 'DELETE':
                return f"DELETE FROM {table} WHERE PATI_ID = '{data.get('id', '')}';"
            else:
                return f"SELECT * FROM {table};"

    async def _llm_validate_and_correct_fictitious_ids_adaptive(self, values: List[Any], columns: List[str], stream_callback=None) -> List[Any]:
        """Validaci√≥n r√°pida de IDs ficticios sin LLM para reducir costos"""
        try:
            if stream_callback:
                stream_callback("   üí° Validando IDs problem√°ticos...")
            
            # VALIDACI√ìN R√ÅPIDA SIN LLM - usar patrones predefinidos
            corrected_values = []
            corrections_applied = []
            
            for val in values:
                if isinstance(val, str):
                    # Patrones de IDs ficticios m√°s agresivos
                    if any(pattern in val.lower() for pattern in [
                        'unico', 'urn:uuid:', 'patient-id', 'observation-id', 
                        'encounter-id', 'medication-id', 'id-', 'ficticio', 
                        'mock', 'fake', 'unknown', 'null', 'none'
                    ]) or val.lower() in ['unknown', 'null', 'none', '']:
                        corrected_values.append(None)
                        corrections_applied.append(f"ID ficticio detectado: {val} ‚Üí NULL")
                    elif val.isdigit():
                        # Convertir string num√©rico a int
                        corrected_values.append(int(val))
                        corrections_applied.append(f"String num√©rico convertido: {val} ‚Üí {int(val)}")
                    else:
                        # Valor v√°lido, mantener
                        corrected_values.append(val)
                elif val is None:
                    # Valor None, mantener
                    corrected_values.append(None)
                else:
                    # Valor no string, mantener
                    corrected_values.append(val)
            
            if stream_callback:
                stream_callback(f"   ‚úÖ IDs validados")
                if corrections_applied:
                    for correction in corrections_applied:
                        stream_callback(f"      - {correction}")
            
            return corrected_values
                
        except Exception as e:
            logger.error(f"Error en validaci√≥n de IDs ficticios: {e}")
            return values

    async def _get_real_inserted_id_adaptive(self, table: str, data: Dict[str, Any], stream_callback=None) -> Optional[int]:
        """
        Obtiene el ID real del registro insertado usando m√∫ltiples estrategias adaptativas.
        
        Args:
            table: Nombre de la tabla
            data: Datos insertados
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            Optional[int]: ID del registro insertado o None si no se puede obtener
        """
        try:
            if stream_callback:
                stream_callback("   üí° Obteniendo ID real del registro insertado...")
            
            # DEBUG: Mostrar informaci√≥n de entrada
            print(f"   üîç DEBUG _get_real_inserted_id_adaptive:")
            print(f"      - Tabla: {table}")
            print(f"      - Datos: {json.dumps(data, indent=2, ensure_ascii=False)}")
            
            # ESTRATEGIA 1: Buscar por criterios √∫nicos seg√∫n tabla
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                # ESTRATEGIA DIN√ÅMICA: Usar LLM para determinar criterios de b√∫squeda
                search_queries = []
                
                # Obtener esquema de la tabla din√°micamente
                table_schema = self._get_table_schema_info(table)
                print(f"      - Esquema de tabla: {table_schema}")
                
                # Buscar campos √∫nicos en la tabla
                if self.llm:
                    # Usar LLM para determinar criterios de b√∫squeda din√°micos
                    search_criteria = await self._llm_determine_search_criteria(table, data, stream_callback)
                    for criteria in search_criteria:
                        search_queries.append(criteria)
                
                # ESTRATEGIA FALLBACK: Buscar el √∫ltimo registro insertado en la tabla
                # Determinar columna ID din√°micamente
                id_column = await self._llm_detect_id_column(table, stream_callback)
                print(f"      - Columna ID detectada: {id_column}")
                
                if id_column:
                    search_queries.append((
                        f"SELECT {id_column} FROM {table} ORDER BY {id_column} DESC LIMIT 1",
                        []
                    ))
                
                print(f"      - Consultas de b√∫squeda: {search_queries}")
                
                # Ejecutar las consultas en orden de prioridad
                for query, params in search_queries:
                    try:
                        print(f"      - Ejecutando consulta: {query}")
                        cursor.execute(query, params)
                        row = cursor.fetchone()
                        print(f"      - Resultado: {row}")
                    except Exception as e:
                        print(f"      - Error ejecutando consulta: {e}")
                        row = None
                        
                        if row and row[0]:
                            # Verificar si el ID es ficticio
                            id_str = str(row[0]).lower()
                            if any(fictitious in id_str for fictitious in [
                                "patient-id-unico", "urn:uuid:", "uuid:", "ficticio", "example", "test", "ejemplo"
                            ]):
                                print(f"      - ‚ö†Ô∏è ID ficticio detectado: {row[0]}, continuando...")
                                continue
                            
                            # Convertir a int de forma segura
                            try:
                                real_id = int(row[0])
                                if real_id > 0:
                                    if stream_callback:
                                        stream_callback(f"   üí° ID encontrado con consulta: {query[:50]}...")
                                    conn.close()
                                    return real_id
                            except (ValueError, TypeError):
                                # Si no se puede convertir a int, continuar con la siguiente consulta
                                print(f"      - Error convirtiendo a int: {row[0]}")
                                continue
                
                conn.close()
            except Exception as e:
                if stream_callback:
                    stream_callback(f"   ‚ö†Ô∏è Error en b√∫squeda por criterios: {e}")
                print(f"      - Error en b√∫squeda por criterios: {e}")
            
            # ESTRATEGIA 2: Buscar por datos espec√≠ficos del registro insertado
            try:
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                
                # Buscar por campos √∫nicos en los datos insertados (solo campos que existen en la tabla)
                table_schema = self._get_table_schema_info(table)
                existing_columns = []
                
                # Extraer nombres de columnas del esquema
                for line in table_schema.split('\n'):
                    if line.strip().startswith('- ') and ':' in line:
                        col_name = line.strip()[2:].split(':')[0].strip()
                        existing_columns.append(col_name)
                
                print(f"      - Columnas existentes en tabla: {existing_columns}")
                
                # Filtrar solo campos que existen en la tabla
                unique_fields = []
                for key, value in data.items():
                    if key in existing_columns and value and value != 'NULL' and value != 'null' and value != 'None':
                        if isinstance(value, str) and len(value) > 0:
                            unique_fields.append((key, value))
                
                print(f"      - Campos √∫nicos v√°lidos encontrados: {unique_fields}")
                
                if unique_fields:
                    # Construir consulta din√°mica
                    conditions = []
                    params = []
                    for field, value in unique_fields[:3]:  # Usar m√°ximo 3 campos
                        conditions.append(f"{field} = ?")
                        params.append(value)
                    
                    if conditions:
                        # Intentar con diferentes nombres de columna ID
                        id_columns_to_try = ['PATI_ID', 'ID', f"{table}_ID", 'id']
                        
                        for id_col in id_columns_to_try:
                            query = f"SELECT {id_col} FROM {table} WHERE {' AND '.join(conditions)} ORDER BY {id_col} DESC LIMIT 1"
                            try:
                                print(f"      - Probando consulta: {query}")
                                cursor.execute(query, params)
                                row = cursor.fetchone()
                                print(f"      - Resultado: {row}")
                                
                                if row and row[0]:
                                    # Verificar si el ID es ficticio
                                    id_str = str(row[0]).lower()
                                    if any(fictitious in id_str for fictitious in [
                                        "patient-id-unico", "urn:uuid:", "uuid:", "ficticio", "example", "test", "ejemplo"
                                    ]):
                                        print(f"      - ‚ö†Ô∏è ID ficticio detectado: {row[0]}, continuando...")
                                        continue
                                    
                                    try:
                                        real_id = int(row[0])
                                        if real_id > 0:
                                            if stream_callback:
                                                stream_callback(f"   üí° ID encontrado por datos √∫nicos: {real_id}")
                                            conn.close()
                                            return real_id
                                    except (ValueError, TypeError):
                                        print(f"      - Error convirtiendo a int: {row[0]}")
                                        pass
                            except Exception as e:
                                print(f"      - Error con columna {id_col}: {e}")
                                continue
                
                conn.close()
            except Exception as e:
                if stream_callback:
                    stream_callback(f"   ‚ö†Ô∏è Error en b√∫squeda por datos espec√≠ficos: {e}")
                print(f"      - Error en b√∫squeda por datos espec√≠ficos: {e}")
            
            if stream_callback:
                stream_callback("   ‚ùå No se pudo obtener el ID del registro insertado")
            
            return None
            
        except Exception as e:
            logger.error(f"Error obteniendo ID real: {e}")
            print(f"      - Error general: {e}")
            return None

    async def _llm_determine_search_criteria(self, table: str, data: Dict[str, Any], stream_callback=None) -> List[Tuple[str, List[Any]]]:
        """Usa LLM para determinar criterios de b√∫squeda din√°micos"""
        try:
            if not self.llm:
                return []
            
            if stream_callback:
                stream_callback("   üí° Determinando criterios de b√∫squeda din√°micos...")
            
            table_schema = self._get_table_schema_info(table)
            
            prompt = f"""Eres un experto en bases de datos m√©dicas. Determina criterios de b√∫squeda para encontrar un registro reci√©n insertado.

TABLA: {table}
DATOS INSERTADOS: {json.dumps(data, indent=2, ensure_ascii=False)}
ESQUEMA DE LA TABLA:
{table_schema}

TAREA: Genera consultas SQL para encontrar el registro reci√©n insertado usando criterios √∫nicos.

INSTRUCCIONES:
1. Analiza los datos insertados
2. Identifica campos que pueden ser √∫nicos
3. Genera consultas SQL para buscar por esos criterios
4. Usa campos como nombre, fecha, identificadores √∫nicos
5. Considera combinaciones de campos para mayor precisi√≥n
6. SOLO usa campos que existan en el esquema de la tabla
7. NO uses campos FHIR como "resourceType", "id", etc. que no existen en SQL

ESTRATEGIA:
- Busca por campos √∫nicos como nombres, fechas, identificadores
- Usa combinaciones de campos para mayor precisi√≥n
- Considera el contexto m√©dico de la tabla
- SOLO usa campos que existan en el esquema

RESPUESTA JSON:
{{
    "search_queries": [
        {{
            "sql": "SELECT PATI_ID FROM PATI_PATIENTS WHERE PATI_NAME = ? AND PATI_BIRTH_DATE = ? ORDER BY PATI_ID DESC LIMIT 1",
            "params": ["Carlos Mart√≠nez", "1963-01-01"]
        }}
    ]
}}

IMPORTANTE: 
- SOLO usa campos que existan en el esquema de la tabla
- NO uses campos FHIR como "resourceType", "id", etc.
- Usa campos espec√≠ficos de la tabla como PATI_NAME, PATI_BIRTH_DATE, etc.

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}]
            )
            
            result = self._try_parse_llm_json(response.content)
            if result and result.get('search_queries'):
                queries = []
                for query_info in result['search_queries']:
                    queries.append((query_info['sql'], query_info['params']))
                return queries
            
            return []
            
        except Exception as e:
            logger.error(f"Error determinando criterios de b√∫squeda: {e}")
            return []
    
    async def _llm_detect_id_column(self, table: str, stream_callback=None) -> Optional[str]:
        """Usa LLM para detectar la columna ID de una tabla"""
        try:
            if not self.llm:
                # Fallback b√°sico
                table_prefix = table.split('_')[0] if '_' in table else table
                return f"{table_prefix}_ID"
            
            if stream_callback:
                stream_callback("   üí° Detectando columna ID...")
            
            table_schema = self._get_table_schema_info(table)
            
            prompt = f"""Eres un experto en esquemas de base de datos. Identifica la columna ID principal de esta tabla.

TABLA: {table}
ESQUEMA:
{table_schema}

TAREA: Identifica la columna que act√∫a como clave primaria o ID principal.

INSTRUCCIONES:
1. Busca columnas que terminen en _ID
2. Busca columnas que sean claves primarias (PRIMARY KEY)
3. Busca columnas de autoincremento
4. Considera el contexto de la tabla
5. Prioriza columnas que sean PRIMARY KEY

ESTRATEGIA:
- Primero busca columnas marcadas como PRIMARY KEY
- Luego busca columnas que terminen en _ID
- Considera el prefijo de la tabla (PATI_, EPIS_, etc.)

RESPUESTA JSON:
{{
    "id_column": "nombre_de_la_columna_id"
}}

IMPORTANTE: 
- Prioriza columnas marcadas como PRIMARY KEY
- Usa el formato est√°ndar: TABLA_ID (ej: PATI_ID, EPIS_ID)
- Si no hay PRIMARY KEY claro, usa el patr√≥n est√°ndar

Responde SOLO con el JSON:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}]
            )
            
            result = self._try_parse_llm_json(response.content)
            if result and result.get('id_column'):
                return result['id_column']
            
            # Fallback b√°sico
            table_prefix = table.split('_')[0] if '_' in table else table
            return f"{table_prefix}_ID"
            
        except Exception as e:
            logger.error(f"Error detectando columna ID: {e}")
            # Fallback b√°sico
            table_prefix = table.split('_')[0] if '_' in table else table
            return f"{table_prefix}_ID"

    async def _llm_consolidated_discovery_and_mapping(self, fhir_data: Dict[str, Any], stream_callback=None, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Mapeo FHIR‚ÜíSQL optimizado con UNA SOLA llamada LLM inteligente"""
        try:
            # DEBUG CR√çTICO: Mostrar datos de entrada
            print(f"üîç DEBUG _llm_consolidated_discovery_and_mapping:")
            print(f"   üì• FHIR Data: {json.dumps(fhir_data, indent=2, ensure_ascii=False)}")
            
            if not self.llm:
                return await self._llm_map_fhir_to_sql_adaptive(fhir_data, stream_callback, context)
            
            if stream_callback:
                stream_callback("   üöÄ Iniciando mapeo FHIR‚ÜíSQL optimizado (UNA llamada LLM)...")
            
            # OPTIMIZACI√ìN: UNA SOLA LLAMADA LLM PARA TODO
            schema_info = await self._get_cached_schema_info()
            
            # CR√çTICO: Leer directamente el resourceType para evitar llamada LLM
            resource_type = fhir_data.get('resourceType', '')
            if not resource_type or not isinstance(resource_type, str) or not resource_type.strip():
                if stream_callback:
                    stream_callback("   ‚ö†Ô∏è No se encontr√≥ resourceType, usando LLM...")
                resource_type = "Unknown"
            else:
                resource_type = resource_type.strip()
                if stream_callback:
                    stream_callback(f"   üìã Tipo detectado directamente: {resource_type}")
            
            # UNA SOLA LLAMADA LLM PARA SELECCI√ìN DE TABLA Y MAPEO
            prompt = f"""CR√çTICO: An√°lisis completo FHIR‚ÜíSQL en UNA SOLA respuesta.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

TIPO DE RECURSO: {resource_type}

ESQUEMA DE BASE DE DATOS:
{schema_info}

INSTRUCCIONES ABSOLUTAS:
1. Analiza el tipo de recurso FHIR
2. Selecciona la tabla SQL m√°s apropiada
3. Mapea los campos FHIR a columnas SQL
4. Extrae SOLO datos reales (NO inventes datos)
5. Usa NULL para campos sin datos reales
6. Considera el contexto m√©dico

RESPUESTA EN FORMATO JSON:
{{
    "resource_type": "tipo_detectado",
    "target_table": "tabla_seleccionada", 
    "mapped_fields": {{
        "columna_sql": "valor_real_o_null",
        "columna_sql2": "valor_real_o_null"
    }},
    "confidence": "alta/media/baja",
    "reasoning": "explicaci√≥n_breve"
}}

IMPORTANTE: 
- Solo mapea campos con datos reales
- Usa NULL para campos sin datos
- NO inventes nombres, fechas, o valores
- Considera el contexto m√©dico del recurso
- Selecciona tabla basada en el tipo de recurso"""

            if stream_callback:
                stream_callback("   ü§ñ Analizando con LLM (UNA llamada)...")
            
            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="An√°lisis completo FHIR‚ÜíSQL"
            )
            
            response_text = self._extract_response_text(response)
            parsed_result = self._try_parse_llm_json(response_text)
            
            if not parsed_result:
                if stream_callback:
                    stream_callback("   ‚ö†Ô∏è Error parsing LLM response, usando fallback...")
                return await self._llm_map_fhir_to_sql_adaptive(fhir_data, stream_callback, context)
            
            # Extraer resultados de la respuesta consolidada
            final_resource_type = parsed_result.get('resource_type', resource_type)
            target_table = parsed_result.get('target_table', '')
            mapped_data = parsed_result.get('mapped_fields', {})
            confidence = parsed_result.get('confidence', 'media')
            reasoning = parsed_result.get('reasoning', '')
            
            if stream_callback:
                stream_callback(f"   ‚úÖ An√°lisis completado (confianza: {confidence})")
                stream_callback(f"   üìã Razonamiento: {reasoning}")
            
            # CR√çTICO: Establecer el ID del paciente si es un recurso Patient
            if final_resource_type == "Patient":
                patient_id = context.get('patient_id') if context else None
                if patient_id:
                    self._current_patient_id = patient_id
                    print(f"   üîó Estableciendo _current_patient_id: {patient_id}")
            
            # Validaci√≥n simple sin LLM adicional
            cleaned_data = {}
            for column, value in mapped_data.items():
                if value is not None and value != "" and str(value).strip():
                    # Validar que no sea un ID ficticio
                    if not self._is_fictitious_id(value):
                        cleaned_data[column] = value
                    else:
                        cleaned_data[column] = None
                else:
                    cleaned_data[column] = None
            
            # Agregar PATI_ID del contexto si existe
            if context and context.get('patient_id'):
                patient_id = context['patient_id']
                print(f"   üîç Verificando PATI_ID del contexto: {patient_id}")
                
                # Obtener columnas de la tabla
                table_columns = await self._get_table_columns(target_table)
                print(f"   üìã Columnas de {target_table}: {table_columns}")
                
                # SISTEMA DIN√ÅMICO: Usar LLM para detectar columnas de relaci√≥n
                if self.llm:
                    try:
                        # PROMPT DIN√ÅMICO para detectar columnas de relaci√≥n
                        relationship_prompt = f"""Eres un experto en relaciones de base de datos m√©dicas.

TABLA: {target_table}
COLUMNAS DISPONIBLES: {table_columns}
PATIENT_ID DEL CONTEXTO: {patient_id}

TAREA: Identifica qu√© columna(s) de la tabla deben recibir el ID del paciente.

REGLAS:
1. Busca columnas que referencien al paciente (ej: PATI_ID, PATIENT_ID, etc.)
2. Considera columnas que contengan "PATI", "PATIENT", "SUBJECT"
3. Si no hay columnas espec√≠ficas, no agregues ninguna
4. Solo agrega relaciones v√°lidas

RESPUESTA JSON:
{{
    "patient_columns": ["columna1", "columna2"],
    "reasoning": "explicaci√≥n de las relaciones"
}}

Responde SOLO con el JSON:"""

                        response = await asyncio.to_thread(
                            _call_openai_native, self.llm, [{"role": "user", "content": relationship_prompt}],
                            task_description="Detectando relaciones de paciente"
                        )
                        
                        content = self._extract_response_text(response)
                        relationship_result = self._try_parse_llm_json(content)
                        
                        if relationship_result and relationship_result.get('patient_columns'):
                            for column in relationship_result['patient_columns']:
                                if column in table_columns:
                                    cleaned_data[column] = patient_id
                                    print(f"   üîó AGREGANDO {column}: {patient_id} (LLM din√°mico)")
                                    print(f"   üìä Razonamiento: {relationship_result.get('reasoning', 'N/A')}")
                        else:
                            print(f"   ‚ö†Ô∏è No se detectaron columnas de relaci√≥n para paciente")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è Error detectando relaciones de paciente: {e}")
                        # Fallback simple
                        if 'PATI_ID' in table_columns:
                            cleaned_data['PATI_ID'] = patient_id
                            print(f"   üîó INSERTANDO PATI_ID del contexto: {patient_id}")
                else:
                    # Fallback sin LLM
                    if 'PATI_ID' in table_columns:
                        cleaned_data['PATI_ID'] = patient_id
                        print(f"   üîó INSERTANDO PATI_ID del contexto: {patient_id}")

                if stream_callback:
                    stream_callback(f"   üéâ Mapeo optimizado completado: {final_resource_type} ‚Üí {target_table}")

                final_result = {
                    "success": True,
                    "resource_type": final_resource_type,
                "target_table": target_table,
                "mapped_data": cleaned_data,
                "validation": {
                    "confidence": confidence,
                    "reasoning": reasoning,
                    "llm_calls": 1  # Solo una llamada LLM
                },
                "debug_info": {
                    "method": "optimized_single_llm_call",
                    "llm_calls_reduced": True
                }
            }
            
            # DEBUG FINAL: Mostrar resultado final
            print(f"   üéØ RESULTADO FINAL _llm_consolidated_discovery_and_mapping:")
            print(f"   üìã Resource Type: {final_resource_type}")
            print(f"   üóÉÔ∏è Target Table: {target_table}")
            print(f"   üìã Mapped Data: {cleaned_data}")
            print(f"   ‚úÖ Success: {final_result['success']}")
            print(f"   üöÄ LLM Calls: 1 (optimizado)")
            
            return final_result
            
        except Exception as e:
            if stream_callback:
                stream_callback(f"   ‚ùå Error en mapeo optimizado: {str(e)}")
            return await self._llm_map_fhir_to_sql_adaptive(fhir_data, stream_callback, context)

    def _is_fictitious_id(self, value: Any) -> bool:
        """Detectar IDs ficticios sin usar LLM"""
        if not value:
            return False
        
        value_str = str(value).lower()
        fictitious_patterns = [
            'urn:uuid:', 'patient-id-', 'encounter-id-', 'medication-id-',
            'observation-id-', 'condition-id-', 'example', 'test', 'demo',
            'fictitious', 'mock', 'sample', 'dummy'
        ]
        
        return any(pattern in value_str for pattern in fictitious_patterns)
    
    async def _get_table_columns(self, table_name: str) -> List[str]:
        """Obtener columnas de tabla directamente de la base de datos"""
        try:
            if not table_name:
                return []
            
            # Consulta directa a la base de datos para obtener columnas
            query = f"PRAGMA table_info({table_name})"
            
            # Usar sqlite3 sincr√≥nico en un thread separado
            def get_columns_sync():
                with sqlite3.connect(self.db_path) as db:
                    cursor = db.execute(query)
                    rows = cursor.fetchall()
                    return [row[1] for row in rows]  # row[1] es el nombre de la columna
            
            # Ejecutar en thread separado para no bloquear
            columns = await asyncio.to_thread(get_columns_sync)
            return columns
                    
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error obteniendo columnas de {table_name}: {e}")
            # Fallback: intentar con el esquema cacheado
            try:
                schema_info = await self._get_cached_schema_info(table_name)
                if schema_info:
                    lines = schema_info.split('\n')
                    columns = []
                    for line in lines:
                        if ':' in line and '(' in line:
                            column_part = line.split(':')[0].strip()
                            if column_part.startswith('- '):
                                column_name = column_part[2:]
                                columns.append(column_name)
                    return columns
            except:
                pass
            return []
    
    async def _llm_detect_resource_type_step(self, fhir_data: Dict[str, Any], stream_callback=None) -> str:
        """Paso 1: Detectar tipo de recurso FHIR"""
        
        # PRIMERA VALIDACI√ìN: Leer directamente el campo resourceType
        actual_resource_type = fhir_data.get('resourceType', '')
        if actual_resource_type and isinstance(actual_resource_type, str) and actual_resource_type.strip():
            if stream_callback:
                stream_callback(f"   üìã Tipo detectado directamente: {actual_resource_type}")
            return actual_resource_type.strip()
        
        # SEGUNDA VALIDACI√ìN: Si no hay resourceType, usar LLM con prompt m√°s espec√≠fico
        prompt = f"""CR√çTICO: Lee EXACTAMENTE el campo "resourceType" del JSON FHIR.

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES ABSOLUTAS:
1. Busca el campo "resourceType" en el nivel ra√≠z del JSON
2. Lee EXACTAMENTE el valor de ese campo
3. NO analices la estructura, NO infieras, NO adivines
4. Solo lee el valor del campo "resourceType"
5. Si el campo no existe, responde "Unknown"

EJEMPLOS ESPEC√çFICOS:
- Si resourceType: "Patient" ‚Üí responde "Patient"
- Si resourceType: "Encounter" ‚Üí responde "Encounter"  
- Si resourceType: "Condition" ‚Üí responde "Condition"
- Si resourceType: "MedicationRequest" ‚Üí responde "MedicationRequest"
- Si resourceType: "Observation" ‚Üí responde "Observation"
- Si resourceType: "Medication" ‚Üí responde "Medication"

RESPUESTA OBLIGATORIA:
- Solo el valor del campo resourceType
- Sin comillas, sin explicaciones
- Sin formato JSON
- Sin texto adicional
- Si no encuentra el campo, responde "Unknown" """

        response = await asyncio.to_thread(
            _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
            task_description="Detecci√≥n de tipo de recurso"
        )
        
        resource_type = self._extract_response_text(response).strip().strip('"').strip("'")
        
        # Validaci√≥n din√°mica usando LLM para verificar si el tipo es v√°lido
        if stream_callback:
            stream_callback(f"   üîç Validando tipo detectado: {resource_type}")
        
        validation_prompt = f"""AN√ÅLISIS DE VALIDACI√ìN DE TIPO DE RECURSO FHIR

TIPO DETECTADO: {resource_type}

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Analiza si el tipo "{resource_type}" es un tipo de recurso FHIR v√°lido
2. Considera el contexto m√©dico y la estructura de los datos
3. Si el tipo es v√°lido, responde "VALID"
4. Si el tipo no es v√°lido o no tiene sentido, responde "INVALID"
5. Si no hay suficiente informaci√≥n, responde "UNKNOWN"

RESPUESTA: Solo "VALID", "INVALID" o "UNKNOWN" """

        validation_response = await asyncio.to_thread(
            _call_openai_native, self.llm, [{"role": "user", "content": validation_prompt}],
            task_description="Validaci√≥n din√°mica de tipo de recurso"
        )
        
        validation_result = self._extract_response_text(validation_response).strip().upper()
        
        if validation_result == "INVALID" or validation_result == "UNKNOWN":
            if stream_callback:
                stream_callback(f"   ‚ö†Ô∏è Tipo detectado no v√°lido: {resource_type}")
                stream_callback(f"   üîÑ Reintentando detecci√≥n con an√°lisis m√°s profundo...")
            
            # Reintentar con un prompt m√°s espec√≠fico y din√°mico
            retry_prompt = f"""AN√ÅLISIS PROFUNDO DE TIPO DE RECURSO FHIR

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Analiza la estructura completa del JSON FHIR
2. Busca patrones m√©dicos, campos espec√≠ficos, y contexto
3. Determina el tipo de recurso m√°s apropiado basado en el contenido
4. Considera campos como "patient", "encounter", "medication", "observation", etc.
5. Si no hay informaci√≥n clara, usa el contexto m√©dico para inferir

RESPUESTA: Solo el tipo de recurso m√°s apropiado (Patient, Encounter, Condition, etc.)"""
            
            retry_response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": retry_prompt}],
                task_description="Reintento de detecci√≥n de tipo"
            )
            
            resource_type = self._extract_response_text(retry_response).strip().strip('"').strip("'")
            
        if stream_callback:
            stream_callback(f"   üìã Tipo detectado: {resource_type}")
        
        return resource_type
    
    async def _llm_select_table_step(self, resource_type: str, fhir_data: Dict[str, Any], stream_callback=None) -> str:
        """Paso 2: Seleccionar tabla apropiada usando LLM inteligente"""
        
        prompt = f"""CR√çTICO: Selecciona la tabla SQL m√°s apropiada para el tipo de recurso FHIR.

TIPO DE RECURSO: {resource_type}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES CR√çTICAS:
1. Analiza el tipo de recurso y el contexto m√©dico
2. Busca en el esquema la tabla m√°s apropiada
3. Considera el significado m√©dico y la estructura de datos
4. NO uses mapeos r√≠gidos, analiza din√°micamente
5. Si no encuentras una tabla espec√≠fica, usa la m√°s gen√©rica disponible

AN√ÅLISIS DIN√ÅMICO:
- Patient: busca tablas relacionadas con pacientes, personas, usuarios
- Encounter: busca tablas de episodios, encuentros, visitas
- Condition: busca tablas de condiciones, diagn√≥sticos, problemas
- Observation: busca tablas de observaciones, mediciones, resultados
- MedicationRequest: busca tablas de medicamentos, prescripciones
- Medication: busca tablas de medicamentos, f√°rmacos

RESPUESTA: Solo el nombre de la tabla m√°s apropiada del esquema disponible."""

        response = await asyncio.to_thread(
            _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
            task_description="Selecci√≥n de tabla"
        )
        
        target_table = self._extract_response_text(response).strip().strip('"').strip("'")
        
        # Validaci√≥n: verificar que la tabla existe y es correcta
        schema_info = self._get_real_schema_info()
        
        # Validaci√≥n din√°mica de tabla usando LLM
        if stream_callback:
            stream_callback(f"   üîç Validando tabla seleccionada: {target_table}")
        
        table_validation_prompt = f"""VALIDACI√ìN DIN√ÅMICA DE TABLA PARA RECURSO FHIR

TIPO DE RECURSO: {resource_type}
TABLA SELECCIONADA: {target_table}

ESQUEMA DE BASE DE DATOS:
{schema_info}

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Analiza si la tabla "{target_table}" es apropiada para el tipo "{resource_type}"
2. Considera la estructura de la tabla y los campos disponibles
3. Si la tabla es correcta, responde "VALID"
4. Si la tabla no es correcta, responde "INVALID"
5. Si no hay suficiente informaci√≥n, responde "UNKNOWN"

RESPUESTA: Solo "VALID", "INVALID" o "UNKNOWN" """

        table_validation_response = await asyncio.to_thread(
            _call_openai_native, self.llm, [{"role": "user", "content": table_validation_prompt}],
            task_description="Validaci√≥n din√°mica de tabla"
        )
        
        table_validation_result = self._extract_response_text(table_validation_response).strip().upper()
        
        if table_validation_result == "INVALID" or table_validation_result == "UNKNOWN":
            if stream_callback:
                stream_callback(f"   ‚ö†Ô∏è Tabla incorrecta para {resource_type}: {target_table}")
                stream_callback(f"   üîÑ Buscando tabla m√°s apropiada...")
            
            # Buscar tabla m√°s apropiada usando LLM
            table_correction_prompt = f"""SELECCI√ìN DIN√ÅMICA DE TABLA PARA RECURSO FHIR

TIPO DE RECURSO: {resource_type}

ESQUEMA DE BASE DE DATOS:
{schema_info}

DATOS FHIR:
{json.dumps(fhir_data, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Analiza el esquema completo de la base de datos
2. Busca la tabla m√°s apropiada para el tipo "{resource_type}"
3. Considera patrones en nombres de tablas, campos disponibles, y contexto m√©dico
4. Selecciona la tabla que mejor se adapte a los datos FHIR
5. Responde solo con el nombre de la tabla m√°s apropiada

RESPUESTA: Solo el nombre de la tabla (ej: PATI_PATIENTS, EPIS_EPISODES, etc.)"""

            table_correction_response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": table_correction_prompt}],
                task_description="Correcci√≥n din√°mica de tabla"
            )
            
            target_table = self._extract_response_text(table_correction_response).strip()
        
        # Verificar que la tabla existe en el esquema
        if target_table not in schema_info:
            if stream_callback:
                stream_callback(f"   ‚ö†Ô∏è Tabla no existe en esquema: {target_table}")
            # Usar tabla por defecto
            target_table = "PATI_PATIENTS"
            if stream_callback:
                stream_callback(f"   üîÑ Usando tabla por defecto: {target_table}")
        
        if stream_callback:
            stream_callback(f"   üéØ Tabla seleccionada: {target_table}")
        
        return target_table

    async def _llm_flexible_sql_analysis(self, sql: str, query_context: str = "", stream_callback=None) -> str:
        """
        An√°lisis flexible de SQL usando prompts espec√≠ficos del LLM.
        ARQUITECTURA ADAPTATIVA: Diferentes prompts seg√∫n el contexto.
        
        Args:
            sql: SQL a analizar
            query_context: Contexto de la consulta original del usuario
            stream_callback: Funci√≥n para mostrar progreso
            
        Returns:
            str: SQL analizado y mejorado
        """
        try:
            if not self.llm:
                return sql
            
            if stream_callback:
                stream_callback("   - An√°lisis flexible con IA...")
            
            # PROMPT ESPEC√çFICO SEG√öN CONTEXTO
            if "grave" in query_context.lower() or "pron√≥stico" in query_context.lower():
                # Prompt para consultas de pron√≥stico grave
                prompt = f"""Eres un experto en SQL especializado en consultas de pron√≥stico m√©dico grave.

CONSULTA ORIGINAL: {query_context}
SQL GENERADO: {sql}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

AN√ÅLISIS ESPEC√çFICO PARA PRON√ìSTICO GRAVE:
1. ¬øBusca pacientes con condiciones m√©dicas graves?
2. ¬øUsa campos de texto libre para buscar t√©rminos m√©dicos?
3. ¬øOrdena por severidad o gravedad?
4. ¬øIncluye informaci√≥n del paciente y diagn√≥stico?

REGLAS PARA PRON√ìSTICO GRAVE:
- Usar DIAG_OBSERVATION (NO DIAG_DESCRIPTION que no existe)
- Buscar t√©rminos como 'grave', 'c√°ncer', 'terminal', 'cr√≠tico'
- JOIN PATI_PATIENTS con EPIS_DIAGNOSTICS
- Ordenar por t√©rminos de gravedad en DIAG_OBSERVATION
- Incluir informaci√≥n del paciente (PATI_NAME, PATI_SURNAME_1)

CAMPOS CORRECTOS:
- EPIS_DIAGNOSTICS.DIAG_OBSERVATION: Campo de texto para diagn√≥sticos
- PATI_PATIENTS.PATI_NAME, PATI_SURNAME_1: Datos del paciente
- NO USAR: DIAG_DESCRIPTION (no existe en la tabla)

EJEMPLOS:
‚úÖ CORRECTO: SELECT p.PATI_NAME, p.PATI_SURNAME_1, d.DIAG_OBSERVATION FROM PATI_PATIENTS p JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%grave%' ORDER BY CASE WHEN d.DIAG_OBSERVATION LIKE '%c√°ncer%' THEN 1 WHEN d.DIAG_OBSERVATION LIKE '%terminal%' THEN 2 ELSE 3 END LIMIT 1

INSTRUCCIONES:
1. Verifica que use DIAG_OBSERVATION (no DIAG_DESCRIPTION)
2. A√±ade JOINs necesarios para obtener datos del paciente
3. Incluye filtros para condiciones graves
4. Ordena por severidad m√©dica
5. Mant√©n la l√≥gica original

Devuelve SOLO el SQL:"""
            
            elif "pacientes" in query_context.lower() or "count" in sql.lower():
                # Prompt para consultas de conteo de pacientes
                prompt = f"""Eres un experto en SQL especializado en consultas m√©dicas de pacientes.

CONSULTA ORIGINAL: {query_context}
SQL GENERADO: {sql}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

AN√ÅLISIS ESPEC√çFICO PARA PACIENTES:
1. ¬øEs una consulta simple de conteo? (SELECT COUNT(*) FROM tabla)
2. ¬øNecesita JOINs para obtener datos relacionados?
3. ¬øHay filtros por condiciones m√©dicas?
4. ¬øSe busca informaci√≥n espec√≠fica de pacientes?

REGLAS PARA CONSULTAS DE PACIENTES:
- Si es SELECT COUNT(*) FROM PATI_PATIENTS ‚Üí Es correcto
- Si busca pacientes con condici√≥n ‚Üí A√±adir JOIN con diagn√≥sticos
- Si busca medicaci√≥n ‚Üí A√±adir JOIN con medicamentos
- Si busca por descripci√≥n ‚Üí Usar LIKE en campos de texto

EJEMPLOS:
‚úÖ SIMPLE: SELECT COUNT(*) FROM PATI_PATIENTS
‚úÖ CON FILTRO: SELECT COUNT(*) FROM PATI_PATIENTS p JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%diabetes%'

INSTRUCCIONES:
1. Analiza si el SQL es apropiado para la consulta
2. Si es simple y correcto ‚Üí NO MODIFICAR
3. Si necesita JOINs para datos relacionados ‚Üí A√ëADIR
4. Si hay errores ‚Üí CORREGIR
5. Mant√©n la l√≥gica original

Devuelve SOLO el SQL:"""
            
            elif "medicaci√≥n" in query_context.lower() or "medication" in sql.lower():
                # Prompt para consultas de medicaci√≥n
                prompt = f"""Eres un experto en SQL especializado en consultas de medicaci√≥n.

CONSULTA ORIGINAL: {query_context}
SQL GENERADO: {sql}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

AN√ÅLISIS ESPEC√çFICO PARA MEDICACI√ìN:
1. ¬øIncluye JOIN con tabla de medicamentos?
2. ¬øRelaciona pacientes con sus medicaciones?
3. ¬øFiltra por tipo de medicaci√≥n?
4. ¬øAgrupa por medicaci√≥n?

REGLAS PARA MEDICACI√ìN:
- Siempre JOIN PATI_PATIENTS con PATI_USUAL_MEDICATION
- Usar LEFT JOIN para incluir pacientes sin medicaci√≥n
- Agrupar por MEDICATION_NAME si se pide conteo
- Filtrar por condici√≥n m√©dica si se especifica

EJEMPLOS:
‚úÖ CORRECTO: SELECT p.PATI_ID, m.MEDICATION_NAME FROM PATI_PATIENTS p LEFT JOIN PATI_USUAL_MEDICATION m ON p.PATI_ID = m.PATI_ID
‚úÖ CON FILTRO: SELECT m.MEDICATION_NAME, COUNT(*) FROM PATI_PATIENTS p JOIN PATI_USUAL_MEDICATION m ON p.PATI_ID = m.PATI_ID JOIN EPIS_DIAGNOSTICS d ON p.PATI_ID = d.PATI_ID WHERE d.DIAG_OBSERVATION LIKE '%diabetes%' GROUP BY m.MEDICATION_NAME

INSTRUCCIONES:
1. Verifica que incluya JOIN con medicaci√≥n
2. A√±ade filtros si se especifican condiciones
3. Corrige agrupaciones si es necesario
4. Mant√©n la l√≥gica original

Devuelve SOLO el SQL:"""
            
            else:
                # Prompt gen√©rico flexible
                prompt = f"""Eres un experto en SQL que analiza consultas de forma inteligente.

CONSULTA ORIGINAL: {query_context}
SQL GENERADO: {sql}

ESQUEMA DISPONIBLE:
{self._get_real_schema_info()}

AN√ÅLISIS FLEXIBLE:
1. ¬øEl SQL es sint√°cticamente correcto?
2. ¬øIncluye todos los JOINs necesarios?
3. ¬øLos filtros son apropiados?
4. ¬øLa l√≥gica coincide con la consulta?

REGLAS GENERALES:
- Si es simple y correcto ‚Üí NO MODIFICAR
- Si falta JOIN necesario ‚Üí A√ëADIR
- Si hay error de sintaxis ‚Üí CORREGIR
- Si la l√≥gica no coincide ‚Üí AJUSTAR

INSTRUCCIONES:
1. Analiza la correcci√≥n del SQL
2. Si es correcto ‚Üí devuelve original
3. Si necesita mejoras ‚Üí mej√≥ralo
4. Mant√©n la l√≥gica original

Devuelve SOLO el SQL:"""

            response = await asyncio.to_thread(
                _call_openai_native, self.llm, [{"role": "user", "content": prompt}],
                task_description="An√°lisis flexible espec√≠fico con IA"
            )
            
            corrected_sql = self._extract_response_text(response).strip()
            corrected_sql = self._clean_llm_sql_response(corrected_sql)
            
            if corrected_sql and not corrected_sql.startswith("Error"):
                if corrected_sql != sql:
                    logger.info(f"üß† LLM realiz√≥ an√°lisis flexible espec√≠fico")
                    logger.info(f"   SQL original: {sql[:100]}...")
                    logger.info(f"   SQL mejorado: {corrected_sql[:100]}...")
                    
                    if stream_callback:
                        stream_callback("   ‚úÖ An√°lisis espec√≠fico completado")
                else:
                    if stream_callback:
                        stream_callback("   ‚úÖ SQL analizado, sin cambios necesarios")
                
                return corrected_sql
            else:
                logger.warning(f"‚ö†Ô∏è LLM no pudo realizar an√°lisis flexible espec√≠fico")
                return sql
                
        except Exception as e:
            logger.error(f"Error en _llm_flexible_sql_analysis: {e}")
            return sql